{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "seed = 0\n",
    "os.environ['PYTHONHASSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../data/turbofan_dataset/N-CMAPSS_DS02-006.h5'\n",
    "output_path = './experiment_set_16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmapss_score_function(actual, predictions, normalize=True):\n",
    "    # diff < 0 -> over-estimation\n",
    "    # diff > 0 -> under-estimation\n",
    "    diff = actual - predictions\n",
    "    alpha = np.full_like(diff, 1/13)\n",
    "    negative_diff_mask = diff < 0\n",
    "    alpha[negative_diff_mask] = 1/10\n",
    "    score = np.sum(np.exp(alpha * np.abs(diff)))\n",
    "    \n",
    "    if normalize:\n",
    "        N = len(predictions)\n",
    "        score /= N\n",
    "    return score\n",
    "\n",
    "def compute_evaluation_metrics(actual, predictions, label='Test'):\n",
    "    mse = mean_squared_error(actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    cmapss_score = cmapss_score_function(actual, predictions)\n",
    "    print('{} set:\\nMSE: {:.2f}\\nRMSE: {:.2f}\\nCMAPSS score: {:.2f}\\n'.format(label, mse, rmse, \n",
    "                                                                     cmapss_score))\n",
    "    return mse, rmse, cmapss_score\n",
    "    \n",
    "def plot_loss_curves(history, output_path=None, y_lim=[0, 150]):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylim(y_lim)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    \n",
    "    if output_path is not None:\n",
    "        plt.savefig(os.path.join(output_path, 'loss_curves.png'), format='png', dpi=300) \n",
    "    plt.show()\n",
    "    \n",
    "def plot_rul(expected, predicted):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(expected)), expected, label='Expected')\n",
    "    plt.plot(range(len(predicted)), predicted, label='Predicted')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def create_mlp_model(input_dim, hidden_layer_sizes, activation='relu', dropout=0, output_weights_file=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], \n",
    "                    input_dim=input_dim, \n",
    "                    kernel_initializer='random_normal', \n",
    "                    activation=activation))\n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "    for layer_size in hidden_layer_sizes[1:]:\n",
    "        model.add(Dense(layer_size, \n",
    "                        kernel_initializer='random_normal', \n",
    "                        activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='random_normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    if output_weights_file is not None:\n",
    "        model.save_weights(output_weights_file)\n",
    "    return model\n",
    "\n",
    "def train_model_existing_weights(model, weights_file, x_train, y_train, x_val, y_val, epochs=200, batch_size=512, callbacks=[]):\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.load_weights(weights_file)\n",
    "    return model.fit(x_train, y_train,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     verbose=1,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "def save_history(history, output_file=os.path.join(output_path, \"history.pkl\")):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "    print(\"Saved training history to file: {}\".format(output_file))\n",
    "\n",
    "def load_history(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def save_object(obj, output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    print(\"Saved object to file: {}\".format(output_file))\n",
    "    \n",
    "def load_object(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def model_evaluation(model, x_test, y_test, x_train=None, y_train=None, plot_range=[0, 10**3]):\n",
    "    if x_train is not None and y_train is not None:\n",
    "        predictions_train = model.predict(x_train).flatten()\n",
    "        compute_evaluation_metrics(predictions_train, y_train, 'Train')\n",
    "        \n",
    "        expected = y_train[plot_range[0]:plot_range[1]]\n",
    "        predicted = predictions_train[plot_range[0]:plot_range[1]]\n",
    "        plot_rul(expected, predicted)\n",
    "        \n",
    "    predictions_test = model.predict(x_test).flatten()\n",
    "    compute_evaluation_metrics(predictions_test, y_test)\n",
    "    \n",
    "    expected = y_test[plot_range[0]:plot_range[1]]\n",
    "    predicted = predictions_test[plot_range[0]:plot_range[1]]\n",
    "    plot_rul(expected, predicted)\n",
    "    \n",
    "def numbers_list_to_string(num_list):\n",
    "    return \" \".join([str(x) for x in num_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPConfigParams:\n",
    "    def __init__(self, layer_sizes=(), activation='tanh', dropout=0.0):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "def train_evaluate_mlp(x_train, y_train, x_test, y_test, num_trials, \n",
    "                       mlp_config_params, results_path, epochs, batch_size, results_file=None):\n",
    "    mse_vals = []\n",
    "    rmse_vals = []\n",
    "    cmapss_vals = []\n",
    "    \n",
    "    input_dim = x_train.shape[1]\n",
    "    \n",
    "    for trial_num in range(num_trials):\n",
    "        # Create results path for current split\n",
    "        results_path_crr_split = os.path.join(results_path, \"split_{}\".format(trial_num))\n",
    "        if not os.path.exists(results_path_crr_split):\n",
    "            os.makedirs(results_path_crr_split)\n",
    "        \n",
    "        \n",
    "        # Train-validation split\n",
    "        x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train, \n",
    "                                                                                  y_train, \n",
    "                                                                                  test_size=0.1, \n",
    "                                                                                  random_state=trial_num)\n",
    "        \n",
    "        # Standardization\n",
    "        scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(x_train_split)\n",
    "        x_val_scaled = scaler.transform(x_val_split)\n",
    "        save_object(scaler, scaler_file)\n",
    "        \n",
    "        weights_file = os.path.join(results_path, 'mlp_initial_weights.h5')\n",
    "        model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "        \n",
    "        # Initialize weights only in first split\n",
    "        if trial_num == 0:\n",
    "            model = create_mlp_model(input_dim, \n",
    "                                     hidden_layer_sizes=mlp_config_params.layer_sizes, \n",
    "                                     activation=mlp_config_params.activation,\n",
    "                                     dropout=mlp_config_params.dropout,\n",
    "                                     output_weights_file=weights_file)\n",
    "        else:\n",
    "            model = create_mlp_model(input_dim, \n",
    "                                     hidden_layer_sizes=mlp_config_params.layer_sizes, \n",
    "                                     activation=mlp_config_params.activation,\n",
    "                                     dropout=mlp_config_params.dropout)\n",
    "        model.summary()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "        mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=2, \n",
    "                             save_best_only=True)\n",
    "        \n",
    "        # Train model\n",
    "        history = train_model_existing_weights(model, weights_file, \n",
    "                                               x_train_scaled, y_train_split, \n",
    "                                               x_val_scaled, y_val_split, \n",
    "                                               batch_size=batch_size, \n",
    "                                               epochs=epochs,\n",
    "                                               callbacks=[es, mc])\n",
    "\n",
    "        history_file = os.path.join(results_path_crr_split, f\"history_{trial_num}.pkl\")\n",
    "        plot_loss_curves(history.history)\n",
    "        save_history(history, history_file)\n",
    "        \n",
    "        # Performance evaluation\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "        loaded_model = load_model(model_path)\n",
    "        predictions_test = loaded_model.predict(x_test_scaled).flatten()\n",
    "        mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_test, y_test)\n",
    "        \n",
    "        mse_vals.append(mse)\n",
    "        rmse_vals.append(rmse)\n",
    "        cmapss_vals.append(cmapss_score)\n",
    "        \n",
    "    mse_mean = np.mean(mse_vals)\n",
    "    mse_std = np.std(mse_vals)\n",
    "    rmse_mean = np.mean(rmse_vals)\n",
    "    rmse_std = np.std(rmse_vals)\n",
    "    cmapss_mean = np.mean(cmapss_vals)\n",
    "    cmapss_std = np.std(cmapss_vals)\n",
    "    \n",
    "    if results_file is not None:\n",
    "        with open(results_file, \"a\") as file:\n",
    "            line_to_write = f\"{numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)},\"\n",
    "            line_to_write += f\"{numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean},\"\n",
    "            line_to_write += f\"{rmse_std}, {cmapss_mean}, {cmapss_std}\\n\"\n",
    "            file.write(line_to_write)\n",
    "\n",
    "    return mse_vals, rmse_vals, cmapss_vals\n",
    "\n",
    "def train_evaluate_mlp_sample_weights(x_train, y_train, \n",
    "                                      x_test, y_test, \n",
    "                                      sample_weights,\n",
    "                                      validation_set_size,\n",
    "                                      mlp_config_params, \n",
    "                                      results_path, \n",
    "                                      epochs, batch_size):\n",
    "    \n",
    "    # Train-validation split for early stopping\n",
    "    x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train, \n",
    "                                                                              y_train, \n",
    "                                                                              test_size=validation_set_size, \n",
    "                                                                              random_state=seed)\n",
    "    train_weights = weights.loc[x_train_split.index]\n",
    "    val_weights = weights.loc[x_val_split.index]\n",
    "\n",
    "    # Standardization\n",
    "    scaler_file = os.path.join(results_path, 'scaler.pkl')\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train_split)\n",
    "    x_val_scaled = scaler.transform(x_val_split)\n",
    "    input_dim = x_train_scaled.shape[1]\n",
    "    save_object(scaler, scaler_file)\n",
    "\n",
    "    # Create model\n",
    "    weights_file = os.path.join(results_path, 'mlp_initial_weights.h5')\n",
    "    model_path = os.path.join(results_path, 'mlp_model_trained.h5')\n",
    "\n",
    "    model = create_mlp_model(input_dim, \n",
    "                             hidden_layer_sizes=mlp_config_params.layer_sizes, \n",
    "                             activation=mlp_config_params.activation,\n",
    "                             dropout=mlp_config_params.dropout,\n",
    "                             output_weights_file=weights_file)\n",
    "    model.summary()\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "    mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=1, \n",
    "                         save_best_only=True)\n",
    "\n",
    "    # Train model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.load_weights(weights_file)\n",
    "    history = model.fit(x_train_scaled, y_train_split,\n",
    "                        validation_data=(x_val_scaled, y_val_split, val_weights),\n",
    "                        sample_weight=train_weights,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1,\n",
    "                        callbacks=[es, mc])\n",
    "\n",
    "    history_file = os.path.join(results_path, \"history.pkl\")\n",
    "    plot_loss_curves(history.history)\n",
    "    save_history(history, history_file)\n",
    "\n",
    "    # Performance evaluation\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    loaded_model = load_model(model_path)\n",
    "    predictions_test = loaded_model.predict(x_test_scaled).flatten()\n",
    "    mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_test, y_test)\n",
    "    return mse, rmse, cmapss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation time (sec):  3.53125\n",
      "Train set shape: (5263447, 47)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()  \n",
    "train_set, test_set, columns = load_dataset(filename)\n",
    "print(\"Operation time (sec): \" , (time.process_time() - start_time))\n",
    "print(\"Train set shape: \" + str(train_set.shape))\n",
    "\n",
    "columns_aux = columns[0] \n",
    "columns_health_params = columns[1] \n",
    "columns_sensor_measurements = columns[2] \n",
    "columns_virtual_sensors = columns[3]\n",
    "columns_operating_conditions = columns[4] \n",
    "target_col = columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = columns_operating_conditions + columns_sensor_measurements\n",
    "train_set_feature_selection = train_set[selected_columns]\n",
    "test_set_feature_selection = test_set[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select N samples from training and test sets\n",
    "N = 10 ** 5\n",
    "train_sample = train_set_feature_selection.sample(n=N, random_state=seed)\n",
    "test_sample = test_set_feature_selection.sample(n=N, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classifier target column\n",
    "train_sample['is_test'] = 0\n",
    "test_sample['is_test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "dataset_sample = pd.concat([train_sample, test_sample], ignore_index=True, axis=0)\n",
    "labels = dataset_sample['is_test'].values\n",
    "dataset_sample = dataset_sample.drop('is_test', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(dataset_sample, \n",
    "                                                                            labels, \n",
    "                                                                            test_size=0.3, \n",
    "                                                                            random_state=seed,\n",
    "                                                                            stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=50; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=50; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=50; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=100; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=100; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=200; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=200; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=200; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=300; total time=   9.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=300; total time=   9.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=auto, n_estimators=300; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=50; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   9.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   9.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=50; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   9.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=100; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=200; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=200; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=200; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=300; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=300; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=auto, n_estimators=300; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   8.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=  12.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=  10.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   9.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=  14.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=  13.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=  20.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=50; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=50; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=50; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   8.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=100; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=200; total time=  11.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=300; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=300; total time=  16.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=auto, n_estimators=300; total time=  16.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=  10.7s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=  11.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200; total time=  10.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300; total time=  16.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300; total time=  16.2s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  10.8s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  11.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=200; total time=  11.1s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=300; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=300; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=4, max_features=log2, n_estimators=300; total time=  16.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=100; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=200; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=300; total time=  18.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=300; total time=  18.8s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=auto, n_estimators=300; total time=  18.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300; total time=  19.0s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300; total time=  18.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=  12.4s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=  12.6s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=200; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=300; total time=  18.8s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=300; total time=  18.7s\n",
      "[CV] END criterion=gini, max_depth=5, max_features=log2, n_estimators=300; total time=  19.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=50; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=50; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=50; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=200; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=200; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=200; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=300; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=300; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=auto, n_estimators=300; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=50; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=50; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=  12.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=50; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=100; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=200; total time=  11.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=200; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=200; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=300; total time=  16.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=300; total time=  16.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=auto, n_estimators=300; total time=  16.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=   3.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  11.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  11.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=  11.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=  17.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=  17.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=  17.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=  12.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=  13.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=  13.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=  13.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=  19.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=  20.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=  20.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=50; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=50; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=50; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=100; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=  17.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=  17.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=200; total time=  17.0s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=300; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=300; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=auto, n_estimators=300; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=  14.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=  14.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200; total time=  14.6s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300; total time=  21.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=  14.8s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=  14.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=200; total time=  14.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=300; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=300; total time=  21.7s\n",
      "[CV] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=300; total time=  21.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=50; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   9.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   8.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=100; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=  17.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=  17.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=200; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=300; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=300; total time=  26.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=auto, n_estimators=300; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   8.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   9.2s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=  17.4s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=  17.4s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300; total time=  26.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300; total time=  26.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   8.9s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=  17.5s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=  17.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=200; total time=  17.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=300; total time=  26.3s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=300; total time=  26.0s\n",
      "[CV] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=300; total time=  26.2s\n",
      "GridSearchCV took 2755.95 seconds for 15 candidate parameter settings.\n",
      "{'mean_fit_time': array([ 2.32665984,  3.39678049,  6.33845806,  9.02238417,  1.64823103,\n",
      "        3.1061755 ,  6.17950217,  8.88955967,  1.63821872,  3.08765984,\n",
      "        6.13155619,  8.91011786,  2.23328598,  4.2347757 ,  8.39853064,\n",
      "       12.40985004,  2.19696999,  4.32243562,  8.37270331, 12.39484056,\n",
      "        2.24981872,  4.84239467,  9.59595784, 15.70588605,  4.80074461,\n",
      "        7.68571448, 14.39552498, 15.88321368,  2.82712857,  5.28477256,\n",
      "       10.74028079, 16.19082729,  2.86752041,  5.44660695, 10.77441001,\n",
      "       15.77212715,  3.46161087,  6.43143924, 12.55256756, 18.5985345 ,\n",
      "        3.4256467 ,  6.31742716, 12.76079194, 18.86146434,  3.30114444,\n",
      "        6.28903254, 12.46688374, 18.66766389,  2.12244821,  3.99351835,\n",
      "        7.77665385, 11.47462304,  2.1041971 ,  3.94012451,  7.82116612,\n",
      "       11.46962595,  2.15882476,  4.13694827,  7.78864614, 11.68275205,\n",
      "        2.94075759,  5.58326006, 11.26254447, 16.40979067,  3.04828215,\n",
      "        5.70842727, 11.07947469, 17.10602403,  2.94404904,  8.94157298,\n",
      "       13.36168718, 19.83402665,  4.41333675,  8.47552919, 16.94441605,\n",
      "       24.74759777,  3.87850753,  7.29355788, 14.31921307, 21.26030993,\n",
      "        3.80021111,  7.25675639, 14.38195205, 21.30047615,  4.54702202,\n",
      "        8.81507738, 17.18359415, 25.95942807,  4.51777506,  8.85800966,\n",
      "       17.27620276, 25.82424275,  4.50997257,  8.87962437, 17.19421951,\n",
      "       25.88397638]), 'std_fit_time': array([0.68812594, 0.08534175, 0.1836815 , 0.09461138, 0.01491981,\n",
      "       0.0206593 , 0.1600782 , 0.05061493, 0.04291152, 0.02622618,\n",
      "       0.19072806, 0.03735175, 0.02808771, 0.01740322, 0.155664  ,\n",
      "       0.14719084, 0.03150617, 0.12321003, 0.11267465, 0.14970448,\n",
      "       0.0090257 , 0.09772074, 0.5550011 , 2.78958558, 0.84392126,\n",
      "       0.63705582, 2.43056232, 0.21703647, 0.01686503, 0.07059527,\n",
      "       0.14157177, 0.395607  , 0.09929973, 0.0675602 , 0.13206303,\n",
      "       0.10476081, 0.20334197, 0.04336377, 0.19902205, 0.05159281,\n",
      "       0.22467874, 0.03410102, 0.26899847, 0.2646033 , 0.03082335,\n",
      "       0.05691536, 0.21444032, 0.28112521, 0.06885905, 0.01456941,\n",
      "       0.0518652 , 0.16053897, 0.03348758, 0.0224467 , 0.14671112,\n",
      "       0.09819094, 0.11143491, 0.24454662, 0.04313943, 0.2327664 ,\n",
      "       0.03323167, 0.00891359, 0.23171967, 0.18236534, 0.0999748 ,\n",
      "       0.04044742, 0.01760398, 0.29708082, 0.02865768, 2.47011598,\n",
      "       0.10789779, 0.1736656 , 0.04072938, 0.09519631, 0.14059014,\n",
      "       1.5144225 , 0.15715364, 0.02177962, 0.06447585, 0.1373364 ,\n",
      "       0.03596318, 0.08885396, 0.15917127, 0.14428603, 0.04357874,\n",
      "       0.21598922, 0.1054987 , 0.25044733, 0.01926155, 0.17966571,\n",
      "       0.06802247, 0.20574671, 0.02189575, 0.16136596, 0.10147919,\n",
      "       0.1299741 ]), 'mean_score_time': array([0.0719862 , 0.13887262, 0.27003781, 0.31981977, 0.0689489 ,\n",
      "       0.11809516, 0.21998843, 0.32173395, 0.06756544, 0.11577956,\n",
      "       0.21470539, 0.31816697, 0.06735078, 0.12524931, 0.22719383,\n",
      "       0.33414952, 0.06598743, 0.12366947, 0.2307806 , 0.35600066,\n",
      "       0.07037894, 0.1417164 , 0.30248849, 0.39529983, 0.11884586,\n",
      "       0.17479444, 0.29863   , 0.35707116, 0.07767995, 0.13822238,\n",
      "       0.2411894 , 0.37047259, 0.07669409, 0.13999168, 0.25523909,\n",
      "       0.36342303, 0.08119901, 0.14295014, 0.26962837, 0.38349668,\n",
      "       0.07879972, 0.14412975, 0.26885287, 0.37919871, 0.08064795,\n",
      "       0.14484413, 0.26932939, 0.37997325, 0.06880546, 0.11966546,\n",
      "       0.22193766, 0.31770237, 0.0715251 , 0.12194125, 0.22015373,\n",
      "       0.32768631, 0.0662388 , 0.12119309, 0.22299353, 0.31598624,\n",
      "       0.07066957, 0.12905105, 0.23487027, 0.33713214, 0.07901732,\n",
      "       0.12602552, 0.23589468, 0.34170747, 0.07598678, 0.20266326,\n",
      "       0.25035365, 0.36815739, 0.07966479, 0.14456129, 0.27874724,\n",
      "       0.3862714 , 0.07274278, 0.13384589, 0.25286961, 0.36181339,\n",
      "       0.07348736, 0.13779855, 0.2469209 , 0.35812902, 0.08007352,\n",
      "       0.14152257, 0.261518  , 0.38142037, 0.07849495, 0.14470236,\n",
      "       0.26324685, 0.38192685, 0.08073187, 0.14291771, 0.26298277,\n",
      "       0.38425946]), 'std_score_time': array([4.34168938e-03, 2.80373678e-02, 7.28927368e-02, 2.66406931e-03,\n",
      "       1.61182990e-04, 3.06424536e-03, 2.72646446e-03, 5.96741176e-04,\n",
      "       7.07418446e-04, 3.26406171e-05, 6.08102269e-03, 1.03400734e-02,\n",
      "       2.00487575e-03, 4.43680429e-03, 6.43549142e-03, 2.62975318e-03,\n",
      "       2.70449272e-03, 1.02070734e-02, 6.60652699e-03, 1.30664396e-02,\n",
      "       5.55766250e-03, 8.40055542e-03, 3.78682563e-02, 2.48075470e-02,\n",
      "       2.81367462e-02, 2.72737574e-02, 5.79052532e-02, 4.95449870e-03,\n",
      "       1.23620473e-03, 3.36587776e-03, 6.91063728e-03, 8.40625621e-03,\n",
      "       3.67551419e-03, 5.69024173e-03, 7.52100403e-03, 4.78790575e-03,\n",
      "       1.50744139e-03, 3.75891580e-03, 1.21305431e-02, 2.66455701e-03,\n",
      "       4.42662511e-03, 3.65037984e-03, 4.10018407e-03, 5.58833834e-03,\n",
      "       1.16549451e-03, 2.89438150e-03, 1.24583683e-03, 5.90315338e-03,\n",
      "       7.96757936e-04, 1.90430981e-03, 6.54808483e-03, 4.06871502e-03,\n",
      "       1.45250051e-03, 1.41988096e-03, 6.96231466e-04, 1.21666414e-03,\n",
      "       2.05510348e-03, 1.36531111e-03, 6.16368510e-03, 2.43754064e-03,\n",
      "       2.63031837e-03, 4.15338563e-03, 3.04847606e-03, 2.90268462e-03,\n",
      "       8.56534127e-03, 8.89911526e-04, 6.54395489e-03, 8.70394842e-03,\n",
      "       4.59539294e-03, 6.02562462e-02, 1.01817988e-03, 2.44720505e-03,\n",
      "       2.48300585e-04, 7.05444786e-04, 2.90506066e-03, 1.39651428e-02,\n",
      "       2.06141730e-03, 1.68418345e-03, 8.15880947e-03, 4.29542740e-03,\n",
      "       2.59824875e-03, 5.94368703e-03, 2.27765242e-03, 6.89328799e-03,\n",
      "       7.35844002e-04, 1.74482594e-03, 5.91156048e-03, 7.65694286e-03,\n",
      "       1.12786523e-03, 1.10158009e-03, 3.78237807e-03, 4.90198454e-03,\n",
      "       1.82080768e-03, 3.91561038e-03, 2.50081254e-03, 3.47319966e-03]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
      "                   300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
      "                   200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
      "                   100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
      "                   50, 100, 200, 300, 50, 100, 200, 300, 50, 100, 200,\n",
      "                   300, 50, 100, 200, 300, 50, 100, 200, 300, 50, 100,\n",
      "                   200, 300, 50, 100, 200, 300, 50, 100, 200, 300, 50,\n",
      "                   100, 200, 300, 50, 100, 200, 300, 50, 100, 200, 300,\n",
      "                   50, 100, 200, 300, 50, 100, 200, 300],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 300}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 300}], 'split0_test_score': array([0.59363147, 0.59367433, 0.59358862, 0.59333148, 0.59378147,\n",
      "       0.59341719, 0.59354576, 0.59382433, 0.5941029 , 0.5939529 ,\n",
      "       0.59361005, 0.59397433, 0.60190284, 0.6014957 , 0.59808859,\n",
      "       0.59967429, 0.60033857, 0.59956715, 0.59858144, 0.5986243 ,\n",
      "       0.60110999, 0.59871001, 0.59937429, 0.59868858, 0.61576703,\n",
      "       0.61298134, 0.6154456 , 0.61471704, 0.61156706, 0.61495275,\n",
      "       0.61349562, 0.61703131, 0.61351705, 0.61411704, 0.61565989,\n",
      "       0.61313133, 0.62498125, 0.62217413, 0.62390983, 0.6238884 ,\n",
      "       0.62678124, 0.62273127, 0.62510982, 0.62322412, 0.6253241 ,\n",
      "       0.62573124, 0.62410268, 0.62395269, 0.59592431, 0.59371719,\n",
      "       0.59348148, 0.59352433, 0.59444575, 0.59371719, 0.59322433,\n",
      "       0.59318148, 0.59288148, 0.59316005, 0.5936529 , 0.59356719,\n",
      "       0.59766002, 0.59963143, 0.59851715, 0.59988857, 0.59639574,\n",
      "       0.59759573, 0.59892429, 0.59811001, 0.59856001, 0.60153856,\n",
      "       0.60080999, 0.59744573, 0.61070992, 0.60723852, 0.61199563,\n",
      "       0.61130992, 0.61265991, 0.60989564, 0.61295991, 0.60878137,\n",
      "       0.60848137, 0.61201706, 0.61100992, 0.61180277, 0.62101699,\n",
      "       0.62174556, 0.62110271, 0.6220027 , 0.61938843, 0.62069557,\n",
      "       0.62088842, 0.62238841, 0.62240984, 0.62189556, 0.62133842,\n",
      "       0.62217413]), 'split1_test_score': array([0.59712431, 0.59740288, 0.59740288, 0.59733859, 0.59693145,\n",
      "       0.59727431, 0.59738145, 0.59721002, 0.59736002, 0.59731716,\n",
      "       0.59733859, 0.59748859, 0.60809566, 0.60785994, 0.60796709,\n",
      "       0.60695995, 0.60773137, 0.60633853, 0.60710995, 0.6082028 ,\n",
      "       0.6063171 , 0.60565282, 0.60648853, 0.60665995, 0.61546703,\n",
      "       0.61617417, 0.61368847, 0.61621703, 0.61591703, 0.61872415,\n",
      "       0.61426704, 0.61756702, 0.61550989, 0.61165277, 0.61730988,\n",
      "       0.61458847, 0.62523839, 0.62695266, 0.62611696, 0.62729552,\n",
      "       0.62697409, 0.62866694, 0.62712409, 0.62609553, 0.62933122,\n",
      "       0.6285598 , 0.62716695, 0.62731695, 0.59697431, 0.59723145,\n",
      "       0.59753145, 0.59740288, 0.59746716, 0.59718859, 0.59729573,\n",
      "       0.59731716, 0.59706002, 0.59706002, 0.59716716, 0.59733859,\n",
      "       0.60425997, 0.60533139, 0.60453854, 0.60573853, 0.60528853,\n",
      "       0.60670281, 0.60614567, 0.60539568, 0.60597424, 0.60365997,\n",
      "       0.60648853, 0.60539568, 0.61085992, 0.61246705, 0.61246705,\n",
      "       0.61184563, 0.61238134, 0.61295991, 0.61280991, 0.61278848,\n",
      "       0.61306705, 0.61377419, 0.61223134, 0.61255277, 0.62335269,\n",
      "       0.62521696, 0.6246384 , 0.62493839, 0.62624553, 0.62513125,\n",
      "       0.62459554, 0.62500268, 0.62478839, 0.62435983, 0.62410268,\n",
      "       0.6243384 ]), 'split2_test_score': array([0.59032272, 0.5909013 , 0.59062272, 0.59036558, 0.590237  ,\n",
      "       0.59117987, 0.59004414, 0.59045129, 0.59032272, 0.59102987,\n",
      "       0.59019415, 0.58974414, 0.59679424, 0.60003   , 0.60082287,\n",
      "       0.59925856, 0.59732996, 0.59679424, 0.59925856, 0.59951571,\n",
      "       0.59664424, 0.59700853, 0.59773711, 0.59900141, 0.61140873,\n",
      "       0.60825869, 0.60913727, 0.6110873 , 0.60952299, 0.61005872,\n",
      "       0.60864441, 0.60924442, 0.60956585, 0.60753011, 0.6088587 ,\n",
      "       0.61020872, 0.62148031, 0.62210174, 0.62062315, 0.62062315,\n",
      "       0.61843741, 0.62028029, 0.62002314, 0.61950885, 0.62124459,\n",
      "       0.62253032, 0.62045172, 0.61985171, 0.59006557, 0.58991557,\n",
      "       0.59010843, 0.59019415, 0.59057987, 0.59002271, 0.59015129,\n",
      "       0.59017272, 0.59010843, 0.59021557, 0.59017272, 0.59002271,\n",
      "       0.59672995, 0.59636566, 0.5992157 , 0.59705139, 0.60043715,\n",
      "       0.59852998, 0.59848712, 0.59865855, 0.59612994, 0.59932285,\n",
      "       0.59887284, 0.59812283, 0.60350148, 0.60444435, 0.60393006,\n",
      "       0.60540865, 0.60311576, 0.60495864, 0.60755154, 0.60549436,\n",
      "       0.6062658 , 0.60260147, 0.60607294, 0.60600866, 0.62064458,\n",
      "       0.6179874 , 0.62002314, 0.62025886, 0.61779454, 0.61695881,\n",
      "       0.61901599, 0.62002314, 0.61830883, 0.61942313, 0.61959457,\n",
      "       0.61903741]), 'mean_test_score': array([0.59369283, 0.59399284, 0.59387141, 0.59367855, 0.59364998,\n",
      "       0.59395712, 0.59365712, 0.59382855, 0.59392855, 0.59409998,\n",
      "       0.59371426, 0.59373569, 0.60226425, 0.60312855, 0.60229285,\n",
      "       0.60196427, 0.60179997, 0.60089997, 0.60164998, 0.60211427,\n",
      "       0.60135711, 0.60045712, 0.60119998, 0.60144998, 0.61421427,\n",
      "       0.6124714 , 0.61275712, 0.61400712, 0.61233569, 0.61457854,\n",
      "       0.61213569, 0.61461425, 0.61286426, 0.61109997, 0.61394282,\n",
      "       0.61264284, 0.62389998, 0.62374285, 0.62354998, 0.62393569,\n",
      "       0.62406425, 0.62389283, 0.62408569, 0.62294283, 0.62529997,\n",
      "       0.62560712, 0.62390712, 0.62370712, 0.5943214 , 0.5936214 ,\n",
      "       0.59370712, 0.59370712, 0.59416426, 0.59364283, 0.59355712,\n",
      "       0.59355712, 0.59334998, 0.59347855, 0.59366426, 0.59364283,\n",
      "       0.59954998, 0.60044283, 0.60075713, 0.60089283, 0.60070714,\n",
      "       0.60094284, 0.6011857 , 0.60072141, 0.6002214 , 0.60150713,\n",
      "       0.60205712, 0.60032141, 0.60835711, 0.60804997, 0.60946425,\n",
      "       0.6095214 , 0.60938567, 0.6092714 , 0.61110712, 0.6090214 ,\n",
      "       0.60927141, 0.60946424, 0.6097714 , 0.6101214 , 0.62167142,\n",
      "       0.62164997, 0.62192142, 0.62239998, 0.62114283, 0.62092854,\n",
      "       0.62149998, 0.62247141, 0.62183569, 0.62189284, 0.62167856,\n",
      "       0.62184998]), 'std_test_score': array([0.00277708, 0.0026638 , 0.0027752 , 0.00285728, 0.00273458,\n",
      "       0.00251716, 0.00299648, 0.00275924, 0.00287561, 0.00256888,\n",
      "       0.00291764, 0.00316616, 0.00462086, 0.00339869, 0.00416468,\n",
      "       0.00353656, 0.00437029, 0.0040088 , 0.00387066, 0.0043206 ,\n",
      "       0.00395279, 0.003739  , 0.00379883, 0.00368622, 0.00198759,\n",
      "       0.00325154, 0.00265824, 0.00215353, 0.00266634, 0.00354753,\n",
      "       0.00248871, 0.00380334, 0.00247015, 0.00271737, 0.00365758,\n",
      "       0.00182108, 0.00171419, 0.00226988, 0.00225722, 0.00272419,\n",
      "       0.00397956, 0.00352097, 0.00298803, 0.00269635, 0.0033014 ,\n",
      "       0.00246309, 0.00274497, 0.00305261, 0.0030397 , 0.00298746,\n",
      "       0.00303463, 0.00294579, 0.00281876, 0.00292593, 0.00292618,\n",
      "       0.00292878, 0.00285724, 0.00280329, 0.00285548, 0.00298717,\n",
      "       0.00335204, 0.00370494, 0.00268902, 0.00361691, 0.00363548,\n",
      "       0.00409073, 0.00351177, 0.00331278, 0.0041871 , 0.00177076,\n",
      "       0.00323173, 0.00359868, 0.00343399, 0.00332514, 0.00391799,\n",
      "       0.00291637, 0.00443495, 0.00329619, 0.00251492, 0.00298264,\n",
      "       0.00283224, 0.00490545, 0.00266232, 0.00292422, 0.00119852,\n",
      "       0.00295223, 0.0019711 , 0.00193096, 0.00366635, 0.00334045,\n",
      "       0.00231853, 0.00203373, 0.00267624, 0.0020154 , 0.00185608,\n",
      "       0.00217622]), 'rank_test_score': array([85, 76, 79, 86, 89, 77, 88, 80, 78, 75, 82, 81, 51, 49, 50, 54, 55,\n",
      "       63, 56, 52, 59, 68, 60, 58, 27, 33, 31, 28, 34, 26, 35, 25, 30, 37,\n",
      "       29, 32,  7,  9, 11,  5,  4,  8,  3, 12,  2,  1,  6, 10, 73, 92, 84,\n",
      "       83, 74, 90, 94, 93, 96, 95, 87, 90, 72, 69, 65, 64, 67, 62, 61, 66,\n",
      "       71, 57, 53, 70, 47, 48, 41, 40, 43, 45, 36, 46, 44, 42, 39, 38, 20,\n",
      "       21, 15, 14, 23, 24, 22, 13, 18, 16, 19, 17])}\n"
     ]
    }
   ],
   "source": [
    "# Grid search classfier hyperparams\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [2, 3, 4, 5],\n",
    "              \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "              \"n_estimators\": [50, 100, 200, 300],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf = RandomForestClassifier(verbose=0, n_jobs=4)\n",
    "\n",
    "grid_search = GridSearchCV(clf, cv=3, param_grid=param_grid, verbose=2)\n",
    "start = time.time()\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time.time() - start, len(grid_search.cv_results_)))\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: grid_search.pkl\n"
     ]
    }
   ],
   "source": [
    "save_object(grid_search, \"grid_search.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5, n_jobs=4)\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(dataset_sample, \n",
    "                                                                            labels, \n",
    "                                                                            test_size=0.3, \n",
    "                                                                            random_state=seed,\n",
    "                                                                            stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_jobs=4)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(X_test_split)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.6840939938222222\n"
     ]
    }
   ],
   "source": [
    "print('ROC-AUC:', roc_auc_score(y_test_split, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = clf.predict_proba(dataset_sample[:500])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Computed sample weight', ylabel='# Samples'>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = (1./predictions_train) - 1. \n",
    "weights /= np.mean(weights) # we do this to re-normalize the computed log-loss\n",
    "plt.xlabel('Computed sample weight')\n",
    "plt.ylabel('# Samples')\n",
    "sns.histplot(weights, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: random_forest_2.pkl\n"
     ]
    }
   ],
   "source": [
    "save_object(clf, \"random_forest_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "y_train = train_set['RUL']\n",
    "x_train = train_set.drop(['RUL'], axis=1)\n",
    "\n",
    "y_test = test_set['RUL']\n",
    "x_test = test_set.drop(['RUL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsf = load_object(\"random_forest_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = columns_operating_conditions + columns_sensor_measurements\n",
    "selected_columns_with_unit = selected_columns + ['unit']\n",
    "x_train = x_train[selected_columns]\n",
    "x_test = x_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = clsf.predict_proba(x_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min(predicted_class[predicted_class != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class[predicted_class == 0] = min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1./predicted_class) - 1. \n",
    "weights /= np.mean(weights) # we do this to re-normalize the computed log-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Computed sample weight', ylabel='# Samples'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Computed sample weight')\n",
    "plt.ylabel('# Samples')\n",
    "sns.histplot(weights[:1000], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: ./experiment_set_16\\result_weights_cls_2\\scaler.pkl\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               4864      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 235,137\n",
      "Trainable params: 235,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "9246/9253 [============================>.] - ETA: 0s - loss: 158.1380\n",
      "Epoch 00001: val_loss improved from inf to 58.73213, saving model to ./experiment_set_16\\result_weights_cls_2\\mlp_model_trained.h5\n",
      "9253/9253 [==============================] - 39s 4ms/step - loss: 158.0741 - val_loss: 58.7321\n",
      "Epoch 2/60\n",
      "9252/9253 [============================>.] - ETA: 0s - loss: 81.3533\n",
      "Epoch 00002: val_loss did not improve from 58.73213\n",
      "9253/9253 [==============================] - 38s 4ms/step - loss: 81.3533 - val_loss: 64.5174\n",
      "Epoch 3/60\n",
      "9236/9253 [============================>.] - ETA: 0s - loss: 72.1732\n",
      "Epoch 00003: val_loss improved from 58.73213 to 57.10441, saving model to ./experiment_set_16\\result_weights_cls_2\\mlp_model_trained.h5\n",
      "9253/9253 [==============================] - 39s 4ms/step - loss: 72.1484 - val_loss: 57.1044\n",
      "Epoch 4/60\n",
      "9253/9253 [==============================] - ETA: 0s - loss: 67.4986\n",
      "Epoch 00004: val_loss did not improve from 57.10441\n",
      "9253/9253 [==============================] - 39s 4ms/step - loss: 67.4986 - val_loss: 62.1694\n",
      "Epoch 5/60\n",
      "9240/9253 [============================>.] - ETA: 0s - loss: 69.9514\n",
      "Epoch 00005: val_loss did not improve from 57.10441\n",
      "9253/9253 [==============================] - 39s 4ms/step - loss: 69.9455 - val_loss: 70.2089\n",
      "Epoch 6/60\n",
      "2045/9253 [=====>........................] - ETA: 27s - loss: 69.0585"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-153726f6a593>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m train_evaluate_mlp_sample_weights(\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-5d812b305e1e>\u001b[0m in \u001b[0;36mtrain_evaluate_mlp_sample_weights\u001b[1;34m(x_train, y_train, x_test, y_test, sample_weights, validation_set_size, mlp_config_params, results_path, epochs, batch_size)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     history = model.fit(x_train_scaled, y_train_split,\n\u001b[0m\u001b[0;32m    138\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train single MLP\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 512\n",
    "mlp_config_params = MLPConfigParams(layer_sizes=[256, 256, 512, 64], activation='tanh', dropout=0.0)\n",
    "\n",
    "results_path = os.path.join(output_path, f\"result_weights_cls_2\")\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "train_evaluate_mlp_sample_weights(\n",
    "        x_train, y_train, \n",
    "        x_test, y_test,\n",
    "        weights,\n",
    "        0.1,\n",
    "        mlp_config_params, \n",
    "        results_path, \n",
    "        EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18008912871947588206\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1375624382837516978\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3175428916\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3664379433591097905\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7332387147933622418\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-keras-gpu",
   "language": "python",
   "name": "tf-keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
