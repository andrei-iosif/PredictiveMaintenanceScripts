{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "seed = 0\n",
    "os.environ['PYTHONHASSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add modules path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_reader import DataReader\n",
    "from src.feature_extraction import get_principal_components, dimensionality_reduction\n",
    "from src.metrics import compute_evaluation_metrics\n",
    "from src.model_evaluation import evaluate_mlp, evaluate_mlp_multiple_splits\n",
    "from src.plotting import plot_loss_curves\n",
    "from src.save_object import load_object\n",
    "from src.training import MLPConfigParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and output paths\n",
    "filename = '../data/N-CMAPSS_DS02-006.h5'\n",
    "output_path = '../results/experiment_set_18'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-4657cbf55546>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-4657cbf55546>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    results_file=None)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train_evaluate_mlp_pca(x_train, y_train,\n",
    "                           x_test, y_test,\n",
    "                           num_trials,\n",
    "                           mlp_config_params,\n",
    "                           results_path,\n",
    "                           epochs, batch_size, results_file=None):\n",
    "    mse_vals = []\n",
    "    rmse_vals = []\n",
    "    cmapss_vals = []\n",
    "    \n",
    "    for trial_num in range(num_trials):\n",
    "        # Train-validation split for early stopping\n",
    "        x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train,\n",
    "                                                                                  y_train,\n",
    "                                                                                  test_size=0.1,\n",
    "                                                                                  random_state=trial_num)\n",
    "        # Create output path\n",
    "        results_path_crr_split = os.path.join(results_path, f\"split_{trial_num}\")\n",
    "        if not os.path.exists(results_path_crr_split):\n",
    "            os.makedirs(results_path_crr_split)\n",
    "    \n",
    "        # Standardization\n",
    "        scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(x_train_split)\n",
    "        x_val_scaled = scaler.transform(x_val_split)\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "        save_object(scaler, scaler_file)\n",
    "    \n",
    "        # PCA\n",
    "        pca = get_principal_components(x_train_scaled, debug=False)\n",
    "        pca_file = os.path.join(results_path_crr_split, 'pca.pkl')\n",
    "        save_object(pca, pca_file)\n",
    "    \n",
    "        x_train_final = dimensionality_reduction(x_train_scaled, pca)\n",
    "        x_val_final = dimensionality_reduction(x_val_scaled, pca)\n",
    "        x_test_final = dimensionality_reduction(x_test_scaled, pca)\n",
    "        input_dim = x_train_final.shape[1]\n",
    "    \n",
    "        # Create model\n",
    "        weights_file = os.path.join(results_path, 'mlp_initial_weights.h5')\n",
    "        model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "    \n",
    "        # Save initial weights\n",
    "        if trial_num == 0:\n",
    "            model = create_mlp_model(input_dim,\n",
    "                                     hidden_layer_sizes=mlp_config_params.layer_sizes,\n",
    "                                     activation=mlp_config_params.activation,\n",
    "                                     dropout=mlp_config_params.dropout,\n",
    "                                     output_weights_file=weights_file)\n",
    "        else:\n",
    "            model = create_mlp_model(input_dim,\n",
    "                                     hidden_layer_sizes=mlp_config_params.layer_sizes,\n",
    "                                     activation=mlp_config_params.activation,\n",
    "                                     dropout=mlp_config_params.dropout)\n",
    "        model.summary()\n",
    "    \n",
    "        # Train model\n",
    "        history = train_mlp(model,\n",
    "                            x_train_scaled, y_train_split,\n",
    "                            x_val_scaled, y_val_split,\n",
    "                            weights_file=weights_file,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            callbacks=get_callbacks(model_path))\n",
    "    \n",
    "        history_file = os.path.join(results_path_crr_split, f\"history_{trial_num}.pkl\")\n",
    "        plot_loss_curves(history.history)\n",
    "        save_object(history.history, history_file)\n",
    "    \n",
    "        # Performance evaluation\n",
    "        loaded_model = load_model(model_path)\n",
    "        predictions_test = loaded_model.predict(x_test_final).flatten()\n",
    "        mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_test, y_test)\n",
    "    \n",
    "        mse_vals.append(mse)\n",
    "        rmse_vals.append(rmse)\n",
    "        cmapss_vals.append(cmapss_score)\n",
    "    \n",
    "    mse_mean = np.mean(mse_vals)\n",
    "    mse_std = np.std(mse_vals)\n",
    "    rmse_mean = np.mean(rmse_vals)\n",
    "    rmse_std = np.std(rmse_vals)\n",
    "    cmapss_mean = np.mean(cmapss_vals)\n",
    "    cmapss_std = np.std(cmapss_vals)\n",
    "\n",
    "    if results_file is not None:\n",
    "        with open(results_file, \"a\") as file:\n",
    "            line_to_write = f\"{numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)},\"\n",
    "            line_to_write += f\"{numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean},\"\n",
    "            line_to_write += f\"{rmse_std}, {cmapss_mean}, {cmapss_std}\\n\"\n",
    "            file.write(line_to_write)\n",
    "    \n",
    "    print(\"MSE: mean = {:.2f}   stddev = {:.2f}\".format(mse_mean, mse_std))\n",
    "    print(\"RMSE: mean = {:.2f}   stddev = {:.2f}\".format(rmse_mean, rmse_std))\n",
    "    print(\"CMAPSS: mean = {:.2f}   stddev = {:.2f}\".format(cmapss_mean, cmapss_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reader = DataReader()\n",
    "\n",
    "start_time = time.process_time()  \n",
    "data_reader.load_dataset(filename, load_train=True, load_test=True)\n",
    "print(\"Operation time (sec): \" , (time.process_time() - start_time))\n",
    "\n",
    "if data_reader.train_set is not None:\n",
    "    print(\"Train set shape: \" + str(data_reader.train_set.shape))\n",
    "    \n",
    "if data_reader.test_set is not None:   \n",
    "    print(\"Test set shape: \" + str(data_reader.test_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_reader.train_set\n",
    "test_set = data_reader.test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['RUL']\n",
    "x_train = train_set.drop(['RUL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7b24089f928e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_cols\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_s_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RUL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_reader' is not defined"
     ]
    }
   ],
   "source": [
    "selected_columns = data_reader.column_names.w_cols + data_reader.column_names.x_s_cols\n",
    "x_train = x_train[selected_columns]\n",
    "\n",
    "y_test = test_set['RUL']\n",
    "x_test = test_set[x_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_0\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_0\\pca.pkl\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 107.7109\n",
      "Epoch 00001: val_loss improved from inf to 14.54236, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 107.6447 - val_loss: 14.5424\n",
      "Epoch 2/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 9.7409\n",
      "Epoch 00002: val_loss improved from 14.54236 to 8.21241, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 9.7369 - val_loss: 8.2124\n",
      "Epoch 3/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 6.1054\n",
      "Epoch 00003: val_loss improved from 8.21241 to 6.53588, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 6.1067 - val_loss: 6.5359\n",
      "Epoch 4/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 5.0008\n",
      "Epoch 00004: val_loss improved from 6.53588 to 4.20478, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.0001 - val_loss: 4.2048\n",
      "Epoch 5/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 4.3448\n",
      "Epoch 00005: val_loss did not improve from 4.20478\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.3450 - val_loss: 4.3646\n",
      "Epoch 6/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.9702\n",
      "Epoch 00006: val_loss did not improve from 4.20478\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.9702 - val_loss: 8.1843\n",
      "Epoch 7/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 3.6187\n",
      "Epoch 00007: val_loss improved from 4.20478 to 4.05974, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.6193 - val_loss: 4.0597\n",
      "Epoch 8/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 3.4501\n",
      "Epoch 00008: val_loss improved from 4.05974 to 3.67936, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.4498 - val_loss: 3.6794\n",
      "Epoch 9/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 3.2025\n",
      "Epoch 00009: val_loss improved from 3.67936 to 3.14918, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.2027 - val_loss: 3.1492\n",
      "Epoch 10/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 3.0516\n",
      "Epoch 00010: val_loss improved from 3.14918 to 3.06307, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.0514 - val_loss: 3.0631\n",
      "Epoch 11/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.9267\n",
      "Epoch 00011: val_loss improved from 3.06307 to 3.04397, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.9265 - val_loss: 3.0440\n",
      "Epoch 12/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.7728\n",
      "Epoch 00012: val_loss improved from 3.04397 to 2.87341, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.7735 - val_loss: 2.8734\n",
      "Epoch 13/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.6683\n",
      "Epoch 00013: val_loss improved from 2.87341 to 2.43331, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.6685 - val_loss: 2.4333\n",
      "Epoch 14/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.5778\n",
      "Epoch 00014: val_loss did not improve from 2.43331\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.5781 - val_loss: 2.9433\n",
      "Epoch 15/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.4872\n",
      "Epoch 00015: val_loss improved from 2.43331 to 2.42878, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4870 - val_loss: 2.4288\n",
      "Epoch 16/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.4303\n",
      "Epoch 00016: val_loss improved from 2.42878 to 2.37380, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4310 - val_loss: 2.3738\n",
      "Epoch 17/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 2.3772\n",
      "Epoch 00017: val_loss did not improve from 2.37380\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3768 - val_loss: 2.5775\n",
      "Epoch 18/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.3031\n",
      "Epoch 00018: val_loss improved from 2.37380 to 2.14067, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3030 - val_loss: 2.1407\n",
      "Epoch 19/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.2522\n",
      "Epoch 00019: val_loss did not improve from 2.14067\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2523 - val_loss: 2.3997\n",
      "Epoch 20/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.1924\n",
      "Epoch 00020: val_loss improved from 2.14067 to 1.95366, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1920 - val_loss: 1.9537\n",
      "Epoch 21/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.1489\n",
      "Epoch 00021: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1488 - val_loss: 2.0436\n",
      "Epoch 22/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.1100\n",
      "Epoch 00022: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1097 - val_loss: 2.0913\n",
      "Epoch 23/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 2.0743\n",
      "Epoch 00023: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.0741 - val_loss: 2.0922\n",
      "Epoch 24/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.0222\n",
      "Epoch 00024: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0223 - val_loss: 2.0274\n",
      "Epoch 25/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.9786\n",
      "Epoch 00025: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9790 - val_loss: 2.0602\n",
      "Epoch 26/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.9693\n",
      "Epoch 00026: val_loss improved from 1.95366 to 1.93020, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.9695 - val_loss: 1.9302\n",
      "Epoch 27/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.9419\n",
      "Epoch 00027: val_loss improved from 1.93020 to 1.89174, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9417 - val_loss: 1.8917\n",
      "Epoch 28/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.9227\n",
      "Epoch 00028: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9220 - val_loss: 1.9245\n",
      "Epoch 29/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.9075\n",
      "Epoch 00029: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9076 - val_loss: 2.0436\n",
      "Epoch 30/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.8676\n",
      "Epoch 00030: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8678 - val_loss: 1.9489\n",
      "Epoch 31/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.8307\n",
      "Epoch 00031: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8307 - val_loss: 1.9495\n",
      "Epoch 32/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.8208\n",
      "Epoch 00032: val_loss improved from 1.89174 to 1.82247, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8208 - val_loss: 1.8225\n",
      "Epoch 33/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.8031\n",
      "Epoch 00033: val_loss did not improve from 1.82247\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8029 - val_loss: 2.0735\n",
      "Epoch 34/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7647\n",
      "Epoch 00034: val_loss improved from 1.82247 to 1.75825, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.7647 - val_loss: 1.7582\n",
      "Epoch 35/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7700\n",
      "Epoch 00035: val_loss did not improve from 1.75825\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7702 - val_loss: 1.8291\n",
      "Epoch 36/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.7562\n",
      "Epoch 00036: val_loss did not improve from 1.75825\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7564 - val_loss: 1.8965\n",
      "Epoch 37/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7231\n",
      "Epoch 00037: val_loss improved from 1.75825 to 1.74347, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.7230 - val_loss: 1.7435\n",
      "Epoch 38/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.7047\n",
      "Epoch 00038: val_loss did not improve from 1.74347\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7047 - val_loss: 1.8221\n",
      "Epoch 39/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6906\n",
      "Epoch 00039: val_loss improved from 1.74347 to 1.62187, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6905 - val_loss: 1.6219\n",
      "Epoch 40/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6824- ETA: \n",
      "Epoch 00040: val_loss did not improve from 1.62187\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6827 - val_loss: 1.8029\n",
      "Epoch 41/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.6783\n",
      "Epoch 00041: val_loss improved from 1.62187 to 1.58902, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6778 - val_loss: 1.5890\n",
      "Epoch 42/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6372\n",
      "Epoch 00042: val_loss did not improve from 1.58902\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6371 - val_loss: 1.8424\n",
      "Epoch 43/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6149\n",
      "Epoch 00043: val_loss improved from 1.58902 to 1.47750, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.6150 - val_loss: 1.4775\n",
      "Epoch 44/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5985\n",
      "Epoch 00044: val_loss did not improve from 1.47750\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5985 - val_loss: 1.6180\n",
      "Epoch 45/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.5980- ETA: 0s - lo\n",
      "Epoch 00045: val_loss did not improve from 1.47750\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5982 - val_loss: 1.5711\n",
      "Epoch 46/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.6062\n",
      "Epoch 00046: val_loss improved from 1.47750 to 1.46927, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6063 - val_loss: 1.4693\n",
      "Epoch 47/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5683\n",
      "Epoch 00047: val_loss improved from 1.46927 to 1.46415, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.5683 - val_loss: 1.4641\n",
      "Epoch 48/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.5569\n",
      "Epoch 00048: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5569 - val_loss: 1.8643\n",
      "Epoch 49/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.5527\n",
      "Epoch 00049: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5530 - val_loss: 1.8368\n",
      "Epoch 50/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.5564\n",
      "Epoch 00050: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.5564 - val_loss: 1.8175\n",
      "Epoch 51/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5381\n",
      "Epoch 00051: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5381 - val_loss: 1.7042\n",
      "Epoch 52/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5267\n",
      "Epoch 00052: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5271 - val_loss: 1.7981\n",
      "Epoch 53/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.5287\n",
      "Epoch 00053: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5287 - val_loss: 1.4751\n",
      "Epoch 54/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5106\n",
      "Epoch 00054: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5105 - val_loss: 1.7031\n",
      "Epoch 55/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5140\n",
      "Epoch 00055: val_loss improved from 1.46415 to 1.41848, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.5140 - val_loss: 1.4185\n",
      "Epoch 56/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.507 - ETA: 0s - loss: 1.5072\n",
      "Epoch 00056: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5071 - val_loss: 1.5680\n",
      "Epoch 57/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4878\n",
      "Epoch 00057: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4878 - val_loss: 1.5200\n",
      "Epoch 58/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.4865\n",
      "Epoch 00058: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4863 - val_loss: 1.4403\n",
      "Epoch 59/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 00059: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4794 - val_loss: 1.5750\n",
      "Epoch 60/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.4709\n",
      "Epoch 00060: val_loss improved from 1.41848 to 1.29716, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 1.4706 - val_loss: 1.2972\n",
      "Epoch 61/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.4614\n",
      "Epoch 00061: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4614 - val_loss: 1.6744\n",
      "Epoch 62/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.4489\n",
      "Epoch 00062: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4494 - val_loss: 1.7070\n",
      "Epoch 63/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4456\n",
      "Epoch 00063: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4455 - val_loss: 1.6752\n",
      "Epoch 64/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4430\n",
      "Epoch 00064: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4430 - val_loss: 1.8154\n",
      "Epoch 65/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.4501\n",
      "Epoch 00065: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4501 - val_loss: 1.7057\n",
      "Epoch 66/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4375\n",
      "Epoch 00066: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4376 - val_loss: 1.5586\n",
      "Epoch 67/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4301\n",
      "Epoch 00067: val_loss improved from 1.29716 to 1.28435, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.4303 - val_loss: 1.2844\n",
      "Epoch 68/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4253\n",
      "Epoch 00068: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4253 - val_loss: 1.5475\n",
      "Epoch 69/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4292\n",
      "Epoch 00069: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4292 - val_loss: 1.5084\n",
      "Epoch 70/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.3911\n",
      "Epoch 00070: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3908 - val_loss: 1.4702\n",
      "Epoch 71/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.4138\n",
      "Epoch 00071: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4138 - val_loss: 1.4546\n",
      "Epoch 72/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3936\n",
      "Epoch 00072: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3936 - val_loss: 1.4057\n",
      "Epoch 73/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4018\n",
      "Epoch 00073: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4017 - val_loss: 1.3685\n",
      "Epoch 74/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.3645\n",
      "Epoch 00074: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3648 - val_loss: 1.9528\n",
      "Epoch 75/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3908\n",
      "Epoch 00075: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3908 - val_loss: 1.3882\n",
      "Epoch 76/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3775\n",
      "Epoch 00076: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3773 - val_loss: 1.4210\n",
      "Epoch 77/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.3881\n",
      "Epoch 00077: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3877 - val_loss: 1.4565\n",
      "Epoch 00077: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 36.73\n",
      "RMSE: 6.06\n",
      "CMAPSS score: 1.58\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_1\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_1\\pca.pkl\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 108.3349\n",
      "Epoch 00001: val_loss improved from inf to 13.60037, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 108.2021 - val_loss: 13.6004\n",
      "Epoch 2/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 9.5052\n",
      "Epoch 00002: val_loss improved from 13.60037 to 8.45470, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 9.5017 - val_loss: 8.4547\n",
      "Epoch 3/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 6.2179\n",
      "Epoch 00003: val_loss improved from 8.45470 to 5.92828, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 6.2171 - val_loss: 5.9283\n",
      "Epoch 4/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 5.1117\n",
      "Epoch 00004: val_loss improved from 5.92828 to 4.89107, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.1107 - val_loss: 4.8911\n",
      "Epoch 5/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 4.5063\n",
      "Epoch 00005: val_loss improved from 4.89107 to 4.52424, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.5062 - val_loss: 4.5242\n",
      "Epoch 6/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 4.1378\n",
      "Epoch 00006: val_loss improved from 4.52424 to 3.59381, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.1376 - val_loss: 3.5938\n",
      "Epoch 7/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 3.8213\n",
      "Epoch 00007: val_loss improved from 3.59381 to 3.42666, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.8205 - val_loss: 3.4267\n",
      "Epoch 8/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.5832\n",
      "Epoch 00008: val_loss did not improve from 3.42666\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.5832 - val_loss: 4.4242\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7186/7197 [============================>.] - ETA: 0s - loss: 3.4169\n",
      "Epoch 00009: val_loss did not improve from 3.42666\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.4166 - val_loss: 3.4978\n",
      "Epoch 10/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 3.2106\n",
      "Epoch 00010: val_loss did not improve from 3.42666\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.2104 - val_loss: 5.7608\n",
      "Epoch 11/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 3.0787\n",
      "Epoch 00011: val_loss improved from 3.42666 to 3.28600, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.0787 - val_loss: 3.2860\n",
      "Epoch 12/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.9563\n",
      "Epoch 00012: val_loss improved from 3.28600 to 3.25010, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.9558 - val_loss: 3.2501\n",
      "Epoch 13/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.8332\n",
      "Epoch 00013: val_loss did not improve from 3.25010\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8333 - val_loss: 3.4789\n",
      "Epoch 14/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.7321\n",
      "Epoch 00014: val_loss improved from 3.25010 to 2.68919, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.7320 - val_loss: 2.6892\n",
      "Epoch 15/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.6321\n",
      "Epoch 00015: val_loss did not improve from 2.68919\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.6324 - val_loss: 2.7102\n",
      "Epoch 16/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 2.5569- ETA: 0s - \n",
      "Epoch 00016: val_loss improved from 2.68919 to 2.26263, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.5569 - val_loss: 2.2626\n",
      "Epoch 17/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.4751\n",
      "Epoch 00017: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4759 - val_loss: 2.4907\n",
      "Epoch 18/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 2.3760\n",
      "Epoch 00018: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3765 - val_loss: 2.7336\n",
      "Epoch 19/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 2.3295\n",
      "Epoch 00019: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3293 - val_loss: 2.3178\n",
      "Epoch 20/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.2527\n",
      "Epoch 00020: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2531 - val_loss: 2.8301\n",
      "Epoch 21/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 2.2128\n",
      "Epoch 00021: val_loss improved from 2.26263 to 2.23043, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.2128 - val_loss: 2.2304\n",
      "Epoch 22/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.1849\n",
      "Epoch 00022: val_loss did not improve from 2.23043\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1849 - val_loss: 2.5527\n",
      "Epoch 23/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 2.1141\n",
      "Epoch 00023: val_loss improved from 2.23043 to 2.22879, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1145 - val_loss: 2.2288\n",
      "Epoch 24/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.0864\n",
      "Epoch 00024: val_loss improved from 2.22879 to 2.22096, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0861 - val_loss: 2.2210\n",
      "Epoch 25/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.0593\n",
      "Epoch 00025: val_loss improved from 2.22096 to 2.03612, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0595 - val_loss: 2.0361\n",
      "Epoch 26/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.0324\n",
      "Epoch 00026: val_loss improved from 2.03612 to 1.77848, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 2.0318 - val_loss: 1.7785\n",
      "Epoch 27/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.9964\n",
      "Epoch 00027: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9964 - val_loss: 2.2867\n",
      "Epoch 28/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.9704\n",
      "Epoch 00028: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9710 - val_loss: 2.3125\n",
      "Epoch 29/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.9460\n",
      "Epoch 00029: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9465 - val_loss: 2.8234\n",
      "Epoch 30/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.9247\n",
      "Epoch 00030: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9249 - val_loss: 2.6177\n",
      "Epoch 31/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.8810\n",
      "Epoch 00031: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8809 - val_loss: 2.1483\n",
      "Epoch 32/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.8749\n",
      "Epoch 00032: val_loss improved from 1.77848 to 1.62791, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8748 - val_loss: 1.6279\n",
      "Epoch 33/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.8301\n",
      "Epoch 00033: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8298 - val_loss: 1.8196\n",
      "Epoch 34/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.8355\n",
      "Epoch 00034: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8351 - val_loss: 1.8596\n",
      "Epoch 35/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.8244\n",
      "Epoch 00035: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8245 - val_loss: 1.8661\n",
      "Epoch 36/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7907\n",
      "Epoch 00036: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7907 - val_loss: 1.8407\n",
      "Epoch 37/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.7544\n",
      "Epoch 00037: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7543 - val_loss: 1.8796\n",
      "Epoch 38/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.7810\n",
      "Epoch 00038: val_loss improved from 1.62791 to 1.58039, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7810 - val_loss: 1.5804\n",
      "Epoch 39/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7427\n",
      "Epoch 00039: val_loss did not improve from 1.58039\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7427 - val_loss: 1.8820\n",
      "Epoch 40/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.7336\n",
      "Epoch 00040: val_loss did not improve from 1.58039\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7334 - val_loss: 1.6911\n",
      "Epoch 41/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6865\n",
      "Epoch 00041: val_loss did not improve from 1.58039\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6874 - val_loss: 4.3511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7130\n",
      "Epoch 00042: val_loss improved from 1.58039 to 1.51682, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7129 - val_loss: 1.5168\n",
      "Epoch 43/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.6644- ETA: 0s\n",
      "Epoch 00043: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6647 - val_loss: 1.9957\n",
      "Epoch 44/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.6510\n",
      "Epoch 00044: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6510 - val_loss: 1.8899\n",
      "Epoch 45/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6474\n",
      "Epoch 00045: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6471 - val_loss: 1.8664\n",
      "Epoch 46/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.6411\n",
      "Epoch 00046: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6411 - val_loss: 1.8276\n",
      "Epoch 47/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.6245\n",
      "Epoch 00047: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6244 - val_loss: 1.7511\n",
      "Epoch 48/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.5991\n",
      "Epoch 00048: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5991 - val_loss: 1.6335\n",
      "Epoch 49/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5784\n",
      "Epoch 00049: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5783 - val_loss: 1.5828\n",
      "Epoch 50/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.5575\n",
      "Epoch 00050: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5575 - val_loss: 1.7401\n",
      "Epoch 51/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.5696\n",
      "Epoch 00051: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5697 - val_loss: 1.7578\n",
      "Epoch 52/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.5687\n",
      "Epoch 00052: val_loss improved from 1.51682 to 1.49611, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.5685 - val_loss: 1.4961\n",
      "Epoch 53/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5458\n",
      "Epoch 00053: val_loss did not improve from 1.49611\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5457 - val_loss: 1.5635\n",
      "Epoch 54/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.5623\n",
      "Epoch 00054: val_loss improved from 1.49611 to 1.47974, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5620 - val_loss: 1.4797\n",
      "Epoch 55/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5310\n",
      "Epoch 00055: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5310 - val_loss: 1.5615\n",
      "Epoch 56/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.5133\n",
      "Epoch 00056: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5133 - val_loss: 1.5074\n",
      "Epoch 57/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.5303\n",
      "Epoch 00057: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5304 - val_loss: 1.7541\n",
      "Epoch 58/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4968\n",
      "Epoch 00058: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4968 - val_loss: 1.7040\n",
      "Epoch 59/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.5087\n",
      "Epoch 00059: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5085 - val_loss: 1.5605\n",
      "Epoch 60/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.4909\n",
      "Epoch 00060: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4909 - val_loss: 1.6777\n",
      "Epoch 61/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5069\n",
      "Epoch 00061: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5069 - val_loss: 1.6856\n",
      "Epoch 62/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4805\n",
      "Epoch 00062: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4803 - val_loss: 1.5304\n",
      "Epoch 63/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.4808\n",
      "Epoch 00063: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4808 - val_loss: 1.9181\n",
      "Epoch 64/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4665\n",
      "Epoch 00064: val_loss improved from 1.47974 to 1.45158, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4664 - val_loss: 1.4516\n",
      "Epoch 65/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.4541\n",
      "Epoch 00065: val_loss did not improve from 1.45158\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4537 - val_loss: 1.6052\n",
      "Epoch 66/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.4658\n",
      "Epoch 00066: val_loss did not improve from 1.45158\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4662 - val_loss: 1.9256\n",
      "Epoch 67/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.4398\n",
      "Epoch 00067: val_loss improved from 1.45158 to 1.44030, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4396 - val_loss: 1.4403\n",
      "Epoch 68/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4395\n",
      "Epoch 00068: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4395 - val_loss: 1.4654\n",
      "Epoch 69/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4242\n",
      "Epoch 00069: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4243 - val_loss: 1.7079\n",
      "Epoch 70/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4094\n",
      "Epoch 00070: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4095 - val_loss: 1.5795\n",
      "Epoch 71/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.3954\n",
      "Epoch 00071: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3951 - val_loss: 1.4432\n",
      "Epoch 72/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4171\n",
      "Epoch 00072: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4172 - val_loss: 1.4450\n",
      "Epoch 73/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.3916\n",
      "Epoch 00073: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3916 - val_loss: 1.5010\n",
      "Epoch 74/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 00074: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4099 - val_loss: 1.6205\n",
      "Epoch 75/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.3828\n",
      "Epoch 00075: val_loss improved from 1.44030 to 1.33419, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3825 - val_loss: 1.3342\n",
      "Epoch 76/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.3946\n",
      "Epoch 00076: val_loss improved from 1.33419 to 1.29899, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3946 - val_loss: 1.2990\n",
      "Epoch 77/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.3833\n",
      "Epoch 00077: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3838 - val_loss: 1.4039\n",
      "Epoch 78/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.3767\n",
      "Epoch 00078: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3766 - val_loss: 2.1334\n",
      "Epoch 79/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3751\n",
      "Epoch 00079: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3751 - val_loss: 1.4842\n",
      "Epoch 80/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.3569\n",
      "Epoch 00080: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3569 - val_loss: 1.5759\n",
      "Epoch 81/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.3491\n",
      "Epoch 00081: val_loss improved from 1.29899 to 1.26471, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.3491 - val_loss: 1.2647\n",
      "Epoch 82/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.3579\n",
      "Epoch 00082: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3580 - val_loss: 1.3480\n",
      "Epoch 83/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.3493\n",
      "Epoch 00083: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3491 - val_loss: 1.3038\n",
      "Epoch 84/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.3528\n",
      "Epoch 00084: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3525 - val_loss: 1.4164\n",
      "Epoch 85/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.3430\n",
      "Epoch 00085: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.3432 - val_loss: 1.3641\n",
      "Epoch 86/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.3316\n",
      "Epoch 00086: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3314 - val_loss: 1.3953\n",
      "Epoch 87/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.3394\n",
      "Epoch 00087: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3392 - val_loss: 1.4428\n",
      "Epoch 88/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.3296\n",
      "Epoch 00088: val_loss improved from 1.26471 to 1.18257, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3295 - val_loss: 1.1826\n",
      "Epoch 89/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3130\n",
      "Epoch 00089: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3129 - val_loss: 1.2918\n",
      "Epoch 90/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3143\n",
      "Epoch 00090: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3141 - val_loss: 1.4531\n",
      "Epoch 91/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.3235\n",
      "Epoch 00091: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3233 - val_loss: 1.2402\n",
      "Epoch 92/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3208\n",
      "Epoch 00092: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3212 - val_loss: 1.7850\n",
      "Epoch 93/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3077\n",
      "Epoch 00093: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3076 - val_loss: 1.2637\n",
      "Epoch 94/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.3097\n",
      "Epoch 00094: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3101 - val_loss: 1.4081\n",
      "Epoch 95/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.3001\n",
      "Epoch 00095: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3000 - val_loss: 1.3996\n",
      "Epoch 96/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.3070\n",
      "Epoch 00096: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3070 - val_loss: 1.5735\n",
      "Epoch 97/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3105\n",
      "Epoch 00097: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3105 - val_loss: 1.4531\n",
      "Epoch 98/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.3007\n",
      "Epoch 00098: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3007 - val_loss: 1.4788\n",
      "Epoch 00098: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 35.61\n",
      "RMSE: 5.97\n",
      "CMAPSS score: 1.56\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_2\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_2\\pca.pkl\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 110.4121\n",
      "Epoch 00001: val_loss improved from inf to 13.66215, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 110.3010 - val_loss: 13.6622\n",
      "Epoch 2/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 9.4672\n",
      "Epoch 00002: val_loss improved from 13.66215 to 6.51067, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 9.4654 - val_loss: 6.5107\n",
      "Epoch 3/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 6.1902\n",
      "Epoch 00003: val_loss improved from 6.51067 to 5.96488, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 6.1891 - val_loss: 5.9649\n",
      "Epoch 4/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 5.0192\n",
      "Epoch 00004: val_loss improved from 5.96488 to 5.29547, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.0190 - val_loss: 5.2955\n",
      "Epoch 5/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 4.3570\n",
      "Epoch 00005: val_loss improved from 5.29547 to 3.94004, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.3565 - val_loss: 3.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 3.9609\n",
      "Epoch 00006: val_loss improved from 3.94004 to 3.82042, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.9603 - val_loss: 3.8204\n",
      "Epoch 7/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 3.6782\n",
      "Epoch 00007: val_loss improved from 3.82042 to 3.26827, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.6783 - val_loss: 3.2683\n",
      "Epoch 8/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.4661\n",
      "Epoch 00008: val_loss did not improve from 3.26827\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.4662 - val_loss: 3.5249\n",
      "Epoch 9/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 3.2645\n",
      "Epoch 00009: val_loss did not improve from 3.26827\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.2644 - val_loss: 3.3979\n",
      "Epoch 10/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 3.0840\n",
      "Epoch 00010: val_loss improved from 3.26827 to 2.95126, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 3.0840 - val_loss: 2.9513\n",
      "Epoch 11/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.9600- ETA\n",
      "Epoch 00011: val_loss did not improve from 2.95126\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.9611 - val_loss: 5.4648\n",
      "Epoch 12/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.8385\n",
      "Epoch 00012: val_loss improved from 2.95126 to 2.68940, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8383 - val_loss: 2.6894\n",
      "Epoch 13/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.7282\n",
      "Epoch 00013: val_loss did not improve from 2.68940\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.7281 - val_loss: 4.0758\n",
      "Epoch 14/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 2.6434\n",
      "Epoch 00014: val_loss did not improve from 2.68940\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.6434 - val_loss: 2.8234\n",
      "Epoch 15/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 2.5815\n",
      "Epoch 00015: val_loss improved from 2.68940 to 2.37209, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 2.5816 - val_loss: 2.3721\n",
      "Epoch 16/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.4688\n",
      "Epoch 00016: val_loss did not improve from 2.37209\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.4687 - val_loss: 2.5204\n",
      "Epoch 17/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.4356\n",
      "Epoch 00017: val_loss improved from 2.37209 to 2.34944, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.4354 - val_loss: 2.3494\n",
      "Epoch 18/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.3775\n",
      "Epoch 00018: val_loss improved from 2.34944 to 2.21599, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3772 - val_loss: 2.2160\n",
      "Epoch 19/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.3420\n",
      "Epoch 00019: val_loss did not improve from 2.21599\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3426 - val_loss: 2.7504\n",
      "Epoch 20/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.2626\n",
      "Epoch 00020: val_loss did not improve from 2.21599\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2629 - val_loss: 2.4623\n",
      "Epoch 21/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.2092\n",
      "Epoch 00021: val_loss did not improve from 2.21599\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2094 - val_loss: 2.2503\n",
      "Epoch 22/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.1758\n",
      "Epoch 00022: val_loss improved from 2.21599 to 2.00007, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1758 - val_loss: 2.0001\n",
      "Epoch 23/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.1382\n",
      "Epoch 00023: val_loss did not improve from 2.00007\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1381 - val_loss: 2.1053\n",
      "Epoch 24/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.1096\n",
      "Epoch 00024: val_loss improved from 2.00007 to 1.98381, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1096 - val_loss: 1.9838\n",
      "Epoch 25/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 2.0650\n",
      "Epoch 00025: val_loss improved from 1.98381 to 1.92093, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 2.0645 - val_loss: 1.9209\n",
      "Epoch 26/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 2.0400\n",
      "Epoch 00026: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0399 - val_loss: 2.3019\n",
      "Epoch 27/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.0091\n",
      "Epoch 00027: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0096 - val_loss: 3.4709\n",
      "Epoch 28/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.9816\n",
      "Epoch 00028: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9816 - val_loss: 2.2241\n",
      "Epoch 29/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.9435\n",
      "Epoch 00029: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9438 - val_loss: 2.0645\n",
      "Epoch 30/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.9063\n",
      "Epoch 00030: val_loss improved from 1.92093 to 1.85241, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.9064 - val_loss: 1.8524\n",
      "Epoch 31/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.9111\n",
      "Epoch 00031: val_loss improved from 1.85241 to 1.81876, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9107 - val_loss: 1.8188\n",
      "Epoch 32/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8660\n",
      "Epoch 00032: val_loss did not improve from 1.81876\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8660 - val_loss: 1.9557\n",
      "Epoch 33/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.8537\n",
      "Epoch 00033: val_loss did not improve from 1.81876\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8535 - val_loss: 2.0449\n",
      "Epoch 34/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8322\n",
      "Epoch 00034: val_loss did not improve from 1.81876\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8322 - val_loss: 1.9982\n",
      "Epoch 35/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.8120\n",
      "Epoch 00035: val_loss improved from 1.81876 to 1.79033, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8116 - val_loss: 1.7903\n",
      "Epoch 36/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.8041\n",
      "Epoch 00036: val_loss improved from 1.79033 to 1.78422, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8036 - val_loss: 1.7842\n",
      "Epoch 37/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7820\n",
      "Epoch 00037: val_loss did not improve from 1.78422\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7821 - val_loss: 1.9467\n",
      "Epoch 38/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.7413\n",
      "Epoch 00038: val_loss did not improve from 1.78422\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7411 - val_loss: 2.0081\n",
      "Epoch 39/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.7286\n",
      "Epoch 00039: val_loss improved from 1.78422 to 1.53895, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.7286 - val_loss: 1.5390\n",
      "Epoch 40/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.7140\n",
      "Epoch 00040: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7136 - val_loss: 1.8448\n",
      "Epoch 41/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.7093- ETA: 0s - lo\n",
      "Epoch 00041: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7092 - val_loss: 2.7093\n",
      "Epoch 42/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.6699\n",
      "Epoch 00042: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6699 - val_loss: 2.0056\n",
      "Epoch 43/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.6806\n",
      "Epoch 00043: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6804 - val_loss: 1.8016\n",
      "Epoch 44/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.6591\n",
      "Epoch 00044: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6590 - val_loss: 1.8524\n",
      "Epoch 45/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6260\n",
      "Epoch 00045: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6261 - val_loss: 1.9799\n",
      "Epoch 46/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.6036\n",
      "Epoch 00046: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6037 - val_loss: 1.6126\n",
      "Epoch 47/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.5899\n",
      "Epoch 00047: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5899 - val_loss: 1.8134\n",
      "Epoch 48/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.6132\n",
      "Epoch 00048: val_loss improved from 1.53895 to 1.53761, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6132 - val_loss: 1.5376\n",
      "Epoch 49/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.5852\n",
      "Epoch 00049: val_loss did not improve from 1.53761\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5852 - val_loss: 1.7157\n",
      "Epoch 50/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.5743\n",
      "Epoch 00050: val_loss did not improve from 1.53761\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5744 - val_loss: 1.8201\n",
      "Epoch 51/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.5619\n",
      "Epoch 00051: val_loss improved from 1.53761 to 1.43365, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5615 - val_loss: 1.4336\n",
      "Epoch 52/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.5676\n",
      "Epoch 00052: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5677 - val_loss: 1.9112\n",
      "Epoch 53/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5511\n",
      "Epoch 00053: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5513 - val_loss: 1.6561\n",
      "Epoch 54/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5304\n",
      "Epoch 00054: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5304 - val_loss: 1.6039\n",
      "Epoch 55/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.5239\n",
      "Epoch 00055: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5239 - val_loss: 1.8523\n",
      "Epoch 56/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.5054\n",
      "Epoch 00056: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5055 - val_loss: 1.6769\n",
      "Epoch 57/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.5076\n",
      "Epoch 00057: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5076 - val_loss: 1.6565\n",
      "Epoch 58/200\n",
      "7181/7197 [============================>.] - ETA: 0s - loss: 1.5100\n",
      "Epoch 00058: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5099 - val_loss: 1.9622\n",
      "Epoch 59/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4937\n",
      "Epoch 00059: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4933 - val_loss: 1.4451\n",
      "Epoch 60/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.4949\n",
      "Epoch 00060: val_loss improved from 1.43365 to 1.40949, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4950 - val_loss: 1.4095\n",
      "Epoch 61/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4589\n",
      "Epoch 00061: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4588 - val_loss: 1.4751\n",
      "Epoch 62/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.4734\n",
      "Epoch 00062: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4736 - val_loss: 1.6506\n",
      "Epoch 63/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.4765\n",
      "Epoch 00063: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4768 - val_loss: 1.6790\n",
      "Epoch 64/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.4715\n",
      "Epoch 00064: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4718 - val_loss: 1.4353\n",
      "Epoch 65/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.4582\n",
      "Epoch 00065: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4582 - val_loss: 1.5604\n",
      "Epoch 66/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.4319\n",
      "Epoch 00066: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4315 - val_loss: 1.5667\n",
      "Epoch 67/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4228\n",
      "Epoch 00067: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4231 - val_loss: 1.6756\n",
      "Epoch 68/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4450\n",
      "Epoch 00068: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4451 - val_loss: 2.4692\n",
      "Epoch 69/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4393\n",
      "Epoch 00069: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4392 - val_loss: 1.5007\n",
      "Epoch 70/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4164\n",
      "Epoch 00070: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4163 - val_loss: 1.5023\n",
      "Epoch 00070: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 32.72\n",
      "RMSE: 5.72\n",
      "CMAPSS score: 1.52\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_3\\scaler.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_3\\pca.pkl\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 105.6114\n",
      "Epoch 00001: val_loss improved from inf to 14.08757, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 105.4815 - val_loss: 14.0876\n",
      "Epoch 2/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 9.5658\n",
      "Epoch 00002: val_loss improved from 14.08757 to 7.34689, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 9.5654 - val_loss: 7.3469\n",
      "Epoch 3/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 6.0949\n",
      "Epoch 00003: val_loss improved from 7.34689 to 5.66737, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 6.0949 - val_loss: 5.6674\n",
      "Epoch 4/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 4.9114\n",
      "Epoch 00004: val_loss improved from 5.66737 to 4.60128, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.9117 - val_loss: 4.6013\n",
      "Epoch 5/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 4.3313\n",
      "Epoch 00005: val_loss improved from 4.60128 to 4.29136, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 4.3312 - val_loss: 4.2914\n",
      "Epoch 6/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.9059\n",
      "Epoch 00006: val_loss improved from 4.29136 to 3.55571, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.9057 - val_loss: 3.5557\n",
      "Epoch 7/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 3.5989\n",
      "Epoch 00007: val_loss improved from 3.55571 to 3.55529, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.5990 - val_loss: 3.5553\n",
      "Epoch 8/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 3.3768\n",
      "Epoch 00008: val_loss improved from 3.55529 to 3.13945, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.3767 - val_loss: 3.1394\n",
      "Epoch 9/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 3.1790\n",
      "Epoch 00009: val_loss did not improve from 3.13945\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.1787 - val_loss: 3.6150\n",
      "Epoch 10/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 3.0333\n",
      "Epoch 00010: val_loss improved from 3.13945 to 2.79450, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 3.0331 - val_loss: 2.7945\n",
      "Epoch 11/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.8918\n",
      "Epoch 00011: val_loss improved from 2.79450 to 2.77848, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8917 - val_loss: 2.7785\n",
      "Epoch 12/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.7820\n",
      "Epoch 00012: val_loss improved from 2.77848 to 2.72046, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.7823 - val_loss: 2.7205\n",
      "Epoch 13/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.6660\n",
      "Epoch 00013: val_loss did not improve from 2.72046\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.6660 - val_loss: 2.8503\n",
      "Epoch 14/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.5732\n",
      "Epoch 00014: val_loss improved from 2.72046 to 2.46548, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.5728 - val_loss: 2.4655\n",
      "Epoch 15/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.4844\n",
      "Epoch 00015: val_loss improved from 2.46548 to 2.25023, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4842 - val_loss: 2.2502\n",
      "Epoch 16/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.4338\n",
      "Epoch 00016: val_loss did not improve from 2.25023\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.4333 - val_loss: 2.2538\n",
      "Epoch 17/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.3627\n",
      "Epoch 00017: val_loss improved from 2.25023 to 2.15850, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3626 - val_loss: 2.1585\n",
      "Epoch 18/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.2801\n",
      "Epoch 00018: val_loss did not improve from 2.15850\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2801 - val_loss: 2.5875\n",
      "Epoch 19/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.2553\n",
      "Epoch 00019: val_loss improved from 2.15850 to 2.12626, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2554 - val_loss: 2.1263\n",
      "Epoch 20/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.1993\n",
      "Epoch 00020: val_loss did not improve from 2.12626\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1994 - val_loss: 2.5970\n",
      "Epoch 21/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.1775- ET\n",
      "Epoch 00021: val_loss improved from 2.12626 to 2.04297, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1775 - val_loss: 2.0430\n",
      "Epoch 22/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.1216\n",
      "Epoch 00022: val_loss did not improve from 2.04297\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1214 - val_loss: 2.1888\n",
      "Epoch 23/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.0672\n",
      "Epoch 00023: val_loss improved from 2.04297 to 1.96064, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 2.0670 - val_loss: 1.9606\n",
      "Epoch 24/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.0587\n",
      "Epoch 00024: val_loss did not improve from 1.96064\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0583 - val_loss: 1.9873\n",
      "Epoch 25/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 2.0235\n",
      "Epoch 00025: val_loss did not improve from 1.96064\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.0233 - val_loss: 1.9643\n",
      "Epoch 26/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.9689- ETA: 0s \n",
      "Epoch 00026: val_loss improved from 1.96064 to 1.82508, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9684 - val_loss: 1.8251\n",
      "Epoch 27/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.9325\n",
      "Epoch 00027: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9325 - val_loss: 1.9621\n",
      "Epoch 28/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.9154\n",
      "Epoch 00028: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9151 - val_loss: 2.0261\n",
      "Epoch 29/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.9085\n",
      "Epoch 00029: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9089 - val_loss: 1.8493\n",
      "Epoch 30/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.8431\n",
      "Epoch 00030: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8434 - val_loss: 2.4517\n",
      "Epoch 31/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8409\n",
      "Epoch 00031: val_loss improved from 1.82508 to 1.64970, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8409 - val_loss: 1.6497\n",
      "Epoch 32/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.8378\n",
      "Epoch 00032: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8384 - val_loss: 1.9648\n",
      "Epoch 33/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.8130\n",
      "Epoch 00033: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8130 - val_loss: 1.9908\n",
      "Epoch 34/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.7996\n",
      "Epoch 00034: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7996 - val_loss: 2.3808\n",
      "Epoch 35/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7596\n",
      "Epoch 00035: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7597 - val_loss: 2.3413\n",
      "Epoch 36/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.7763\n",
      "Epoch 00036: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7768 - val_loss: 1.7960\n",
      "Epoch 37/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.7456\n",
      "Epoch 00037: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7456 - val_loss: 1.7737\n",
      "Epoch 38/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.7171\n",
      "Epoch 00038: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7170 - val_loss: 1.6574\n",
      "Epoch 39/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6817\n",
      "Epoch 00039: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6817 - val_loss: 1.7559\n",
      "Epoch 40/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7004\n",
      "Epoch 00040: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7004 - val_loss: 1.7617\n",
      "Epoch 41/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.6599\n",
      "Epoch 00041: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6603 - val_loss: 1.8178\n",
      "Epoch 00041: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_3\\history.pkl\n",
      "Test set:\n",
      "MSE: 36.53\n",
      "RMSE: 6.04\n",
      "CMAPSS score: 1.56\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_4\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_4\\pca.pkl\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 103.0529\n",
      "Epoch 00001: val_loss improved from inf to 14.98844, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 103.0389 - val_loss: 14.9884\n",
      "Epoch 2/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 9.2333\n",
      "Epoch 00002: val_loss improved from 14.98844 to 6.88040, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 9.2328 - val_loss: 6.8804\n",
      "Epoch 3/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 5.8592\n",
      "Epoch 00003: val_loss improved from 6.88040 to 5.15158, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.8599 - val_loss: 5.1516\n",
      "Epoch 4/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 4.7302\n",
      "Epoch 00004: val_loss did not improve from 5.15158\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 4.7304 - val_loss: 5.4690\n",
      "Epoch 5/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 4.1814\n",
      "Epoch 00005: val_loss improved from 5.15158 to 3.74251, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.1810 - val_loss: 3.7425\n",
      "Epoch 6/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 3.7810\n",
      "Epoch 00006: val_loss did not improve from 3.74251\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.7816 - val_loss: 4.4628\n",
      "Epoch 7/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 3.4765\n",
      "Epoch 00007: val_loss did not improve from 3.74251\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.4757 - val_loss: 3.7773\n",
      "Epoch 8/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 3.2653\n",
      "Epoch 00008: val_loss improved from 3.74251 to 3.32227, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.2657 - val_loss: 3.3223\n",
      "Epoch 9/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 3.0996\n",
      "Epoch 00009: val_loss improved from 3.32227 to 2.80296, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.0992 - val_loss: 2.8030\n",
      "Epoch 10/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.9280\n",
      "Epoch 00010: val_loss improved from 2.80296 to 2.56991, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.9280 - val_loss: 2.5699\n",
      "Epoch 11/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.8063\n",
      "Epoch 00011: val_loss did not improve from 2.56991\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8062 - val_loss: 3.1983\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.6982\n",
      "Epoch 00012: val_loss did not improve from 2.56991\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.6979 - val_loss: 2.6942\n",
      "Epoch 13/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.5879\n",
      "Epoch 00013: val_loss did not improve from 2.56991\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.5882 - val_loss: 2.6061\n",
      "Epoch 14/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.4779\n",
      "Epoch 00014: val_loss improved from 2.56991 to 2.56137, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4778 - val_loss: 2.5614\n",
      "Epoch 15/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.4391\n",
      "Epoch 00015: val_loss did not improve from 2.56137\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4392 - val_loss: 2.7317\n",
      "Epoch 16/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 2.3537\n",
      "Epoch 00016: val_loss improved from 2.56137 to 2.20523, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3535 - val_loss: 2.2052\n",
      "Epoch 17/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.3218\n",
      "Epoch 00017: val_loss improved from 2.20523 to 2.15376, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3217 - val_loss: 2.1538\n",
      "Epoch 18/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.2631\n",
      "Epoch 00018: val_loss improved from 2.15376 to 2.06571, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.2632 - val_loss: 2.0657\n",
      "Epoch 19/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.2097\n",
      "Epoch 00019: val_loss improved from 2.06571 to 2.01537, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.2098 - val_loss: 2.0154\n",
      "Epoch 20/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.1410\n",
      "Epoch 00020: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1412 - val_loss: 2.3181\n",
      "Epoch 21/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.1264\n",
      "Epoch 00021: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.1265 - val_loss: 2.1127\n",
      "Epoch 22/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.0747\n",
      "Epoch 00022: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.0749 - val_loss: 3.2425\n",
      "Epoch 23/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.0300\n",
      "Epoch 00023: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.0298 - val_loss: 3.0204\n",
      "Epoch 24/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 2.0111\n",
      "Epoch 00024: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.0111 - val_loss: 2.3206\n",
      "Epoch 25/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.9491\n",
      "Epoch 00025: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.9496 - val_loss: 2.6184\n",
      "Epoch 26/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.9615\n",
      "Epoch 00026: val_loss improved from 2.01537 to 1.81037, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.9611 - val_loss: 1.8104\n",
      "Epoch 27/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.9173\n",
      "Epoch 00027: val_loss did not improve from 1.81037\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.9173 - val_loss: 2.0126\n",
      "Epoch 28/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.8692\n",
      "Epoch 00028: val_loss did not improve from 1.81037\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8692 - val_loss: 2.2174\n",
      "Epoch 29/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.8866\n",
      "Epoch 00029: val_loss did not improve from 1.81037\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8870 - val_loss: 2.1274\n",
      "Epoch 30/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.8663\n",
      "Epoch 00030: val_loss improved from 1.81037 to 1.61255, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 1.8657 - val_loss: 1.6126\n",
      "Epoch 31/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8112\n",
      "Epoch 00031: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8111 - val_loss: 2.4027\n",
      "Epoch 32/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.8204\n",
      "Epoch 00032: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8205 - val_loss: 1.8177\n",
      "Epoch 33/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7830\n",
      "Epoch 00033: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7834 - val_loss: 1.7582\n",
      "Epoch 34/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.7621\n",
      "Epoch 00034: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7624 - val_loss: 1.9941\n",
      "Epoch 35/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7593\n",
      "Epoch 00035: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7592 - val_loss: 1.8214\n",
      "Epoch 36/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7330\n",
      "Epoch 00036: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7332 - val_loss: 1.7654\n",
      "Epoch 37/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7247\n",
      "Epoch 00037: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7248 - val_loss: 1.8966\n",
      "Epoch 38/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.6949\n",
      "Epoch 00038: val_loss improved from 1.61255 to 1.58689, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6940 - val_loss: 1.5869\n",
      "Epoch 39/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7012\n",
      "Epoch 00039: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7011 - val_loss: 1.6053\n",
      "Epoch 40/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.6677\n",
      "Epoch 00040: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6676 - val_loss: 1.6569\n",
      "Epoch 41/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.6568\n",
      "Epoch 00041: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6570 - val_loss: 1.8143\n",
      "Epoch 42/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.6377\n",
      "Epoch 00042: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6376 - val_loss: 1.6731\n",
      "Epoch 43/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.6151\n",
      "Epoch 00043: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6150 - val_loss: 1.8214\n",
      "Epoch 44/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.6035\n",
      "Epoch 00044: val_loss improved from 1.58689 to 1.56316, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6037 - val_loss: 1.5632\n",
      "Epoch 45/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.6228\n",
      "Epoch 00045: val_loss did not improve from 1.56316\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6228 - val_loss: 1.9158\n",
      "Epoch 46/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.5886\n",
      "Epoch 00046: val_loss did not improve from 1.56316\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5886 - val_loss: 1.5728\n",
      "Epoch 47/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.6128\n",
      "Epoch 00047: val_loss did not improve from 1.56316\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6128 - val_loss: 1.6792\n",
      "Epoch 48/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.5605\n",
      "Epoch 00048: val_loss improved from 1.56316 to 1.48890, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5599 - val_loss: 1.4889\n",
      "Epoch 49/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.5777\n",
      "Epoch 00049: val_loss did not improve from 1.48890\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5775 - val_loss: 1.6890\n",
      "Epoch 50/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5434\n",
      "Epoch 00050: val_loss improved from 1.48890 to 1.36087, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5432 - val_loss: 1.3609\n",
      "Epoch 51/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5631\n",
      "Epoch 00051: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5635 - val_loss: 2.8896\n",
      "Epoch 52/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5615\n",
      "Epoch 00052: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5615 - val_loss: 1.5781\n",
      "Epoch 53/200\n",
      "7181/7197 [============================>.] - ETA: 0s - loss: 1.5259\n",
      "Epoch 00053: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5268 - val_loss: 1.9175\n",
      "Epoch 54/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.5347\n",
      "Epoch 00054: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5347 - val_loss: 1.8904\n",
      "Epoch 55/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.5222\n",
      "Epoch 00055: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5222 - val_loss: 2.0372\n",
      "Epoch 56/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5148\n",
      "Epoch 00056: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5148 - val_loss: 1.5989\n",
      "Epoch 57/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4901\n",
      "Epoch 00057: val_loss improved from 1.36087 to 1.32864, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4901 - val_loss: 1.3286\n",
      "Epoch 58/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4955\n",
      "Epoch 00058: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4950 - val_loss: 1.3697\n",
      "Epoch 59/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.5013\n",
      "Epoch 00059: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5013 - val_loss: 1.4495\n",
      "Epoch 60/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.4705\n",
      "Epoch 00060: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4704 - val_loss: 1.5607\n",
      "Epoch 61/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4847\n",
      "Epoch 00061: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4850 - val_loss: 1.5382\n",
      "Epoch 62/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4469\n",
      "Epoch 00062: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4469 - val_loss: 1.3327\n",
      "Epoch 63/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.4706\n",
      "Epoch 00063: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4703 - val_loss: 1.4783\n",
      "Epoch 64/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.4718\n",
      "Epoch 00064: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4714 - val_loss: 1.3554\n",
      "Epoch 65/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4388\n",
      "Epoch 00065: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4385 - val_loss: 1.5002\n",
      "Epoch 66/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4565\n",
      "Epoch 00066: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4568 - val_loss: 2.1125\n",
      "Epoch 67/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.4467\n",
      "Epoch 00067: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4467 - val_loss: 1.5411\n",
      "Epoch 00067: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_4\\history.pkl\n",
      "Test set:\n",
      "MSE: 97.17\n",
      "RMSE: 9.86\n",
      "CMAPSS score: 2.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Test effect of PCA for feature extraction\n",
    "###########################################\n",
    "NUM_TRIALS = 3\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "mlp_config_params = MLPConfigParams(layer_sizes=[256, 256, 512, 64], activation='tanh', dropout=0.0)\n",
    "\n",
    "results_path = os.path.join(output_path, \"results_pca_a1\")\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "results_file = os.path.join(output_path, \"results_pca_a1.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "train_evaluate_pca(\n",
    "    x_train, y_train, \n",
    "    x_test, y_test,\n",
    "    NUM_TRIALS, \n",
    "    mlp_params, \n",
    "    results_path, \n",
    "    EPOCHS, BATCH_SIZE,\n",
    "    results_file=results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 3\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "mlp_params = MLPConfigParams(layer_sizes=[128, 256, 64], activation='tanh', dropout=0.05)\n",
    "\n",
    "results_path = os.path.join(output_path, \"results_pca_a2\")\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "results_file = os.path.join(output_path, \"results_pca_a2.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "train_evaluate_pca(\n",
    "    x_train, y_train, \n",
    "    x_test, y_test,\n",
    "    NUM_TRIALS, \n",
    "    mlp_params, \n",
    "    results_path, \n",
    "    EPOCHS, BATCH_SIZE,\n",
    "    results_file=results_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-keras-gpu",
   "language": "python",
   "name": "tf-keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
