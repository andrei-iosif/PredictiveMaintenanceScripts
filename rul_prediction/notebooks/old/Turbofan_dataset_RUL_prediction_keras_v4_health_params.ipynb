{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "seed = 0\n",
    "os.environ['PYTHONHASSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/turbofan_dataset/N-CMAPSS_DS02-006.h5'\n",
    "output_path = 'DS02/experiment_set_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, load_test_set=True):\n",
    "    \"\"\" Reads a dataset from a given .h5 file and compose (in memory) the train and test data. \n",
    "    Args:\n",
    "        filename(str): path to the .h5 file\n",
    "    Returns:\n",
    "        train_set(pd.DataFrame), test_set(pd.DataFrame)\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as hdf:\n",
    "        # Development set\n",
    "        W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "        X_v_dev = np.array(hdf.get('X_v_dev'))         # X_v\n",
    "        T_dev = np.array(hdf.get('T_dev'))             # T\n",
    "        Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
    "        A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "        # Test set\n",
    "        if load_test_set:\n",
    "            W_test = np.array(hdf.get('W_test'))           # W\n",
    "            X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
    "            X_v_test = np.array(hdf.get('X_v_test'))       # X_v\n",
    "            T_test = np.array(hdf.get('T_test'))           # T\n",
    "            Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
    "            A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
    "        \n",
    "        # Column names\n",
    "        W_var = np.array(hdf.get('W_var'))\n",
    "        X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "        X_v_var = np.array(hdf.get('X_v_var')) \n",
    "        T_var = np.array(hdf.get('T_var'))\n",
    "        A_var = np.array(hdf.get('A_var'))\n",
    "        \n",
    "        columns = []\n",
    "        columns.append(list(np.array(A_var, dtype='U20')))\n",
    "        columns.append(list(np.array(T_var, dtype='U20')))\n",
    "        columns.append(list(np.array(X_s_var, dtype='U20')))\n",
    "        columns.append(list(np.array(X_v_var, dtype='U20')))\n",
    "        columns.append(list(np.array(W_var, dtype='U20')))\n",
    "        columns.append(['RUL'])\n",
    "        \n",
    "        columns_list = []\n",
    "        for columns_per_category in columns:\n",
    "            columns_list += columns_per_category\n",
    "        \n",
    "    train_set = np.concatenate((A_dev, T_dev, X_s_dev, X_v_dev, W_dev, Y_dev), axis=1)\n",
    "    if load_test_set:\n",
    "        test_set = np.concatenate((A_test, T_test, X_s_test, X_v_test, W_test, Y_test), axis=1)\n",
    "        return pd.DataFrame(data=train_set, columns=columns_list), pd.DataFrame(data=test_set, columns=columns_list), columns\n",
    "    else:\n",
    "        return pd.DataFrame(data=train_set, columns=columns_list), None, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_cycle_info(df, compute_cycle_len=False):\n",
    "    unit_ids = np.unique(df['unit'])\n",
    "    print('Engine units in df: ', unit_ids)\n",
    "    for i in unit_ids:\n",
    "        num_cycles = len(np.unique(df.loc[df['unit'] == i, 'cycle']))\n",
    "        print('Unit: ', i, ' - Number of flight cycles: ', num_cycles)\n",
    "        \n",
    "    if compute_cycle_len:\n",
    "        cycle_ids = np.unique(df['cycle'])\n",
    "        print('Total number of cycles: ', len(cycle_ids))\n",
    "        min_len = np.inf\n",
    "        max_len = 0\n",
    "        for i in cycle_ids:\n",
    "            cycle_len = len(df.loc[df['cycle'] == i, 'cycle'])\n",
    "            if cycle_len < min_len:\n",
    "                min_len = cycle_len\n",
    "            elif cycle_len > max_len:\n",
    "                max_len = cycle_len\n",
    "        print('Min cycle length: ', min_len)\n",
    "        print('Max cycle length: ', max_len)\n",
    "    \n",
    "    return unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter constant and quasi-constant features\n",
    "def get_quasi_constant_features(dataset, variance_th=0.01, debug=True):\n",
    "    constant_filter = VarianceThreshold(threshold=variance_th)\n",
    "    constant_filter.fit(dataset)\n",
    "    constant_features = [col for col in dataset.columns \n",
    "                         if col not in dataset.columns[constant_filter.get_support()]]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Number of non-constant features: \", len(dataset.columns[constant_filter.get_support()]))\n",
    "        \n",
    "        print(\"Number of quasi-constant features: \", len(constant_features))\n",
    "        print(\"Quasi-constant features: \")\n",
    "        for col in constant_features:\n",
    "            print(col)\n",
    "    return constant_features\n",
    "\n",
    "def get_non_correlated_features(dataset, corr_th=0.9, debug=True):\n",
    "    corr_mat = dataset.corr()\n",
    "    corr_mat = np.abs(corr_mat)\n",
    "    \n",
    "    num_cols = corr_mat.shape[0]\n",
    "    columns = np.full((num_cols,), True, dtype=bool)\n",
    "    for i in range(num_cols):\n",
    "        for j in range(i+1, num_cols):\n",
    "            val = corr_mat.iloc[i, j]\n",
    "            if val >= corr_th:\n",
    "                if columns[j]:\n",
    "                    columns[j] = False\n",
    "                    if debug:\n",
    "                        print(dataset.columns[i], \"|\", dataset.columns[j], \"|\", round(val, 2))\n",
    "    if debug:        \n",
    "        correlated_features = dataset.columns[~columns]\n",
    "        print(\"Number of correlated features: \", len(correlated_features))\n",
    "        print(\"Correlated features: \", list(correlated_features))\n",
    "    \n",
    "    selected_columns = dataset.columns[columns]\n",
    "    if debug:\n",
    "        print(\"Number of selected features: \", len(selected_columns))\n",
    "        print(\"Selected features: \", list(selected_columns))\n",
    "    return selected_columns\n",
    "\n",
    "def cmapss_score_function(actual, predictions, normalize=True):\n",
    "    # diff < 0 -> over-estimation\n",
    "    # diff > 0 -> under-estimation\n",
    "    diff = actual - predictions\n",
    "    alpha = np.full_like(diff, 1/13)\n",
    "    negative_diff_mask = diff < 0\n",
    "    alpha[negative_diff_mask] = 1/10\n",
    "    score = np.sum(np.exp(alpha * np.abs(diff)))\n",
    "    \n",
    "    if normalize:\n",
    "        N = len(predictions)\n",
    "        score /= N\n",
    "    return score\n",
    "\n",
    "def compute_evaluation_metrics(actual, predictions, label='Test'):\n",
    "    mse = mean_squared_error(actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    cmapss_score = cmapss_score_function(actual, predictions)\n",
    "    print('{} set:\\nMSE: {:.2f}\\nRMSE: {:.2f}\\nCMAPSS score: {:.2f}\\n'.format(label, mse, rmse, \n",
    "                                                                     cmapss_score))\n",
    "    return mse, rmse, cmapss_score\n",
    "    \n",
    "def plot_loss_curves(history, output_path=None, y_lim=[0, 150]):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylim(y_lim)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    \n",
    "    if output_path is not None:\n",
    "        plt.savefig(os.path.join(output_path, 'loss_curves.png'), format='png', dpi=300) \n",
    "    plt.show()\n",
    "    \n",
    "def plot_rul(expected, predicted):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(expected)), expected, label='Expected')\n",
    "    plt.plot(range(len(predicted)), predicted, label='Predicted')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def create_mlp_model(input_dim, hidden_layer_sizes, activation='relu', output_weights_file=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], \n",
    "                    input_dim=input_dim, \n",
    "                    kernel_initializer='random_normal', \n",
    "                    activation=activation))\n",
    "\n",
    "    for layer_size in hidden_layer_sizes[1:]:\n",
    "        model.add(Dense(layer_size, \n",
    "                        kernel_initializer='random_normal', \n",
    "                        activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='random_normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    if output_weights_file is not None:\n",
    "        model.save_weights(output_weights_file)\n",
    "    return model\n",
    "\n",
    "def train_model_existing_weights(model, weights_file, x_train, y_train, x_val, y_val, epochs=200, batch_size=512, callbacks=[]):\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.load_weights(weights_file)\n",
    "    return model.fit(x_train, y_train,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     verbose=1,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "def save_history(history, output_file=os.path.join(output_path, \"history.pkl\")):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "    print(\"Saved training history to file: {}\".format(output_file))\n",
    "\n",
    "def load_history(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def save_object(obj, output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    print(\"Saved object to file: {}\".format(output_file))\n",
    "    \n",
    "def load_object(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def model_evaluation(model, x_test, y_test, x_train=None, y_train=None, plot_range=[0, 10**3]):\n",
    "    if x_train is not None and y_train is not None:\n",
    "        predictions_train = model.predict(x_train).flatten()\n",
    "        compute_evaluation_metrics(predictions_train, y_train, 'Train')\n",
    "        \n",
    "        expected = y_train[plot_range[0]:plot_range[1]]\n",
    "        predicted = predictions_train[plot_range[0]:plot_range[1]]\n",
    "        plot_rul(expected, predicted)\n",
    "        \n",
    "    predictions_test = model.predict(x_test).flatten()\n",
    "    compute_evaluation_metrics(predictions_test, y_test)\n",
    "    \n",
    "    expected = y_test[plot_range[0]:plot_range[1]]\n",
    "    predicted = predictions_test[plot_range[0]:plot_range[1]]\n",
    "    plot_rul(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list(string_list, output_file):\n",
    "    output_file.write(\"[\")\n",
    "    n = len(string_list)\n",
    "    for i in range(n - 1):\n",
    "        output_file.write(\"{}, \".format(string_list[i]))\n",
    "    output_file.write(\"{}]\\n\".format(string_list[-1]))\n",
    "    \n",
    "def feature_list_to_string(feature_list):\n",
    "    return \"__\".join(feature_list)\n",
    "\n",
    "def numbers_list_to_string(num_list):\n",
    "    return \" \".join([str(x) for x in num_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation time (sec):  3.5\n",
      "\n",
      "Train set shape: (5263447, 47)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()  \n",
    "train_set, test_set, columns = load_dataset(filename)\n",
    "print(\"Operation time (sec): \" , (time.process_time() - start_time))\n",
    "print()\n",
    "print(\"Train set shape: \" + str(train_set.shape))\n",
    "\n",
    "columns_aux = columns[0] \n",
    "columns_health_params = columns[1] \n",
    "columns_sensor_measurements = columns[2] \n",
    "columns_virtual_sensors = columns[3]\n",
    "columns_operating_conditions = columns[4] \n",
    "target_col = columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['RUL']\n",
    "x_train = train_set.drop(['RUL'], axis=1)\n",
    "\n",
    "y_test = test_set['RUL']\n",
    "x_test = test_set.drop(['RUL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-constant features:  35\n",
      "Number of quasi-constant features:  7\n",
      "Quasi-constant features: \n",
      "fan_eff_mod\n",
      "fan_flow_mod\n",
      "LPC_eff_mod\n",
      "LPC_flow_mod\n",
      "HPC_eff_mod\n",
      "HPC_flow_mod\n",
      "HPT_flow_mod\n",
      "Train shape:  (5263447, 35)\n"
     ]
    }
   ],
   "source": [
    "x_train.drop(labels=[x for x in columns_aux if x in x_train.columns], axis=1, inplace=True)\n",
    "\n",
    "constant_features = get_quasi_constant_features(x_train, variance_th=0.0)\n",
    "x_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "print(\"Train shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_holdout, y_train, y_holdout = train_test_split(x_train, y_train, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: DS02/experiment_set_9\\results_0.95\\split_0\\scaler.pkl\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 233,089\n",
      "Trainable params: 233,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 123.1595\n",
      "Epoch 00001: val_loss improved from inf to 17.16080, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 123.0051 - val_loss: 17.1608\n",
      "Epoch 2/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 12.8876\n",
      "Epoch 00002: val_loss improved from 17.16080 to 8.78409, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 12.8876 - val_loss: 8.7841\n",
      "Epoch 3/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 7.5783\n",
      "Epoch 00003: val_loss improved from 8.78409 to 7.25814, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.5757 - val_loss: 7.2581\n",
      "Epoch 4/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 5.5637\n",
      "Epoch 00004: val_loss improved from 7.25814 to 4.63405, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.5631 - val_loss: 4.6341\n",
      "Epoch 5/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 4.6525\n",
      "Epoch 00005: val_loss improved from 4.63405 to 4.19858, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.6523 - val_loss: 4.1986\n",
      "Epoch 6/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 4.0619\n",
      "Epoch 00006: val_loss did not improve from 4.19858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 4.0643 - val_loss: 4.5098\n",
      "Epoch 7/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 3.6703\n",
      "Epoch 00007: val_loss improved from 4.19858 to 3.26783, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.6703 - val_loss: 3.2678\n",
      "Epoch 8/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 3.3555\n",
      "Epoch 00008: val_loss did not improve from 3.26783\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.3550 - val_loss: 3.3009\n",
      "Epoch 9/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.1432\n",
      "Epoch 00009: val_loss improved from 3.26783 to 2.69525, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.1433 - val_loss: 2.6953\n",
      "Epoch 10/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.9303\n",
      "Epoch 00010: val_loss did not improve from 2.69525\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.9303 - val_loss: 3.3505\n",
      "Epoch 11/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.7608\n",
      "Epoch 00011: val_loss improved from 2.69525 to 2.33450, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.7607 - val_loss: 2.3345\n",
      "Epoch 12/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.6240\n",
      "Epoch 00012: val_loss improved from 2.33450 to 2.20609, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6233 - val_loss: 2.2061\n",
      "Epoch 13/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.5163\n",
      "Epoch 00013: val_loss did not improve from 2.20609\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5157 - val_loss: 2.5451\n",
      "Epoch 14/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.4075\n",
      "Epoch 00014: val_loss did not improve from 2.20609\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.4074 - val_loss: 2.4496\n",
      "Epoch 15/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.3151\n",
      "Epoch 00015: val_loss improved from 2.20609 to 2.01117, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.3150 - val_loss: 2.0112\n",
      "Epoch 16/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.2193- E\n",
      "Epoch 00016: val_loss did not improve from 2.01117\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.2193 - val_loss: 2.8815\n",
      "Epoch 17/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.1388\n",
      "Epoch 00017: val_loss improved from 2.01117 to 1.77991, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1385 - val_loss: 1.7799\n",
      "Epoch 18/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.0395\n",
      "Epoch 00018: val_loss did not improve from 1.77991\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0395 - val_loss: 2.1424\n",
      "Epoch 19/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.0149\n",
      "Epoch 00019: val_loss improved from 1.77991 to 1.73454, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0147 - val_loss: 1.7345\n",
      "Epoch 20/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 1.9664\n",
      "Epoch 00020: val_loss did not improve from 1.73454\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9667 - val_loss: 1.7669\n",
      "Epoch 21/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.8962\n",
      "Epoch 00021: val_loss did not improve from 1.73454\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8961 - val_loss: 2.3073\n",
      "Epoch 22/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 1.8529\n",
      "Epoch 00022: val_loss improved from 1.73454 to 1.53746, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8522 - val_loss: 1.5375\n",
      "Epoch 23/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.7892\n",
      "Epoch 00023: val_loss did not improve from 1.53746\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7894 - val_loss: 2.6050\n",
      "Epoch 24/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.7624\n",
      "Epoch 00024: val_loss did not improve from 1.53746\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7635 - val_loss: 4.6178\n",
      "Epoch 25/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7443\n",
      "Epoch 00025: val_loss improved from 1.53746 to 1.52861, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7440 - val_loss: 1.5286\n",
      "Epoch 26/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.7127\n",
      "Epoch 00026: val_loss did not improve from 1.52861\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7124 - val_loss: 1.6130\n",
      "Epoch 27/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.6335\n",
      "Epoch 00027: val_loss improved from 1.52861 to 1.23016, saving model to DS02/experiment_set_9\\results_0.95\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6334 - val_loss: 1.2302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6618\n",
      "Epoch 00028: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6620 - val_loss: 1.7382\n",
      "Epoch 29/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5934\n",
      "Epoch 00029: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5932 - val_loss: 1.4337\n",
      "Epoch 30/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.5789\n",
      "Epoch 00030: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5784 - val_loss: 1.6961\n",
      "Epoch 31/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.5459\n",
      "Epoch 00031: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5458 - val_loss: 1.5570\n",
      "Epoch 32/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.5151\n",
      "Epoch 00032: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5155 - val_loss: 3.0800\n",
      "Epoch 33/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.5100\n",
      "Epoch 00033: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5106 - val_loss: 1.7800\n",
      "Epoch 34/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.4855\n",
      "Epoch 00034: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4852 - val_loss: 1.5598\n",
      "Epoch 35/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.4579\n",
      "Epoch 00035: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4579 - val_loss: 1.7399\n",
      "Epoch 36/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.4357\n",
      "Epoch 00036: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4357 - val_loss: 1.3638\n",
      "Epoch 37/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.4070\n",
      "Epoch 00037: val_loss did not improve from 1.23016\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4077 - val_loss: 1.7832\n",
      "Epoch 00037: early stopping\n",
      "Saved training history to file: DS02/experiment_set_9\\results_0.95\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.24\n",
      "RMSE: 1.11\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_9\\results_0.95\\split_1\\scaler.pkl\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 233,089\n",
      "Trainable params: 233,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 130.1988\n",
      "Epoch 00001: val_loss improved from inf to 16.67661, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 130.1187 - val_loss: 16.6766\n",
      "Epoch 2/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 12.1684\n",
      "Epoch 00002: val_loss improved from 16.67661 to 8.31271, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 12.1610 - val_loss: 8.3127\n",
      "Epoch 3/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 7.1558\n",
      "Epoch 00003: val_loss improved from 8.31271 to 5.68073, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.1524 - val_loss: 5.6807\n",
      "Epoch 4/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 5.1875\n",
      "Epoch 00004: val_loss improved from 5.68073 to 5.01504, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.1868 - val_loss: 5.0150\n",
      "Epoch 5/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 4.3172\n",
      "Epoch 00005: val_loss improved from 5.01504 to 4.09064, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 4.3175 - val_loss: 4.0906\n",
      "Epoch 6/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 3.7808\n",
      "Epoch 00006: val_loss improved from 4.09064 to 3.67200, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.7805 - val_loss: 3.6720\n",
      "Epoch 7/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 3.3986\n",
      "Epoch 00007: val_loss improved from 3.67200 to 3.01582, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3986 - val_loss: 3.0158\n",
      "Epoch 8/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.1517\n",
      "Epoch 00008: val_loss improved from 3.01582 to 2.57822, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.1517 - val_loss: 2.5782\n",
      "Epoch 9/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.9271\n",
      "Epoch 00009: val_loss did not improve from 2.57822\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9271 - val_loss: 2.7591\n",
      "Epoch 10/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.7371\n",
      "Epoch 00010: val_loss improved from 2.57822 to 2.17178, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.7366 - val_loss: 2.1718\n",
      "Epoch 11/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.5434\n",
      "Epoch 00011: val_loss did not improve from 2.17178\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5435 - val_loss: 2.8186\n",
      "Epoch 12/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.4795\n",
      "Epoch 00012: val_loss did not improve from 2.17178\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.4795 - val_loss: 2.4685\n",
      "Epoch 13/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.3777\n",
      "Epoch 00013: val_loss improved from 2.17178 to 2.10249, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3770 - val_loss: 2.1025\n",
      "Epoch 14/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.2576\n",
      "Epoch 00014: val_loss did not improve from 2.10249\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.2570 - val_loss: 2.1425\n",
      "Epoch 15/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.1644\n",
      "Epoch 00015: val_loss improved from 2.10249 to 1.84312, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1644 - val_loss: 1.8431\n",
      "Epoch 16/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.1192\n",
      "Epoch 00016: val_loss did not improve from 1.84312\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1195 - val_loss: 2.1363\n",
      "Epoch 17/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.0489\n",
      "Epoch 00017: val_loss did not improve from 1.84312\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0490 - val_loss: 2.1372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.9826\n",
      "Epoch 00018: val_loss improved from 1.84312 to 1.74409, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9820 - val_loss: 1.7441\n",
      "Epoch 19/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.8947\n",
      "Epoch 00019: val_loss improved from 1.74409 to 1.55508, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8943 - val_loss: 1.5551\n",
      "Epoch 20/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.8887\n",
      "Epoch 00020: val_loss did not improve from 1.55508\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8886 - val_loss: 1.6278\n",
      "Epoch 21/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8208\n",
      "Epoch 00021: val_loss improved from 1.55508 to 1.47513, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8206 - val_loss: 1.4751\n",
      "Epoch 22/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.7736\n",
      "Epoch 00022: val_loss did not improve from 1.47513\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7735 - val_loss: 2.1117\n",
      "Epoch 23/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.7494\n",
      "Epoch 00023: val_loss did not improve from 1.47513\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7493 - val_loss: 1.6899\n",
      "Epoch 24/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.6951\n",
      "Epoch 00024: val_loss did not improve from 1.47513\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6953 - val_loss: 1.7948\n",
      "Epoch 25/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.7142\n",
      "Epoch 00025: val_loss improved from 1.47513 to 1.28984, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 29s 4ms/step - loss: 1.7141 - val_loss: 1.2898\n",
      "Epoch 26/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.6295\n",
      "Epoch 00026: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6292 - val_loss: 1.6333\n",
      "Epoch 27/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.6021\n",
      "Epoch 00027: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6016 - val_loss: 1.4637\n",
      "Epoch 28/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5786\n",
      "Epoch 00028: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.5785 - val_loss: 1.4373\n",
      "Epoch 29/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5846\n",
      "Epoch 00029: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5846 - val_loss: 2.5142\n",
      "Epoch 30/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.5292\n",
      "Epoch 00030: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.5290 - val_loss: 1.5243\n",
      "Epoch 31/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5164\n",
      "Epoch 00031: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5165 - val_loss: 1.4039\n",
      "Epoch 32/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 1.4841\n",
      "Epoch 00032: val_loss did not improve from 1.28984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4836 - val_loss: 1.5115\n",
      "Epoch 33/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.4755\n",
      "Epoch 00033: val_loss improved from 1.28984 to 1.24250, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4753 - val_loss: 1.2425\n",
      "Epoch 34/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.4482\n",
      "Epoch 00034: val_loss improved from 1.24250 to 1.16885, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4476 - val_loss: 1.1688\n",
      "Epoch 35/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.3961\n",
      "Epoch 00035: val_loss did not improve from 1.16885\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3959 - val_loss: 1.2327\n",
      "Epoch 36/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 1.4271\n",
      "Epoch 00036: val_loss improved from 1.16885 to 1.16013, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4263 - val_loss: 1.1601\n",
      "Epoch 37/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.4115\n",
      "Epoch 00037: val_loss did not improve from 1.16013\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4115 - val_loss: 1.3371\n",
      "Epoch 38/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3424\n",
      "Epoch 00038: val_loss did not improve from 1.16013\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3427 - val_loss: 1.6146\n",
      "Epoch 39/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.3304\n",
      "Epoch 00039: val_loss did not improve from 1.16013\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3325 - val_loss: 2.1762\n",
      "Epoch 40/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3276\n",
      "Epoch 00040: val_loss improved from 1.16013 to 1.15926, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3279 - val_loss: 1.1593\n",
      "Epoch 41/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.3261\n",
      "Epoch 00041: val_loss improved from 1.15926 to 1.06721, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3254 - val_loss: 1.0672\n",
      "Epoch 42/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.2869\n",
      "Epoch 00042: val_loss did not improve from 1.06721\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2870 - val_loss: 1.7618\n",
      "Epoch 43/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.2993\n",
      "Epoch 00043: val_loss did not improve from 1.06721\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2996 - val_loss: 1.1006\n",
      "Epoch 44/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.2594\n",
      "Epoch 00044: val_loss did not improve from 1.06721\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2595 - val_loss: 1.6582\n",
      "Epoch 45/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.2799\n",
      "Epoch 00045: val_loss did not improve from 1.06721\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2797 - val_loss: 1.3928\n",
      "Epoch 46/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.2759\n",
      "Epoch 00046: val_loss did not improve from 1.06721\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2773 - val_loss: 1.8920\n",
      "Epoch 47/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.2272\n",
      "Epoch 00047: val_loss improved from 1.06721 to 1.05310, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2269 - val_loss: 1.0531\n",
      "Epoch 48/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.2159\n",
      "Epoch 00048: val_loss improved from 1.05310 to 0.95739, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2153 - val_loss: 0.9574\n",
      "Epoch 49/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.2242\n",
      "Epoch 00049: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2242 - val_loss: 1.0412\n",
      "Epoch 50/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.2179\n",
      "Epoch 00050: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2179 - val_loss: 1.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.1719\n",
      "Epoch 00051: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1724 - val_loss: 1.5041\n",
      "Epoch 52/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.1731\n",
      "Epoch 00052: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1729 - val_loss: 1.3266\n",
      "Epoch 53/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.1678\n",
      "Epoch 00053: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1675 - val_loss: 0.9612\n",
      "Epoch 54/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.1438\n",
      "Epoch 00054: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1438 - val_loss: 1.1647\n",
      "Epoch 55/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.1725\n",
      "Epoch 00055: val_loss did not improve from 0.95739\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1722 - val_loss: 1.0806\n",
      "Epoch 56/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.1477\n",
      "Epoch 00056: val_loss improved from 0.95739 to 0.80224, saving model to DS02/experiment_set_9\\results_0.95\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1472 - val_loss: 0.8022\n",
      "Epoch 57/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.1161\n",
      "Epoch 00057: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1160 - val_loss: 0.9832\n",
      "Epoch 58/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.1131\n",
      "Epoch 00058: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1127 - val_loss: 0.9121\n",
      "Epoch 59/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.1333\n",
      "Epoch 00059: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1330 - val_loss: 0.8459\n",
      "Epoch 60/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.0985\n",
      "Epoch 00060: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.0985 - val_loss: 1.1898\n",
      "Epoch 61/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.0980\n",
      "Epoch 00061: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.0980 - val_loss: 1.0386\n",
      "Epoch 62/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.0738\n",
      "Epoch 00062: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.0738 - val_loss: 1.2431\n",
      "Epoch 63/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.1142\n",
      "Epoch 00063: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1142 - val_loss: 1.0079\n",
      "Epoch 64/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.0914\n",
      "Epoch 00064: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.0917 - val_loss: 1.0767\n",
      "Epoch 65/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.0512\n",
      "Epoch 00065: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.0512 - val_loss: 1.2358\n",
      "Epoch 66/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.0380\n",
      "Epoch 00066: val_loss did not improve from 0.80224\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.0377 - val_loss: 0.8617\n",
      "Epoch 00066: early stopping\n",
      "Saved training history to file: DS02/experiment_set_9\\results_0.95\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.82\n",
      "RMSE: 0.91\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_9\\results_0.95\\split_2\\scaler.pkl\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 233,089\n",
      "Trainable params: 233,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 125.0284\n",
      "Epoch 00001: val_loss improved from inf to 16.91738, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 124.8517 - val_loss: 16.9174\n",
      "Epoch 2/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 12.8250\n",
      "Epoch 00002: val_loss improved from 16.91738 to 9.43441, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 12.8234 - val_loss: 9.4344\n",
      "Epoch 3/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 7.7295\n",
      "Epoch 00003: val_loss improved from 9.43441 to 6.54835, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 7.7287 - val_loss: 6.5483\n",
      "Epoch 4/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 5.7086\n",
      "Epoch 00004: val_loss improved from 6.54835 to 5.26963, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 5.7055 - val_loss: 5.2696\n",
      "Epoch 5/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 4.6634\n",
      "Epoch 00005: val_loss improved from 5.26963 to 4.74281, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 4.6635 - val_loss: 4.7428\n",
      "Epoch 6/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 4.0209\n",
      "Epoch 00006: val_loss improved from 4.74281 to 4.41093, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.0211 - val_loss: 4.4109\n",
      "Epoch 7/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.6708\n",
      "Epoch 00007: val_loss improved from 4.41093 to 3.95169, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.6706 - val_loss: 3.9517\n",
      "Epoch 8/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 3.3869\n",
      "Epoch 00008: val_loss improved from 3.95169 to 3.10438, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3865 - val_loss: 3.1044\n",
      "Epoch 9/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.1716\n",
      "Epoch 00009: val_loss improved from 3.10438 to 2.91930, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.1717 - val_loss: 2.9193\n",
      "Epoch 10/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.9725\n",
      "Epoch 00010: val_loss did not improve from 2.91930\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.9754 - val_loss: 4.2009\n",
      "Epoch 11/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.8285\n",
      "Epoch 00011: val_loss improved from 2.91930 to 2.80598, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.8283 - val_loss: 2.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.7061\n",
      "Epoch 00012: val_loss improved from 2.80598 to 2.36036, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7056 - val_loss: 2.3604\n",
      "Epoch 13/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 2.5426\n",
      "Epoch 00013: val_loss improved from 2.36036 to 2.06704, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5414 - val_loss: 2.0670\n",
      "Epoch 14/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.4396\n",
      "Epoch 00014: val_loss did not improve from 2.06704\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.4395 - val_loss: 3.4772\n",
      "Epoch 15/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.3670\n",
      "Epoch 00015: val_loss did not improve from 2.06704\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.3667 - val_loss: 2.7446\n",
      "Epoch 16/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.2646\n",
      "Epoch 00016: val_loss improved from 2.06704 to 2.01306, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.2645 - val_loss: 2.0131\n",
      "Epoch 17/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 2.1734\n",
      "Epoch 00017: val_loss did not improve from 2.01306\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1725 - val_loss: 2.1299\n",
      "Epoch 18/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.1240\n",
      "Epoch 00018: val_loss did not improve from 2.01306\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1249 - val_loss: 2.7278\n",
      "Epoch 19/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.0711\n",
      "Epoch 00019: val_loss improved from 2.01306 to 1.95523, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0709 - val_loss: 1.9552\n",
      "Epoch 20/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.9898\n",
      "Epoch 00020: val_loss improved from 1.95523 to 1.84638, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9896 - val_loss: 1.8464\n",
      "Epoch 21/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.9348\n",
      "Epoch 00021: val_loss improved from 1.84638 to 1.66699, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9347 - val_loss: 1.6670\n",
      "Epoch 22/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.9046\n",
      "Epoch 00022: val_loss improved from 1.66699 to 1.63820, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9045 - val_loss: 1.6382\n",
      "Epoch 23/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.8529\n",
      "Epoch 00023: val_loss did not improve from 1.63820\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8527 - val_loss: 1.7297\n",
      "Epoch 24/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8262\n",
      "Epoch 00024: val_loss did not improve from 1.63820\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8261 - val_loss: 1.9223\n",
      "Epoch 25/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.7939\n",
      "Epoch 00025: val_loss did not improve from 1.63820\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7939 - val_loss: 1.9180\n",
      "Epoch 26/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7622\n",
      "Epoch 00026: val_loss did not improve from 1.63820\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7630 - val_loss: 2.2728\n",
      "Epoch 27/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.6943\n",
      "Epoch 00027: val_loss did not improve from 1.63820\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6944 - val_loss: 1.7633\n",
      "Epoch 28/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.6675\n",
      "Epoch 00028: val_loss improved from 1.63820 to 1.42498, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6674 - val_loss: 1.4250\n",
      "Epoch 29/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.6574\n",
      "Epoch 00029: val_loss did not improve from 1.42498\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6576 - val_loss: 1.4518\n",
      "Epoch 30/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.6072\n",
      "Epoch 00030: val_loss did not improve from 1.42498\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6069 - val_loss: 1.5072\n",
      "Epoch 31/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5570\n",
      "Epoch 00031: val_loss did not improve from 1.42498\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5570 - val_loss: 1.6591\n",
      "Epoch 32/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.5366\n",
      "Epoch 00032: val_loss did not improve from 1.42498\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5369 - val_loss: 1.8292\n",
      "Epoch 33/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5183\n",
      "Epoch 00033: val_loss did not improve from 1.42498\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5183 - val_loss: 1.6945\n",
      "Epoch 34/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.5448\n",
      "Epoch 00034: val_loss improved from 1.42498 to 1.37964, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5448 - val_loss: 1.3796\n",
      "Epoch 35/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4727\n",
      "Epoch 00035: val_loss improved from 1.37964 to 1.34364, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4724 - val_loss: 1.3436\n",
      "Epoch 36/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.4711\n",
      "Epoch 00036: val_loss improved from 1.34364 to 1.10041, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4705 - val_loss: 1.1004\n",
      "Epoch 37/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.4467\n",
      "Epoch 00037: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4477 - val_loss: 2.0684\n",
      "Epoch 38/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.4161\n",
      "Epoch 00038: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4163 - val_loss: 1.4112\n",
      "Epoch 39/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3953\n",
      "Epoch 00039: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3952 - val_loss: 1.7269\n",
      "Epoch 40/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.4003\n",
      "Epoch 00040: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3999 - val_loss: 1.2910\n",
      "Epoch 41/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 1.3746\n",
      "Epoch 00041: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3742 - val_loss: 1.4542\n",
      "Epoch 42/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3897\n",
      "Epoch 00042: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3896 - val_loss: 1.1335\n",
      "Epoch 43/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3371\n",
      "Epoch 00043: val_loss did not improve from 1.10041\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3367 - val_loss: 1.3296\n",
      "Epoch 44/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.3266\n",
      "Epoch 00044: val_loss improved from 1.10041 to 1.04944, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3264 - val_loss: 1.0494\n",
      "Epoch 45/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3060\n",
      "Epoch 00045: val_loss did not improve from 1.04944\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3060 - val_loss: 1.2114\n",
      "Epoch 46/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2867\n",
      "Epoch 00046: val_loss did not improve from 1.04944\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2867 - val_loss: 1.2024\n",
      "Epoch 47/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.2946\n",
      "Epoch 00047: val_loss did not improve from 1.04944\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2944 - val_loss: 1.2817\n",
      "Epoch 48/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.2611\n",
      "Epoch 00048: val_loss improved from 1.04944 to 1.04364, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2607 - val_loss: 1.0436\n",
      "Epoch 49/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.2458\n",
      "Epoch 00049: val_loss did not improve from 1.04364\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2458 - val_loss: 1.2670\n",
      "Epoch 50/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.2451\n",
      "Epoch 00050: val_loss did not improve from 1.04364\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2491 - val_loss: 2.4321\n",
      "Epoch 51/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.2575\n",
      "Epoch 00051: val_loss did not improve from 1.04364\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2575 - val_loss: 1.4446\n",
      "Epoch 52/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.2379\n",
      "Epoch 00052: val_loss did not improve from 1.04364\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2384 - val_loss: 1.2601\n",
      "Epoch 53/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.2276\n",
      "Epoch 00053: val_loss improved from 1.04364 to 0.87547, saving model to DS02/experiment_set_9\\results_0.95\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2267 - val_loss: 0.8755\n",
      "Epoch 54/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.2043\n",
      "Epoch 00054: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2039 - val_loss: 1.2516\n",
      "Epoch 55/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.2022\n",
      "Epoch 00055: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2024 - val_loss: 1.3599\n",
      "Epoch 56/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.1943\n",
      "Epoch 00056: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1936 - val_loss: 0.9881\n",
      "Epoch 57/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.1545\n",
      "Epoch 00057: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1548 - val_loss: 1.2603\n",
      "Epoch 58/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.1744\n",
      "Epoch 00058: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1747 - val_loss: 1.1575\n",
      "Epoch 59/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.1460\n",
      "Epoch 00059: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1474 - val_loss: 1.2782\n",
      "Epoch 60/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.1603\n",
      "Epoch 00060: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1609 - val_loss: 1.4396\n",
      "Epoch 61/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.1132\n",
      "Epoch 00061: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1134 - val_loss: 1.0610\n",
      "Epoch 62/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.1278\n",
      "Epoch 00062: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1276 - val_loss: 0.9679\n",
      "Epoch 63/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.1254\n",
      "Epoch 00063: val_loss did not improve from 0.87547\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1255 - val_loss: 1.1245\n",
      "Epoch 00063: early stopping\n",
      "Saved training history to file: DS02/experiment_set_9\\results_0.95\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.87\n",
      "RMSE: 0.93\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_9\\results_0.9\\split_0\\scaler.pkl\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,577\n",
      "Trainable params: 232,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 121.0532\n",
      "Epoch 00001: val_loss improved from inf to 17.04404, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 120.8375 - val_loss: 17.0440\n",
      "Epoch 2/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 12.9596\n",
      "Epoch 00002: val_loss improved from 17.04404 to 8.60997, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 12.9575 - val_loss: 8.6100\n",
      "Epoch 3/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 7.4702\n",
      "Epoch 00003: val_loss improved from 8.60997 to 7.20629, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.4690 - val_loss: 7.2063\n",
      "Epoch 4/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 5.6682\n",
      "Epoch 00004: val_loss improved from 7.20629 to 4.82471, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.6671 - val_loss: 4.8247\n",
      "Epoch 5/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 4.8425\n",
      "Epoch 00005: val_loss improved from 4.82471 to 3.79216, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.8422 - val_loss: 3.7922\n",
      "Epoch 6/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 4.2067\n",
      "Epoch 00006: val_loss improved from 3.79216 to 3.72918, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.2067 - val_loss: 3.7292\n",
      "Epoch 7/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.8925\n",
      "Epoch 00007: val_loss improved from 3.72918 to 3.16722, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.8925 - val_loss: 3.1672\n",
      "Epoch 8/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 3.5854\n",
      "Epoch 00008: val_loss did not improve from 3.16722\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.5853 - val_loss: 3.4180\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.3446\n",
      "Epoch 00009: val_loss improved from 3.16722 to 3.10204, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3448 - val_loss: 3.1020\n",
      "Epoch 10/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.1065\n",
      "Epoch 00010: val_loss did not improve from 3.10204\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.1073 - val_loss: 6.2895\n",
      "Epoch 11/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.0296\n",
      "Epoch 00011: val_loss improved from 3.10204 to 2.93472, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.0294 - val_loss: 2.9347\n",
      "Epoch 12/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.8536\n",
      "Epoch 00012: val_loss improved from 2.93472 to 2.44055, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.8533 - val_loss: 2.4405\n",
      "Epoch 13/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.7243\n",
      "Epoch 00013: val_loss did not improve from 2.44055\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7242 - val_loss: 2.5418\n",
      "Epoch 14/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.6371\n",
      "Epoch 00014: val_loss improved from 2.44055 to 2.40120, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.6370 - val_loss: 2.4012\n",
      "Epoch 15/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.5416\n",
      "Epoch 00015: val_loss improved from 2.40120 to 2.31717, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.5415 - val_loss: 2.3172\n",
      "Epoch 16/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 2.4127\n",
      "Epoch 00016: val_loss did not improve from 2.31717\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4133 - val_loss: 2.9756\n",
      "Epoch 17/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 2.3546\n",
      "Epoch 00017: val_loss improved from 2.31717 to 2.16260, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3546 - val_loss: 2.1626\n",
      "Epoch 18/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.2118\n",
      "Epoch 00018: val_loss improved from 2.16260 to 1.93826, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2112 - val_loss: 1.9383\n",
      "Epoch 19/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.1722\n",
      "Epoch 00019: val_loss did not improve from 1.93826\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1722 - val_loss: 1.9893\n",
      "Epoch 20/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.1671- ETA: 0s - l\n",
      "Epoch 00020: val_loss improved from 1.93826 to 1.64342, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1671 - val_loss: 1.6434\n",
      "Epoch 21/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.0708\n",
      "Epoch 00021: val_loss did not improve from 1.64342\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0709 - val_loss: 3.1699\n",
      "Epoch 22/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.0481\n",
      "Epoch 00022: val_loss improved from 1.64342 to 1.58220, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0477 - val_loss: 1.5822\n",
      "Epoch 23/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.9962\n",
      "Epoch 00023: val_loss did not improve from 1.58220\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9961 - val_loss: 1.9255\n",
      "Epoch 24/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.9403\n",
      "Epoch 00024: val_loss did not improve from 1.58220\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9397 - val_loss: 1.6585\n",
      "Epoch 25/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.9234\n",
      "Epoch 00025: val_loss improved from 1.58220 to 1.52577, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9229 - val_loss: 1.5258\n",
      "Epoch 26/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.8515\n",
      "Epoch 00026: val_loss did not improve from 1.52577\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8516 - val_loss: 2.1804\n",
      "Epoch 27/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8284\n",
      "Epoch 00027: val_loss did not improve from 1.52577\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8299 - val_loss: 1.9927\n",
      "Epoch 28/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.7735\n",
      "Epoch 00028: val_loss did not improve from 1.52577\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7735 - val_loss: 3.8293\n",
      "Epoch 29/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.7867\n",
      "Epoch 00029: val_loss improved from 1.52577 to 1.50595, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7865 - val_loss: 1.5060\n",
      "Epoch 30/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.7102\n",
      "Epoch 00030: val_loss did not improve from 1.50595\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7105 - val_loss: 2.1885\n",
      "Epoch 31/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.6835\n",
      "Epoch 00031: val_loss did not improve from 1.50595\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6835 - val_loss: 1.8971\n",
      "Epoch 32/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.6452\n",
      "Epoch 00032: val_loss did not improve from 1.50595\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6456 - val_loss: 1.9790\n",
      "Epoch 33/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.6693\n",
      "Epoch 00033: val_loss did not improve from 1.50595\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6691 - val_loss: 1.5264\n",
      "Epoch 34/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.5753\n",
      "Epoch 00034: val_loss improved from 1.50595 to 1.50263, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5758 - val_loss: 1.5026\n",
      "Epoch 35/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.5502\n",
      "Epoch 00035: val_loss improved from 1.50263 to 1.32036, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5498 - val_loss: 1.3204\n",
      "Epoch 36/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5536\n",
      "Epoch 00036: val_loss did not improve from 1.32036\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5539 - val_loss: 1.9396\n",
      "Epoch 37/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5570\n",
      "Epoch 00037: val_loss did not improve from 1.32036\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5573 - val_loss: 1.4807\n",
      "Epoch 38/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4717\n",
      "Epoch 00038: val_loss did not improve from 1.32036\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4721 - val_loss: 1.5284\n",
      "Epoch 39/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.4617\n",
      "Epoch 00039: val_loss did not improve from 1.32036\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4616 - val_loss: 1.4139\n",
      "Epoch 40/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.4630\n",
      "Epoch 00040: val_loss improved from 1.32036 to 1.31421, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4630 - val_loss: 1.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.4709\n",
      "Epoch 00041: val_loss did not improve from 1.31421\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4712 - val_loss: 1.3768\n",
      "Epoch 42/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4046\n",
      "Epoch 00042: val_loss did not improve from 1.31421\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4041 - val_loss: 1.3216\n",
      "Epoch 43/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.4164\n",
      "Epoch 00043: val_loss did not improve from 1.31421\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4167 - val_loss: 1.4275\n",
      "Epoch 44/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.4096\n",
      "Epoch 00044: val_loss did not improve from 1.31421\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4099 - val_loss: 2.5349\n",
      "Epoch 45/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.3812\n",
      "Epoch 00045: val_loss improved from 1.31421 to 1.24733, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3805 - val_loss: 1.2473\n",
      "Epoch 46/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3577\n",
      "Epoch 00046: val_loss did not improve from 1.24733\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3580 - val_loss: 1.3537\n",
      "Epoch 47/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.3831\n",
      "Epoch 00047: val_loss did not improve from 1.24733\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3829 - val_loss: 1.4117\n",
      "Epoch 48/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3578\n",
      "Epoch 00048: val_loss did not improve from 1.24733\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3584 - val_loss: 2.0451\n",
      "Epoch 49/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3399\n",
      "Epoch 00049: val_loss did not improve from 1.24733\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3399 - val_loss: 1.5681\n",
      "Epoch 50/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3379\n",
      "Epoch 00050: val_loss improved from 1.24733 to 1.00316, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3377 - val_loss: 1.0032\n",
      "Epoch 51/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3081\n",
      "Epoch 00051: val_loss did not improve from 1.00316\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3088 - val_loss: 2.3087\n",
      "Epoch 52/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.2807\n",
      "Epoch 00052: val_loss did not improve from 1.00316\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2810 - val_loss: 1.3382\n",
      "Epoch 53/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2265\n",
      "Epoch 00053: val_loss improved from 1.00316 to 0.99757, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2263 - val_loss: 0.9976\n",
      "Epoch 54/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.2912\n",
      "Epoch 00054: val_loss did not improve from 0.99757\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2923 - val_loss: 2.1821\n",
      "Epoch 55/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.2286\n",
      "Epoch 00055: val_loss did not improve from 0.99757\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2286 - val_loss: 1.3324\n",
      "Epoch 56/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.2479\n",
      "Epoch 00056: val_loss improved from 0.99757 to 0.94858, saving model to DS02/experiment_set_9\\results_0.9\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2480 - val_loss: 0.9486\n",
      "Epoch 57/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.2586\n",
      "Epoch 00057: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2589 - val_loss: 1.2472\n",
      "Epoch 58/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.1938\n",
      "Epoch 00058: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1938 - val_loss: 1.1830\n",
      "Epoch 59/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2279\n",
      "Epoch 00059: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2277 - val_loss: 1.9018\n",
      "Epoch 60/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.2398\n",
      "Epoch 00060: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2397 - val_loss: 1.7296\n",
      "Epoch 61/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.1900\n",
      "Epoch 00061: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1898 - val_loss: 1.2205\n",
      "Epoch 62/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.1463\n",
      "Epoch 00062: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1464 - val_loss: 1.1473\n",
      "Epoch 63/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.1766\n",
      "Epoch 00063: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1766 - val_loss: 1.1171\n",
      "Epoch 64/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.1528\n",
      "Epoch 00064: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1531 - val_loss: 1.1466\n",
      "Epoch 65/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.1748\n",
      "Epoch 00065: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1747 - val_loss: 1.1697\n",
      "Epoch 66/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.1326\n",
      "Epoch 00066: val_loss did not improve from 0.94858\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1326 - val_loss: 1.0493\n",
      "Epoch 00066: early stopping\n",
      "Saved training history to file: DS02/experiment_set_9\\results_0.9\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.95\n",
      "RMSE: 0.98\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_9\\results_0.9\\split_1\\scaler.pkl\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,577\n",
      "Trainable params: 232,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 127.7566\n",
      "Epoch 00001: val_loss improved from inf to 17.18901, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 127.6100 - val_loss: 17.1890\n",
      "Epoch 2/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 14.2960\n",
      "Epoch 00002: val_loss improved from 17.18901 to 10.45555, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 14.2960 - val_loss: 10.4555\n",
      "Epoch 3/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 8.7161\n",
      "Epoch 00003: val_loss improved from 10.45555 to 6.52382, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6477/6477 [==============================] - 25s 4ms/step - loss: 8.7138 - val_loss: 6.5238\n",
      "Epoch 4/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 6.1101\n",
      "Epoch 00004: val_loss improved from 6.52382 to 6.48881, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 6.1096 - val_loss: 6.4888\n",
      "Epoch 5/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 5.0717\n",
      "Epoch 00005: val_loss improved from 6.48881 to 4.25866, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 5.0718 - val_loss: 4.2587\n",
      "Epoch 6/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 4.4265\n",
      "Epoch 00006: val_loss improved from 4.25866 to 3.77151, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 4.4256 - val_loss: 3.7715\n",
      "Epoch 7/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 4.0107\n",
      "Epoch 00007: val_loss improved from 3.77151 to 3.34171, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.0107 - val_loss: 3.3417\n",
      "Epoch 8/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.6088\n",
      "Epoch 00008: val_loss improved from 3.34171 to 2.98191, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.6087 - val_loss: 2.9819\n",
      "Epoch 9/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 3.3712\n",
      "Epoch 00009: val_loss did not improve from 2.98191\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.3709 - val_loss: 3.1493\n",
      "Epoch 10/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.1865\n",
      "Epoch 00010: val_loss did not improve from 2.98191\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.1867 - val_loss: 3.2245\n",
      "Epoch 11/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.9708\n",
      "Epoch 00011: val_loss did not improve from 2.98191\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.9709 - val_loss: 3.2041\n",
      "Epoch 12/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.8122\n",
      "Epoch 00012: val_loss improved from 2.98191 to 2.79978, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.8126 - val_loss: 2.7998\n",
      "Epoch 13/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 2.6388\n",
      "Epoch 00013: val_loss improved from 2.79978 to 2.29281, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.6382 - val_loss: 2.2928\n",
      "Epoch 14/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.5532\n",
      "Epoch 00014: val_loss improved from 2.29281 to 2.10366, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5524 - val_loss: 2.1037\n",
      "Epoch 15/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.4777\n",
      "Epoch 00015: val_loss did not improve from 2.10366\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.4777 - val_loss: 2.1675\n",
      "Epoch 16/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.3269\n",
      "Epoch 00016: val_loss did not improve from 2.10366\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.3269 - val_loss: 2.5422\n",
      "Epoch 17/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 2.2483\n",
      "Epoch 00017: val_loss improved from 2.10366 to 2.00954, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.2474 - val_loss: 2.0095\n",
      "Epoch 18/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.2122\n",
      "Epoch 00018: val_loss improved from 2.00954 to 1.93390, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.2122 - val_loss: 1.9339\n",
      "Epoch 19/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.1172\n",
      "Epoch 00019: val_loss did not improve from 1.93390\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1171 - val_loss: 2.4968\n",
      "Epoch 20/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.0734\n",
      "Epoch 00020: val_loss improved from 1.93390 to 1.77434, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0731 - val_loss: 1.7743\n",
      "Epoch 21/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.9719\n",
      "Epoch 00021: val_loss did not improve from 1.77434\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9718 - val_loss: 2.3215\n",
      "Epoch 22/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.9343\n",
      "Epoch 00022: val_loss did not improve from 1.77434\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9338 - val_loss: 1.8027\n",
      "Epoch 23/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.8933\n",
      "Epoch 00023: val_loss improved from 1.77434 to 1.47882, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8932 - val_loss: 1.4788\n",
      "Epoch 24/200\n",
      "6460/6477 [============================>.] - ETA: 0s - loss: 1.8271\n",
      "Epoch 00024: val_loss did not improve from 1.47882\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8264 - val_loss: 1.5828\n",
      "Epoch 25/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7596\n",
      "Epoch 00025: val_loss did not improve from 1.47882\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7594 - val_loss: 1.5538\n",
      "Epoch 26/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7522\n",
      "Epoch 00026: val_loss improved from 1.47882 to 1.45507, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7519 - val_loss: 1.4551\n",
      "Epoch 27/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7055\n",
      "Epoch 00027: val_loss did not improve from 1.45507\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7050 - val_loss: 1.4887\n",
      "Epoch 28/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.6722\n",
      "Epoch 00028: val_loss did not improve from 1.45507\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6721 - val_loss: 1.5923\n",
      "Epoch 29/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6211\n",
      "Epoch 00029: val_loss improved from 1.45507 to 1.28623, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6209 - val_loss: 1.2862\n",
      "Epoch 30/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 1.5843\n",
      "Epoch 00030: val_loss did not improve from 1.28623\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5846 - val_loss: 1.6371\n",
      "Epoch 31/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.5732\n",
      "Epoch 00031: val_loss did not improve from 1.28623\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5729 - val_loss: 1.4193\n",
      "Epoch 32/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.5481\n",
      "Epoch 00032: val_loss did not improve from 1.28623\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5480 - val_loss: 1.3970\n",
      "Epoch 33/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.5189\n",
      "Epoch 00033: val_loss improved from 1.28623 to 1.18587, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5187 - val_loss: 1.1859\n",
      "Epoch 34/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4686\n",
      "Epoch 00034: val_loss did not improve from 1.18587\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4687 - val_loss: 1.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.4955\n",
      "Epoch 00035: val_loss did not improve from 1.18587\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4955 - val_loss: 1.5066\n",
      "Epoch 36/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.4329\n",
      "Epoch 00036: val_loss improved from 1.18587 to 1.13014, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4329 - val_loss: 1.1301\n",
      "Epoch 37/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4398\n",
      "Epoch 00037: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4394 - val_loss: 1.5218\n",
      "Epoch 38/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4268\n",
      "Epoch 00038: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4268 - val_loss: 1.1853\n",
      "Epoch 39/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.4155\n",
      "Epoch 00039: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4155 - val_loss: 1.9440\n",
      "Epoch 40/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3723\n",
      "Epoch 00040: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3724 - val_loss: 1.3155\n",
      "Epoch 41/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3721\n",
      "Epoch 00041: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3719 - val_loss: 1.3884\n",
      "Epoch 42/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 1.3259\n",
      "Epoch 00042: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3257 - val_loss: 1.1724\n",
      "Epoch 43/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.3399\n",
      "Epoch 00043: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3406 - val_loss: 1.4980\n",
      "Epoch 44/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3109\n",
      "Epoch 00044: val_loss did not improve from 1.13014\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3107 - val_loss: 1.1637\n",
      "Epoch 45/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3322\n",
      "Epoch 00045: val_loss improved from 1.13014 to 0.93527, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3322 - val_loss: 0.9353\n",
      "Epoch 46/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3259\n",
      "Epoch 00046: val_loss did not improve from 0.93527\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3257 - val_loss: 1.1096\n",
      "Epoch 47/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.3004\n",
      "Epoch 00047: val_loss improved from 0.93527 to 0.89806, saving model to DS02/experiment_set_9\\results_0.9\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3003 - val_loss: 0.8981\n",
      "Epoch 48/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.2504\n",
      "Epoch 00048: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2502 - val_loss: 1.2443\n",
      "Epoch 49/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.2970\n",
      "Epoch 00049: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2968 - val_loss: 0.9997\n",
      "Epoch 50/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.2253\n",
      "Epoch 00050: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2253 - val_loss: 1.0332\n",
      "Epoch 51/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.2356\n",
      "Epoch 00051: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2362 - val_loss: 1.1811\n",
      "Epoch 52/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 1.2480\n",
      "Epoch 00052: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2477 - val_loss: 0.9412\n",
      "Epoch 53/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.1940\n",
      "Epoch 00053: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1934 - val_loss: 1.1247\n",
      "Epoch 54/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.1729\n",
      "Epoch 00054: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1731 - val_loss: 1.0490\n",
      "Epoch 55/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.1969\n",
      "Epoch 00055: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1967 - val_loss: 1.0125\n",
      "Epoch 56/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.1796\n",
      "Epoch 00056: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1793 - val_loss: 1.0021\n",
      "Epoch 57/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.1451\n",
      "Epoch 00057: val_loss did not improve from 0.89806\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1451 - val_loss: 1.1161\n",
      "Epoch 00057: early stopping\n",
      "Saved training history to file: DS02/experiment_set_9\\results_0.9\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.95\n",
      "RMSE: 0.97\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_9\\results_0.9\\split_2\\scaler.pkl\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,577\n",
      "Trainable params: 232,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 126.3353\n",
      "Epoch 00001: val_loss improved from inf to 17.35910, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 126.1746 - val_loss: 17.3591\n",
      "Epoch 2/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 15.3784\n",
      "Epoch 00002: val_loss improved from 17.35910 to 13.06507, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 15.3765 - val_loss: 13.0651\n",
      "Epoch 3/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 9.8960\n",
      "Epoch 00003: val_loss improved from 13.06507 to 8.08292, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 9.8931 - val_loss: 8.0829\n",
      "Epoch 4/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 6.4912\n",
      "Epoch 00004: val_loss improved from 8.08292 to 5.52355, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 6.4875 - val_loss: 5.5235\n",
      "Epoch 5/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 5.2087\n",
      "Epoch 00005: val_loss improved from 5.52355 to 5.19884, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.2093 - val_loss: 5.1988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 4.6099\n",
      "Epoch 00006: val_loss did not improve from 5.19884\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 4.6136 - val_loss: 6.8185\n",
      "Epoch 7/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 4.1650\n",
      "Epoch 00007: val_loss improved from 5.19884 to 4.92447, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.1646 - val_loss: 4.9245\n",
      "Epoch 8/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 3.8224\n",
      "Epoch 00008: val_loss improved from 4.92447 to 3.36219, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.8226 - val_loss: 3.3622\n",
      "Epoch 9/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.5293\n",
      "Epoch 00009: val_loss did not improve from 3.36219\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.5296 - val_loss: 3.7467\n",
      "Epoch 10/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 3.3302\n",
      "Epoch 00010: val_loss improved from 3.36219 to 2.88589, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3304 - val_loss: 2.8859\n",
      "Epoch 11/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.1466\n",
      "Epoch 00011: val_loss did not improve from 2.88589\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.1468 - val_loss: 3.1195\n",
      "Epoch 12/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.9472\n",
      "Epoch 00012: val_loss improved from 2.88589 to 2.76981, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.9472 - val_loss: 2.7698\n",
      "Epoch 13/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.8760\n",
      "Epoch 00013: val_loss improved from 2.76981 to 2.50019, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.8760 - val_loss: 2.5002\n",
      "Epoch 14/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.6975\n",
      "Epoch 00014: val_loss improved from 2.50019 to 2.46100, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6967 - val_loss: 2.4610\n",
      "Epoch 15/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.5534\n",
      "Epoch 00015: val_loss did not improve from 2.46100\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5539 - val_loss: 2.5264\n",
      "Epoch 16/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.5263\n",
      "Epoch 00016: val_loss did not improve from 2.46100\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5279 - val_loss: 4.8495\n",
      "Epoch 17/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 2.4754\n",
      "Epoch 00017: val_loss did not improve from 2.46100\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4758 - val_loss: 2.5806\n",
      "Epoch 18/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.3491\n",
      "Epoch 00018: val_loss did not improve from 2.46100\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.3485 - val_loss: 2.5710\n",
      "Epoch 19/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.2582\n",
      "Epoch 00019: val_loss improved from 2.46100 to 1.95341, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.2579 - val_loss: 1.9534\n",
      "Epoch 20/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.1876\n",
      "Epoch 00020: val_loss did not improve from 1.95341\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1873 - val_loss: 2.1764\n",
      "Epoch 21/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 2.1086\n",
      "Epoch 00021: val_loss did not improve from 1.95341\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1097 - val_loss: 2.2761\n",
      "Epoch 22/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.0846\n",
      "Epoch 00022: val_loss improved from 1.95341 to 1.83678, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0844 - val_loss: 1.8368\n",
      "Epoch 23/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.0278\n",
      "Epoch 00023: val_loss did not improve from 1.83678\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0278 - val_loss: 1.9734\n",
      "Epoch 24/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.0117\n",
      "Epoch 00024: val_loss did not improve from 1.83678\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0117 - val_loss: 2.7259\n",
      "Epoch 25/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.9537\n",
      "Epoch 00025: val_loss did not improve from 1.83678\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9535 - val_loss: 2.3092\n",
      "Epoch 26/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.9477\n",
      "Epoch 00026: val_loss did not improve from 1.83678\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9476 - val_loss: 2.5694\n",
      "Epoch 27/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8742\n",
      "Epoch 00027: val_loss did not improve from 1.83678\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8746 - val_loss: 2.0224\n",
      "Epoch 28/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.8511\n",
      "Epoch 00028: val_loss improved from 1.83678 to 1.54548, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8505 - val_loss: 1.5455\n",
      "Epoch 29/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8311\n",
      "Epoch 00029: val_loss did not improve from 1.54548\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8309 - val_loss: 1.6664\n",
      "Epoch 30/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.7874\n",
      "Epoch 00030: val_loss did not improve from 1.54548\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7871 - val_loss: 1.5532\n",
      "Epoch 31/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.7422\n",
      "Epoch 00031: val_loss did not improve from 1.54548\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7421 - val_loss: 1.5735\n",
      "Epoch 32/200\n",
      "6462/6477 [============================>.] - ETA: 0s - loss: 1.7339\n",
      "Epoch 00032: val_loss did not improve from 1.54548\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7338 - val_loss: 1.8258\n",
      "Epoch 33/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.6626\n",
      "Epoch 00033: val_loss improved from 1.54548 to 1.41711, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6626 - val_loss: 1.4171\n",
      "Epoch 34/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6931\n",
      "Epoch 00034: val_loss improved from 1.41711 to 1.36427, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6929 - val_loss: 1.3643\n",
      "Epoch 35/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.6522\n",
      "Epoch 00035: val_loss did not improve from 1.36427\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6521 - val_loss: 1.4760\n",
      "Epoch 36/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.6171\n",
      "Epoch 00036: val_loss did not improve from 1.36427\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6183 - val_loss: 3.3967\n",
      "Epoch 37/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.5900\n",
      "Epoch 00037: val_loss did not improve from 1.36427\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5901 - val_loss: 1.5719\n",
      "Epoch 38/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.5846\n",
      "Epoch 00038: val_loss improved from 1.36427 to 1.29959, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5844 - val_loss: 1.2996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.5823\n",
      "Epoch 00039: val_loss did not improve from 1.29959\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5823 - val_loss: 1.4175\n",
      "Epoch 40/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.5256- ETA: 0s - los\n",
      "Epoch 00040: val_loss did not improve from 1.29959\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5261 - val_loss: 2.0034\n",
      "Epoch 41/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5430\n",
      "Epoch 00041: val_loss improved from 1.29959 to 1.23430, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5425 - val_loss: 1.2343\n",
      "Epoch 42/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.4846- ETA: 0s - loss: 1.484\n",
      "Epoch 00042: val_loss did not improve from 1.23430\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4844 - val_loss: 1.5593\n",
      "Epoch 43/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5152\n",
      "Epoch 00043: val_loss did not improve from 1.23430\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5152 - val_loss: 1.5142\n",
      "Epoch 44/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.5183\n",
      "Epoch 00044: val_loss did not improve from 1.23430\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5179 - val_loss: 1.2770\n",
      "Epoch 45/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.4594\n",
      "Epoch 00045: val_loss did not improve from 1.23430\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4592 - val_loss: 1.3005\n",
      "Epoch 46/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.4699\n",
      "Epoch 00046: val_loss improved from 1.23430 to 1.20560, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4699 - val_loss: 1.2056\n",
      "Epoch 47/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.4433\n",
      "Epoch 00047: val_loss did not improve from 1.20560\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4432 - val_loss: 1.5888\n",
      "Epoch 48/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3872\n",
      "Epoch 00048: val_loss did not improve from 1.20560\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3870 - val_loss: 1.2106\n",
      "Epoch 49/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.4275\n",
      "Epoch 00049: val_loss improved from 1.20560 to 1.06831, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4275 - val_loss: 1.0683\n",
      "Epoch 50/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4024\n",
      "Epoch 00050: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4028 - val_loss: 1.1850\n",
      "Epoch 51/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3836\n",
      "Epoch 00051: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3830 - val_loss: 1.2787\n",
      "Epoch 52/200\n",
      "6461/6477 [============================>.] - ETA: 0s - loss: 1.3677\n",
      "Epoch 00052: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3687 - val_loss: 1.8373\n",
      "Epoch 53/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3727\n",
      "Epoch 00053: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3726 - val_loss: 1.2913\n",
      "Epoch 54/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3300\n",
      "Epoch 00054: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3300 - val_loss: 1.2614\n",
      "Epoch 55/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.3592\n",
      "Epoch 00055: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3588 - val_loss: 1.1569\n",
      "Epoch 56/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.2993\n",
      "Epoch 00056: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2991 - val_loss: 1.2084\n",
      "Epoch 57/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3107\n",
      "Epoch 00057: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3106 - val_loss: 1.1077\n",
      "Epoch 58/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2901\n",
      "Epoch 00058: val_loss did not improve from 1.06831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2902 - val_loss: 1.1256\n",
      "Epoch 59/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.2917\n",
      "Epoch 00059: val_loss improved from 1.06831 to 1.02721, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.2916 - val_loss: 1.0272\n",
      "Epoch 60/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2804\n",
      "Epoch 00060: val_loss improved from 1.02721 to 0.98725, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2802 - val_loss: 0.9872\n",
      "Epoch 61/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3131\n",
      "Epoch 00061: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3126 - val_loss: 1.3761\n",
      "Epoch 62/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.2463\n",
      "Epoch 00062: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2465 - val_loss: 1.7112\n",
      "Epoch 63/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.2781\n",
      "Epoch 00063: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2782 - val_loss: 1.3147\n",
      "Epoch 64/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.2836\n",
      "Epoch 00064: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2836 - val_loss: 1.1053\n",
      "Epoch 65/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.2232\n",
      "Epoch 00065: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2234 - val_loss: 1.7054\n",
      "Epoch 66/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.2459\n",
      "Epoch 00066: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2458 - val_loss: 1.2118\n",
      "Epoch 67/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.2159\n",
      "Epoch 00067: val_loss did not improve from 0.98725\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2159 - val_loss: 1.1478\n",
      "Epoch 68/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2127\n",
      "Epoch 00068: val_loss improved from 0.98725 to 0.89316, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2124 - val_loss: 0.8932\n",
      "Epoch 69/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.1651\n",
      "Epoch 00069: val_loss did not improve from 0.89316\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1653 - val_loss: 1.1314\n",
      "Epoch 70/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.2062\n",
      "Epoch 00070: val_loss did not improve from 0.89316\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2060 - val_loss: 1.0292\n",
      "Epoch 71/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.2014\n",
      "Epoch 00071: val_loss improved from 0.89316 to 0.85018, saving model to DS02/experiment_set_9\\results_0.9\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2011 - val_loss: 0.8502\n",
      "Epoch 72/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.1600\n",
      "Epoch 00072: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1597 - val_loss: 0.9661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.1924\n",
      "Epoch 00073: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1920 - val_loss: 1.1098\n",
      "Epoch 74/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.1587\n",
      "Epoch 00074: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1585 - val_loss: 1.0354\n",
      "Epoch 75/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.1531\n",
      "Epoch 00075: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1533 - val_loss: 1.4244\n",
      "Epoch 76/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.1556\n",
      "Epoch 00076: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1555 - val_loss: 1.0840\n",
      "Epoch 77/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.1573\n",
      "Epoch 00077: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1572 - val_loss: 0.8686\n",
      "Epoch 78/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.1309\n",
      "Epoch 00078: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1310 - val_loss: 0.9583\n",
      "Epoch 79/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.1204\n",
      "Epoch 00079: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1204 - val_loss: 1.3015\n",
      "Epoch 80/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.1066\n",
      "Epoch 00080: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.1064 - val_loss: 1.0565\n",
      "Epoch 81/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.1083\n",
      "Epoch 00081: val_loss did not improve from 0.85018\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.1085 - val_loss: 1.4323\n",
      "Epoch 00081: early stopping\n",
      "Saved training history to file: DS02/experiment_set_9\\results_0.9\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.87\n",
      "RMSE: 0.93\n",
      "CMAPSS score: 1.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Test effect of correlation threshold + health params\n",
    "######################################################\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "layer_sizes = [256, 256, 512, 64]\n",
    "\n",
    "initial_columns = x_train.columns\n",
    "# corr_th_list = [None, 0.99, 0.95, 0.9]\n",
    "corr_th_list = [0.95, 0.9]\n",
    "\n",
    "results_file = os.path.join(output_path, \"results_corr_th_health_params.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"corr_th,selected_features,num_features,mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "\n",
    "for corr_th in corr_th_list:\n",
    "    # Select features based on training set\n",
    "    if corr_th is not None:\n",
    "        selected_columns = get_non_correlated_features(x_train, corr_th=corr_th, debug=False)\n",
    "    else:\n",
    "        selected_columns = x_train.columns\n",
    "    \n",
    "    x_train_feature_selection = x_train[selected_columns]\n",
    "    \n",
    "    mse_vals = []\n",
    "    rmse_vals = []\n",
    "    cmapss_vals = []\n",
    "    \n",
    "    for random_seed in range(NUM_TRIALS):\n",
    "        # Train-validation split for early stopping\n",
    "        x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train_feature_selection, \n",
    "                                                                                  y_train, \n",
    "                                                                                  test_size=0.1, \n",
    "                                                                                  random_state=random_seed)\n",
    "        # Create output path\n",
    "        results_folder = \"results_all\" if corr_th is None else \"results_{}\".format(corr_th)\n",
    "        results_path_crr_th = os.path.join(output_path, results_folder)\n",
    "        results_path_crr_split = os.path.join(results_path_crr_th, \"split_{}\".format(random_seed))\n",
    "        if not os.path.exists(results_path_crr_split):\n",
    "            os.makedirs(results_path_crr_split)\n",
    "\n",
    "        # Standardization\n",
    "        scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(x_train_split)\n",
    "        x_val_scaled = scaler.transform(x_val_split)\n",
    "        input_dim = x_train_scaled.shape[1]\n",
    "        save_object(scaler, scaler_file)\n",
    "\n",
    "        # Create model\n",
    "        weights_file = os.path.join(results_path_crr_th, 'mlp_initial_weights.h5')\n",
    "        model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "        \n",
    "        # Save initial weights\n",
    "        if random_seed == 0:\n",
    "            model = create_mlp_model(input_dim, layer_sizes, activation='tanh',\n",
    "                                     output_weights_file=weights_file)\n",
    "        else:\n",
    "            model = create_mlp_model(input_dim, layer_sizes, activation='tanh')\n",
    "        model.summary()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=2, \n",
    "                             save_best_only=True)\n",
    "\n",
    "        # Train model\n",
    "        history = train_model_existing_weights(model, weights_file, \n",
    "                                               x_train_scaled, y_train_split, \n",
    "                                               x_val_scaled, y_val_split, \n",
    "                                               batch_size=batch_size, \n",
    "                                               epochs=epochs, \n",
    "                                               callbacks=[es, mc])\n",
    "\n",
    "        history_file = os.path.join(results_path_crr_split, \"history.pkl\")\n",
    "        save_history(history, history_file)\n",
    "\n",
    "        # Performance evaluation\n",
    "        x_holdout_feature_selection = x_holdout[selected_columns]\n",
    "        x_holdout_scaled = scaler.transform(x_holdout_feature_selection)\n",
    "\n",
    "        loaded_model = load_model(model_path)\n",
    "        predictions_holdout = loaded_model.predict(x_holdout_scaled).flatten()\n",
    "        mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_holdout, y_holdout)\n",
    "        \n",
    "        mse_vals.append(mse)\n",
    "        rmse_vals.append(rmse)\n",
    "        cmapss_vals.append(cmapss_score)\n",
    "    \n",
    "    mse_mean = np.mean(mse_vals)\n",
    "    mse_std = np.std(mse_vals)\n",
    "    rmse_mean = np.mean(rmse_vals)\n",
    "    rmse_std = np.std(rmse_vals)\n",
    "    cmapss_mean = np.mean(cmapss_vals)\n",
    "    cmapss_std = np.std(cmapss_vals)\n",
    "    \n",
    "    with open(results_file, \"a\") as file:\n",
    "        th = \"all\" if corr_th is None else corr_th\n",
    "        \n",
    "        file.write(f\"{th}, {feature_list_to_string(selected_columns)}, {len(selected_columns)}, {numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)}, {numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean}, {rmse_std}, {cmapss_mean}, {cmapss_std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "MSE: 31.89\n",
      "RMSE: 5.65\n",
      "CMAPSS score: 1.52\n",
      "\n",
      "Test set:\n",
      "MSE: 32.34\n",
      "RMSE: 5.69\n",
      "CMAPSS score: 1.53\n",
      "\n",
      "Test set:\n",
      "MSE: 38.99\n",
      "RMSE: 6.24\n",
      "CMAPSS score: 1.59\n",
      "\n",
      "Test set:\n",
      "MSE: 28.58\n",
      "RMSE: 5.35\n",
      "CMAPSS score: 1.52\n",
      "\n",
      "Test set:\n",
      "MSE: 36.26\n",
      "RMSE: 6.02\n",
      "CMAPSS score: 1.58\n",
      "\n",
      "Test set:\n",
      "MSE: 37.41\n",
      "RMSE: 6.12\n",
      "CMAPSS score: 1.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Results on test set\n",
    "######################################################\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "initial_columns = x_train.columns\n",
    "# corr_th_list = [None, 0.99, 0.95, 0.9]\n",
    "corr_th_list = [0.95, 0.9]\n",
    "\n",
    "results_file = os.path.join(output_path, \"results_corr_th_health_params_test_set.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"corr_th,selected_features,num_features,mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "\n",
    "for corr_th in corr_th_list:\n",
    "    # Select features based on training set\n",
    "    if corr_th is not None:\n",
    "        selected_columns = get_non_correlated_features(x_train, corr_th=corr_th, debug=False)\n",
    "    else:\n",
    "        selected_columns = x_train.columns\n",
    "    \n",
    "    mse_vals = []\n",
    "    rmse_vals = []\n",
    "    cmapss_vals = []\n",
    "    \n",
    "    for random_seed in range(NUM_TRIALS):\n",
    "        results_folder = \"results_all\" if corr_th is None else \"results_{}\".format(corr_th)\n",
    "        results_path_crr_th = os.path.join(output_path, results_folder)\n",
    "        results_path_crr_split = os.path.join(results_path_crr_th, \"split_{}\".format(random_seed))\n",
    "        \n",
    "        scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "        scaler = load_object(scaler_file)\n",
    "\n",
    "        model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "        \n",
    "        # Performance evaluation\n",
    "        x_test_feature_selection = x_test[selected_columns]\n",
    "        x_test_scaled = scaler.transform(x_test_feature_selection)\n",
    "\n",
    "        loaded_model = load_model(model_path)\n",
    "        predictions_test = loaded_model.predict(x_test_scaled).flatten()\n",
    "        mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_test, y_test)\n",
    "        \n",
    "        mse_vals.append(mse)\n",
    "        rmse_vals.append(rmse)\n",
    "        cmapss_vals.append(cmapss_score)\n",
    "    \n",
    "    mse_mean = np.mean(mse_vals)\n",
    "    mse_std = np.std(mse_vals)\n",
    "    rmse_mean = np.mean(rmse_vals)\n",
    "    rmse_std = np.std(rmse_vals)\n",
    "    cmapss_mean = np.mean(cmapss_vals)\n",
    "    cmapss_std = np.std(cmapss_vals)\n",
    "    \n",
    "    with open(results_file, \"a\") as file:\n",
    "        th = \"all\" if corr_th is None else corr_th\n",
    "        \n",
    "        file.write(f\"{th}, {feature_list_to_string(selected_columns)}, {len(selected_columns)}, {numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)}, {numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean}, {rmse_std}, {cmapss_mean}, {cmapss_std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-keras-gpu",
   "language": "python",
   "name": "tf-keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
