{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "seed = 0\n",
    "os.environ['PYTHONHASSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/turbofan_dataset/N-CMAPSS_DS02-006.h5'\n",
    "output_path = 'DS02/experiment_set_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TEST_SET_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, load_test_set=True):\n",
    "    \"\"\" Reads a dataset from a given .h5 file and compose (in memory) the train and test data. \n",
    "    Args:\n",
    "        filename(str): path to the .h5 file\n",
    "    Returns:\n",
    "        train_set(pd.DataFrame), test_set(pd.DataFrame)\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as hdf:\n",
    "        # Development set\n",
    "        W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "        X_v_dev = np.array(hdf.get('X_v_dev'))         # X_v\n",
    "        T_dev = np.array(hdf.get('T_dev'))             # T\n",
    "        Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
    "        A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "        # Test set\n",
    "        if load_test_set:\n",
    "            W_test = np.array(hdf.get('W_test'))           # W\n",
    "            X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
    "            X_v_test = np.array(hdf.get('X_v_test'))       # X_v\n",
    "            T_test = np.array(hdf.get('T_test'))           # T\n",
    "            Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
    "            A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
    "        \n",
    "        # Column names\n",
    "        W_var = np.array(hdf.get('W_var'))\n",
    "        X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "        X_v_var = np.array(hdf.get('X_v_var')) \n",
    "        T_var = np.array(hdf.get('T_var'))\n",
    "        A_var = np.array(hdf.get('A_var'))\n",
    "        \n",
    "        columns = []\n",
    "        columns.append(list(np.array(A_var, dtype='U20')))\n",
    "        columns.append(list(np.array(T_var, dtype='U20')))\n",
    "        columns.append(list(np.array(X_s_var, dtype='U20')))\n",
    "        columns.append(list(np.array(X_v_var, dtype='U20')))\n",
    "        columns.append(list(np.array(W_var, dtype='U20')))\n",
    "        columns.append(['RUL'])\n",
    "        \n",
    "        columns_list = []\n",
    "        for columns_per_category in columns:\n",
    "            columns_list += columns_per_category\n",
    "        \n",
    "    train_set = np.concatenate((A_dev, T_dev, X_s_dev, X_v_dev, W_dev, Y_dev), axis=1)\n",
    "    if load_test_set:\n",
    "        test_set = np.concatenate((A_test, T_test, X_s_test, X_v_test, W_test, Y_test), axis=1)\n",
    "        return pd.DataFrame(data=train_set, columns=columns_list), pd.DataFrame(data=test_set, columns=columns_list), columns\n",
    "    else:\n",
    "        return pd.DataFrame(data=train_set, columns=columns_list), None, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_cycle_info(df, compute_cycle_len=False):\n",
    "    unit_ids = np.unique(df['unit'])\n",
    "    print('Engine units in df: ', unit_ids)\n",
    "    for i in unit_ids:\n",
    "        num_cycles = len(np.unique(df.loc[df['unit'] == i, 'cycle']))\n",
    "        print('Unit: ', i, ' - Number of flight cycles: ', num_cycles)\n",
    "        \n",
    "    if compute_cycle_len:\n",
    "        cycle_ids = np.unique(df['cycle'])\n",
    "        print('Total number of cycles: ', len(cycle_ids))\n",
    "        min_len = np.inf\n",
    "        max_len = 0\n",
    "        for i in cycle_ids:\n",
    "            cycle_len = len(df.loc[df['cycle'] == i, 'cycle'])\n",
    "            if cycle_len < min_len:\n",
    "                min_len = cycle_len\n",
    "            elif cycle_len > max_len:\n",
    "                max_len = cycle_len\n",
    "        print('Min cycle length: ', min_len)\n",
    "        print('Max cycle length: ', max_len)\n",
    "    \n",
    "    return unit_ids\n",
    "\n",
    "def get_quasi_constant_features(dataset, variance_th=0.01, debug=True):\n",
    "    constant_filter = VarianceThreshold(threshold=variance_th)\n",
    "    constant_filter.fit(dataset)\n",
    "    constant_features = [col for col in dataset.columns \n",
    "                         if col not in dataset.columns[constant_filter.get_support()]]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Number of non-constant features: \", len(dataset.columns[constant_filter.get_support()]))\n",
    "        \n",
    "        print(\"Number of quasi-constant features: \", len(constant_features))\n",
    "        print(\"Quasi-constant features: \")\n",
    "        for col in constant_features:\n",
    "            print(col)\n",
    "    return constant_features\n",
    "\n",
    "def get_principal_components(X, explained_variance=0.99, debug=False):   \n",
    "    pca = PCA(explained_variance, svd_solver='full', random_state=seed)\n",
    "    pca = pca.fit(X)\n",
    "    \n",
    "    if debug:\n",
    "        explained_variance_cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "        pca_dims = np.argmax(explained_variance_cumsum >= explained_variance) + 1\n",
    "        print(f\"Can reduce from {X.shape[1]} to {pca_dims} dimensions while retaining {explained_variance}% of variance.\")\n",
    "\n",
    "        plt.plot(explained_variance_cumsum)\n",
    "        plt.xlabel('Number of components')\n",
    "        plt.ylabel('Cumulative explained variance')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.bar(range(pca.components_.shape[0]), pca.explained_variance_ratio_)\n",
    "        plt.xlabel('PC')\n",
    "        plt.ylabel('Explained variance')\n",
    "    return pca\n",
    "    \n",
    "def dimensionality_reduction(X, pca):\n",
    "    return pca.transform(X)\n",
    "\n",
    "def cmapss_score_function(actual, predictions, normalize=True):\n",
    "    # diff < 0 -> over-estimation\n",
    "    # diff > 0 -> under-estimation\n",
    "    diff = actual - predictions\n",
    "    alpha = np.full_like(diff, 1/13)\n",
    "    negative_diff_mask = diff < 0\n",
    "    alpha[negative_diff_mask] = 1/10\n",
    "    score = np.sum(np.exp(alpha * np.abs(diff)))\n",
    "    \n",
    "    if normalize:\n",
    "        N = len(predictions)\n",
    "        score /= N\n",
    "    return score\n",
    "\n",
    "def compute_evaluation_metrics(actual, predictions, label='Test'):\n",
    "    mse = mean_squared_error(actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    cmapss_score = cmapss_score_function(actual, predictions)\n",
    "    print('{} set:\\nMSE: {:.2f}\\nRMSE: {:.2f}\\nCMAPSS score: {:.2f}\\n'.format(label, mse, rmse, \n",
    "                                                                     cmapss_score))\n",
    "    return mse, rmse, cmapss_score\n",
    "    \n",
    "def plot_loss_curves(history, output_path=None, y_lim=[0, 150]):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylim(y_lim)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    \n",
    "    if output_path is not None:\n",
    "        plt.savefig(os.path.join(output_path, 'loss_curves.png'), format='png', dpi=300) \n",
    "    plt.show()\n",
    "    \n",
    "def plot_rul(expected, predicted):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(expected)), expected, label='Expected')\n",
    "    plt.plot(range(len(predicted)), predicted, label='Predicted')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def create_mlp_model(input_dim, hidden_layer_sizes, activation='relu', output_weights_file=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], \n",
    "                    input_dim=input_dim, \n",
    "                    kernel_initializer='random_normal', \n",
    "                    activation=activation))\n",
    "\n",
    "    for layer_size in hidden_layer_sizes[1:]:\n",
    "        model.add(Dense(layer_size, \n",
    "                        kernel_initializer='random_normal', \n",
    "                        activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='random_normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    if output_weights_file is not None:\n",
    "        model.save_weights(output_weights_file)\n",
    "    return model\n",
    "\n",
    "def train_model_existing_weights(model, weights_file, x_train, y_train, x_val, y_val, epochs=200, batch_size=512, callbacks=[]):\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.load_weights(weights_file)\n",
    "    return model.fit(x_train, y_train,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     verbose=1,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "def save_history(history, output_file=os.path.join(output_path, \"history.pkl\")):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "    print(\"Saved training history to file: {}\".format(output_file))\n",
    "\n",
    "def load_history(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def save_object(obj, output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    print(\"Saved object to file: {}\".format(output_file))\n",
    "    \n",
    "def load_object(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def model_evaluation(model, x_test, y_test, x_train=None, y_train=None, plot_range=[0, 10**3]):\n",
    "    if x_train is not None and y_train is not None:\n",
    "        predictions_train = model.predict(x_train).flatten()\n",
    "        compute_evaluation_metrics(predictions_train, y_train, 'Train')\n",
    "        \n",
    "        expected = y_train[plot_range[0]:plot_range[1]]\n",
    "        predicted = predictions_train[plot_range[0]:plot_range[1]]\n",
    "        plot_rul(expected, predicted)\n",
    "        \n",
    "    predictions_test = model.predict(x_test).flatten()\n",
    "    compute_evaluation_metrics(predictions_test, y_test)\n",
    "    \n",
    "    expected = y_test[plot_range[0]:plot_range[1]]\n",
    "    predicted = predictions_test[plot_range[0]:plot_range[1]]\n",
    "    plot_rul(expected, predicted)\n",
    "\n",
    "def numbers_list_to_string(num_list):\n",
    "    return \" \".join([str(x) for x in num_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation time (sec):  3.90625\n",
      "\n",
      "Train set shape: (5263447, 47)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()  \n",
    "train_set, test_set, columns = load_dataset(filename)\n",
    "print(\"Operation time (sec): \" , (time.process_time() - start_time))\n",
    "print()\n",
    "print(\"Train set shape: \" + str(train_set.shape))\n",
    "\n",
    "columns_aux = columns[0] \n",
    "columns_health_params = columns[1] \n",
    "columns_sensor_measurements = columns[2] \n",
    "columns_virtual_sensors = columns[3]\n",
    "columns_operating_conditions = columns[4] \n",
    "target_col = columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['RUL']\n",
    "x_train = train_set.drop(['RUL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-constant features:  38\n",
      "Number of quasi-constant features:  8\n",
      "Quasi-constant features: \n",
      "Fc\n",
      "fan_eff_mod\n",
      "fan_flow_mod\n",
      "LPC_eff_mod\n",
      "LPC_flow_mod\n",
      "HPC_eff_mod\n",
      "HPC_flow_mod\n",
      "HPT_flow_mod\n",
      "Train shape:  (5263447, 38)\n"
     ]
    }
   ],
   "source": [
    "constant_features = get_quasi_constant_features(x_train, variance_th=0)\n",
    "x_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "print(\"Train shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary data columns\n",
    "x_train.drop(labels=[x for x in columns_aux if x in x_train.columns], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_set['RUL']\n",
    "x_test = test_set[x_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_0\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_0\\pca.pkl\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 107.7109\n",
      "Epoch 00001: val_loss improved from inf to 14.54236, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 107.6447 - val_loss: 14.5424\n",
      "Epoch 2/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 9.7409\n",
      "Epoch 00002: val_loss improved from 14.54236 to 8.21241, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 9.7369 - val_loss: 8.2124\n",
      "Epoch 3/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 6.1054\n",
      "Epoch 00003: val_loss improved from 8.21241 to 6.53588, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 6.1067 - val_loss: 6.5359\n",
      "Epoch 4/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 5.0008\n",
      "Epoch 00004: val_loss improved from 6.53588 to 4.20478, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.0001 - val_loss: 4.2048\n",
      "Epoch 5/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 4.3448\n",
      "Epoch 00005: val_loss did not improve from 4.20478\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.3450 - val_loss: 4.3646\n",
      "Epoch 6/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.9702\n",
      "Epoch 00006: val_loss did not improve from 4.20478\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.9702 - val_loss: 8.1843\n",
      "Epoch 7/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 3.6187\n",
      "Epoch 00007: val_loss improved from 4.20478 to 4.05974, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.6193 - val_loss: 4.0597\n",
      "Epoch 8/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 3.4501\n",
      "Epoch 00008: val_loss improved from 4.05974 to 3.67936, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.4498 - val_loss: 3.6794\n",
      "Epoch 9/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 3.2025\n",
      "Epoch 00009: val_loss improved from 3.67936 to 3.14918, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.2027 - val_loss: 3.1492\n",
      "Epoch 10/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 3.0516\n",
      "Epoch 00010: val_loss improved from 3.14918 to 3.06307, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.0514 - val_loss: 3.0631\n",
      "Epoch 11/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.9267\n",
      "Epoch 00011: val_loss improved from 3.06307 to 3.04397, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.9265 - val_loss: 3.0440\n",
      "Epoch 12/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.7728\n",
      "Epoch 00012: val_loss improved from 3.04397 to 2.87341, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.7735 - val_loss: 2.8734\n",
      "Epoch 13/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.6683\n",
      "Epoch 00013: val_loss improved from 2.87341 to 2.43331, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.6685 - val_loss: 2.4333\n",
      "Epoch 14/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.5778\n",
      "Epoch 00014: val_loss did not improve from 2.43331\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.5781 - val_loss: 2.9433\n",
      "Epoch 15/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.4872\n",
      "Epoch 00015: val_loss improved from 2.43331 to 2.42878, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4870 - val_loss: 2.4288\n",
      "Epoch 16/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.4303\n",
      "Epoch 00016: val_loss improved from 2.42878 to 2.37380, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4310 - val_loss: 2.3738\n",
      "Epoch 17/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 2.3772\n",
      "Epoch 00017: val_loss did not improve from 2.37380\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3768 - val_loss: 2.5775\n",
      "Epoch 18/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.3031\n",
      "Epoch 00018: val_loss improved from 2.37380 to 2.14067, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3030 - val_loss: 2.1407\n",
      "Epoch 19/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.2522\n",
      "Epoch 00019: val_loss did not improve from 2.14067\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2523 - val_loss: 2.3997\n",
      "Epoch 20/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.1924\n",
      "Epoch 00020: val_loss improved from 2.14067 to 1.95366, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1920 - val_loss: 1.9537\n",
      "Epoch 21/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.1489\n",
      "Epoch 00021: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1488 - val_loss: 2.0436\n",
      "Epoch 22/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.1100\n",
      "Epoch 00022: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1097 - val_loss: 2.0913\n",
      "Epoch 23/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 2.0743\n",
      "Epoch 00023: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.0741 - val_loss: 2.0922\n",
      "Epoch 24/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.0222\n",
      "Epoch 00024: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0223 - val_loss: 2.0274\n",
      "Epoch 25/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.9786\n",
      "Epoch 00025: val_loss did not improve from 1.95366\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9790 - val_loss: 2.0602\n",
      "Epoch 26/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.9693\n",
      "Epoch 00026: val_loss improved from 1.95366 to 1.93020, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.9695 - val_loss: 1.9302\n",
      "Epoch 27/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.9419\n",
      "Epoch 00027: val_loss improved from 1.93020 to 1.89174, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9417 - val_loss: 1.8917\n",
      "Epoch 28/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.9227\n",
      "Epoch 00028: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9220 - val_loss: 1.9245\n",
      "Epoch 29/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.9075\n",
      "Epoch 00029: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9076 - val_loss: 2.0436\n",
      "Epoch 30/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.8676\n",
      "Epoch 00030: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8678 - val_loss: 1.9489\n",
      "Epoch 31/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.8307\n",
      "Epoch 00031: val_loss did not improve from 1.89174\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8307 - val_loss: 1.9495\n",
      "Epoch 32/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.8208\n",
      "Epoch 00032: val_loss improved from 1.89174 to 1.82247, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8208 - val_loss: 1.8225\n",
      "Epoch 33/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.8031\n",
      "Epoch 00033: val_loss did not improve from 1.82247\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8029 - val_loss: 2.0735\n",
      "Epoch 34/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7647\n",
      "Epoch 00034: val_loss improved from 1.82247 to 1.75825, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.7647 - val_loss: 1.7582\n",
      "Epoch 35/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7700\n",
      "Epoch 00035: val_loss did not improve from 1.75825\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7702 - val_loss: 1.8291\n",
      "Epoch 36/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.7562\n",
      "Epoch 00036: val_loss did not improve from 1.75825\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7564 - val_loss: 1.8965\n",
      "Epoch 37/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7231\n",
      "Epoch 00037: val_loss improved from 1.75825 to 1.74347, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.7230 - val_loss: 1.7435\n",
      "Epoch 38/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.7047\n",
      "Epoch 00038: val_loss did not improve from 1.74347\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7047 - val_loss: 1.8221\n",
      "Epoch 39/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6906\n",
      "Epoch 00039: val_loss improved from 1.74347 to 1.62187, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6905 - val_loss: 1.6219\n",
      "Epoch 40/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6824- ETA: \n",
      "Epoch 00040: val_loss did not improve from 1.62187\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6827 - val_loss: 1.8029\n",
      "Epoch 41/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.6783\n",
      "Epoch 00041: val_loss improved from 1.62187 to 1.58902, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6778 - val_loss: 1.5890\n",
      "Epoch 42/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6372\n",
      "Epoch 00042: val_loss did not improve from 1.58902\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6371 - val_loss: 1.8424\n",
      "Epoch 43/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6149\n",
      "Epoch 00043: val_loss improved from 1.58902 to 1.47750, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.6150 - val_loss: 1.4775\n",
      "Epoch 44/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5985\n",
      "Epoch 00044: val_loss did not improve from 1.47750\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5985 - val_loss: 1.6180\n",
      "Epoch 45/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.5980- ETA: 0s - lo\n",
      "Epoch 00045: val_loss did not improve from 1.47750\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5982 - val_loss: 1.5711\n",
      "Epoch 46/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.6062\n",
      "Epoch 00046: val_loss improved from 1.47750 to 1.46927, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6063 - val_loss: 1.4693\n",
      "Epoch 47/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5683\n",
      "Epoch 00047: val_loss improved from 1.46927 to 1.46415, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.5683 - val_loss: 1.4641\n",
      "Epoch 48/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.5569\n",
      "Epoch 00048: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5569 - val_loss: 1.8643\n",
      "Epoch 49/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.5527\n",
      "Epoch 00049: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5530 - val_loss: 1.8368\n",
      "Epoch 50/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.5564\n",
      "Epoch 00050: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.5564 - val_loss: 1.8175\n",
      "Epoch 51/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5381\n",
      "Epoch 00051: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5381 - val_loss: 1.7042\n",
      "Epoch 52/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5267\n",
      "Epoch 00052: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5271 - val_loss: 1.7981\n",
      "Epoch 53/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.5287\n",
      "Epoch 00053: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5287 - val_loss: 1.4751\n",
      "Epoch 54/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5106\n",
      "Epoch 00054: val_loss did not improve from 1.46415\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5105 - val_loss: 1.7031\n",
      "Epoch 55/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5140\n",
      "Epoch 00055: val_loss improved from 1.46415 to 1.41848, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.5140 - val_loss: 1.4185\n",
      "Epoch 56/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.507 - ETA: 0s - loss: 1.5072\n",
      "Epoch 00056: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5071 - val_loss: 1.5680\n",
      "Epoch 57/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4878\n",
      "Epoch 00057: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4878 - val_loss: 1.5200\n",
      "Epoch 58/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.4865\n",
      "Epoch 00058: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4863 - val_loss: 1.4403\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4794\n",
      "Epoch 00059: val_loss did not improve from 1.41848\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4794 - val_loss: 1.5750\n",
      "Epoch 60/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.4709\n",
      "Epoch 00060: val_loss improved from 1.41848 to 1.29716, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 1.4706 - val_loss: 1.2972\n",
      "Epoch 61/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.4614\n",
      "Epoch 00061: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4614 - val_loss: 1.6744\n",
      "Epoch 62/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.4489\n",
      "Epoch 00062: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4494 - val_loss: 1.7070\n",
      "Epoch 63/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4456\n",
      "Epoch 00063: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4455 - val_loss: 1.6752\n",
      "Epoch 64/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4430\n",
      "Epoch 00064: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4430 - val_loss: 1.8154\n",
      "Epoch 65/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.4501\n",
      "Epoch 00065: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4501 - val_loss: 1.7057\n",
      "Epoch 66/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4375\n",
      "Epoch 00066: val_loss did not improve from 1.29716\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4376 - val_loss: 1.5586\n",
      "Epoch 67/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4301\n",
      "Epoch 00067: val_loss improved from 1.29716 to 1.28435, saving model to DS02/experiment_set_6\\results_pca\\split_0\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.4303 - val_loss: 1.2844\n",
      "Epoch 68/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4253\n",
      "Epoch 00068: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4253 - val_loss: 1.5475\n",
      "Epoch 69/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4292\n",
      "Epoch 00069: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4292 - val_loss: 1.5084\n",
      "Epoch 70/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.3911\n",
      "Epoch 00070: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3908 - val_loss: 1.4702\n",
      "Epoch 71/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.4138\n",
      "Epoch 00071: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4138 - val_loss: 1.4546\n",
      "Epoch 72/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3936\n",
      "Epoch 00072: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3936 - val_loss: 1.4057\n",
      "Epoch 73/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4018\n",
      "Epoch 00073: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4017 - val_loss: 1.3685\n",
      "Epoch 74/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.3645\n",
      "Epoch 00074: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3648 - val_loss: 1.9528\n",
      "Epoch 75/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3908\n",
      "Epoch 00075: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3908 - val_loss: 1.3882\n",
      "Epoch 76/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3775\n",
      "Epoch 00076: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3773 - val_loss: 1.4210\n",
      "Epoch 77/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.3881\n",
      "Epoch 00077: val_loss did not improve from 1.28435\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3877 - val_loss: 1.4565\n",
      "Epoch 00077: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 36.73\n",
      "RMSE: 6.06\n",
      "CMAPSS score: 1.58\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_1\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_1\\pca.pkl\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 108.3349\n",
      "Epoch 00001: val_loss improved from inf to 13.60037, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 108.2021 - val_loss: 13.6004\n",
      "Epoch 2/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 9.5052\n",
      "Epoch 00002: val_loss improved from 13.60037 to 8.45470, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 9.5017 - val_loss: 8.4547\n",
      "Epoch 3/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 6.2179\n",
      "Epoch 00003: val_loss improved from 8.45470 to 5.92828, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 6.2171 - val_loss: 5.9283\n",
      "Epoch 4/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 5.1117\n",
      "Epoch 00004: val_loss improved from 5.92828 to 4.89107, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.1107 - val_loss: 4.8911\n",
      "Epoch 5/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 4.5063\n",
      "Epoch 00005: val_loss improved from 4.89107 to 4.52424, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.5062 - val_loss: 4.5242\n",
      "Epoch 6/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 4.1378\n",
      "Epoch 00006: val_loss improved from 4.52424 to 3.59381, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.1376 - val_loss: 3.5938\n",
      "Epoch 7/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 3.8213\n",
      "Epoch 00007: val_loss improved from 3.59381 to 3.42666, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.8205 - val_loss: 3.4267\n",
      "Epoch 8/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.5832\n",
      "Epoch 00008: val_loss did not improve from 3.42666\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.5832 - val_loss: 4.4242\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7186/7197 [============================>.] - ETA: 0s - loss: 3.4169\n",
      "Epoch 00009: val_loss did not improve from 3.42666\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.4166 - val_loss: 3.4978\n",
      "Epoch 10/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 3.2106\n",
      "Epoch 00010: val_loss did not improve from 3.42666\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.2104 - val_loss: 5.7608\n",
      "Epoch 11/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 3.0787\n",
      "Epoch 00011: val_loss improved from 3.42666 to 3.28600, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.0787 - val_loss: 3.2860\n",
      "Epoch 12/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.9563\n",
      "Epoch 00012: val_loss improved from 3.28600 to 3.25010, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.9558 - val_loss: 3.2501\n",
      "Epoch 13/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.8332\n",
      "Epoch 00013: val_loss did not improve from 3.25010\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8333 - val_loss: 3.4789\n",
      "Epoch 14/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.7321\n",
      "Epoch 00014: val_loss improved from 3.25010 to 2.68919, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.7320 - val_loss: 2.6892\n",
      "Epoch 15/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.6321\n",
      "Epoch 00015: val_loss did not improve from 2.68919\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.6324 - val_loss: 2.7102\n",
      "Epoch 16/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 2.5569- ETA: 0s - \n",
      "Epoch 00016: val_loss improved from 2.68919 to 2.26263, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.5569 - val_loss: 2.2626\n",
      "Epoch 17/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.4751\n",
      "Epoch 00017: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4759 - val_loss: 2.4907\n",
      "Epoch 18/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 2.3760\n",
      "Epoch 00018: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3765 - val_loss: 2.7336\n",
      "Epoch 19/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 2.3295\n",
      "Epoch 00019: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3293 - val_loss: 2.3178\n",
      "Epoch 20/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.2527\n",
      "Epoch 00020: val_loss did not improve from 2.26263\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2531 - val_loss: 2.8301\n",
      "Epoch 21/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 2.2128\n",
      "Epoch 00021: val_loss improved from 2.26263 to 2.23043, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.2128 - val_loss: 2.2304\n",
      "Epoch 22/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.1849\n",
      "Epoch 00022: val_loss did not improve from 2.23043\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1849 - val_loss: 2.5527\n",
      "Epoch 23/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 2.1141\n",
      "Epoch 00023: val_loss improved from 2.23043 to 2.22879, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1145 - val_loss: 2.2288\n",
      "Epoch 24/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.0864\n",
      "Epoch 00024: val_loss improved from 2.22879 to 2.22096, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0861 - val_loss: 2.2210\n",
      "Epoch 25/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.0593\n",
      "Epoch 00025: val_loss improved from 2.22096 to 2.03612, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0595 - val_loss: 2.0361\n",
      "Epoch 26/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.0324\n",
      "Epoch 00026: val_loss improved from 2.03612 to 1.77848, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 2.0318 - val_loss: 1.7785\n",
      "Epoch 27/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.9964\n",
      "Epoch 00027: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9964 - val_loss: 2.2867\n",
      "Epoch 28/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.9704\n",
      "Epoch 00028: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9710 - val_loss: 2.3125\n",
      "Epoch 29/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.9460\n",
      "Epoch 00029: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9465 - val_loss: 2.8234\n",
      "Epoch 30/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.9247\n",
      "Epoch 00030: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.9249 - val_loss: 2.6177\n",
      "Epoch 31/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.8810\n",
      "Epoch 00031: val_loss did not improve from 1.77848\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8809 - val_loss: 2.1483\n",
      "Epoch 32/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.8749\n",
      "Epoch 00032: val_loss improved from 1.77848 to 1.62791, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8748 - val_loss: 1.6279\n",
      "Epoch 33/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.8301\n",
      "Epoch 00033: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8298 - val_loss: 1.8196\n",
      "Epoch 34/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.8355\n",
      "Epoch 00034: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8351 - val_loss: 1.8596\n",
      "Epoch 35/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.8244\n",
      "Epoch 00035: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.8245 - val_loss: 1.8661\n",
      "Epoch 36/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7907\n",
      "Epoch 00036: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7907 - val_loss: 1.8407\n",
      "Epoch 37/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.7544\n",
      "Epoch 00037: val_loss did not improve from 1.62791\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7543 - val_loss: 1.8796\n",
      "Epoch 38/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.7810\n",
      "Epoch 00038: val_loss improved from 1.62791 to 1.58039, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7810 - val_loss: 1.5804\n",
      "Epoch 39/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7427\n",
      "Epoch 00039: val_loss did not improve from 1.58039\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7427 - val_loss: 1.8820\n",
      "Epoch 40/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.7336\n",
      "Epoch 00040: val_loss did not improve from 1.58039\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7334 - val_loss: 1.6911\n",
      "Epoch 41/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6865\n",
      "Epoch 00041: val_loss did not improve from 1.58039\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6874 - val_loss: 4.3511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7130\n",
      "Epoch 00042: val_loss improved from 1.58039 to 1.51682, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.7129 - val_loss: 1.5168\n",
      "Epoch 43/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.6644- ETA: 0s\n",
      "Epoch 00043: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6647 - val_loss: 1.9957\n",
      "Epoch 44/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.6510\n",
      "Epoch 00044: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6510 - val_loss: 1.8899\n",
      "Epoch 45/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.6474\n",
      "Epoch 00045: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6471 - val_loss: 1.8664\n",
      "Epoch 46/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.6411\n",
      "Epoch 00046: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6411 - val_loss: 1.8276\n",
      "Epoch 47/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.6245\n",
      "Epoch 00047: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.6244 - val_loss: 1.7511\n",
      "Epoch 48/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.5991\n",
      "Epoch 00048: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5991 - val_loss: 1.6335\n",
      "Epoch 49/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5784\n",
      "Epoch 00049: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5783 - val_loss: 1.5828\n",
      "Epoch 50/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.5575\n",
      "Epoch 00050: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5575 - val_loss: 1.7401\n",
      "Epoch 51/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.5696\n",
      "Epoch 00051: val_loss did not improve from 1.51682\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5697 - val_loss: 1.7578\n",
      "Epoch 52/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.5687\n",
      "Epoch 00052: val_loss improved from 1.51682 to 1.49611, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.5685 - val_loss: 1.4961\n",
      "Epoch 53/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5458\n",
      "Epoch 00053: val_loss did not improve from 1.49611\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5457 - val_loss: 1.5635\n",
      "Epoch 54/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.5623\n",
      "Epoch 00054: val_loss improved from 1.49611 to 1.47974, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5620 - val_loss: 1.4797\n",
      "Epoch 55/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5310\n",
      "Epoch 00055: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5310 - val_loss: 1.5615\n",
      "Epoch 56/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.5133\n",
      "Epoch 00056: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5133 - val_loss: 1.5074\n",
      "Epoch 57/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.5303\n",
      "Epoch 00057: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5304 - val_loss: 1.7541\n",
      "Epoch 58/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4968\n",
      "Epoch 00058: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4968 - val_loss: 1.7040\n",
      "Epoch 59/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.5087\n",
      "Epoch 00059: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5085 - val_loss: 1.5605\n",
      "Epoch 60/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.4909\n",
      "Epoch 00060: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4909 - val_loss: 1.6777\n",
      "Epoch 61/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5069\n",
      "Epoch 00061: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.5069 - val_loss: 1.6856\n",
      "Epoch 62/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.4805\n",
      "Epoch 00062: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4803 - val_loss: 1.5304\n",
      "Epoch 63/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.4808\n",
      "Epoch 00063: val_loss did not improve from 1.47974\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4808 - val_loss: 1.9181\n",
      "Epoch 64/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4665\n",
      "Epoch 00064: val_loss improved from 1.47974 to 1.45158, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4664 - val_loss: 1.4516\n",
      "Epoch 65/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.4541\n",
      "Epoch 00065: val_loss did not improve from 1.45158\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4537 - val_loss: 1.6052\n",
      "Epoch 66/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.4658\n",
      "Epoch 00066: val_loss did not improve from 1.45158\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4662 - val_loss: 1.9256\n",
      "Epoch 67/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.4398\n",
      "Epoch 00067: val_loss improved from 1.45158 to 1.44030, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4396 - val_loss: 1.4403\n",
      "Epoch 68/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4395\n",
      "Epoch 00068: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4395 - val_loss: 1.4654\n",
      "Epoch 69/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4242\n",
      "Epoch 00069: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4243 - val_loss: 1.7079\n",
      "Epoch 70/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4094\n",
      "Epoch 00070: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4095 - val_loss: 1.5795\n",
      "Epoch 71/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.3954\n",
      "Epoch 00071: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3951 - val_loss: 1.4432\n",
      "Epoch 72/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4171\n",
      "Epoch 00072: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4172 - val_loss: 1.4450\n",
      "Epoch 73/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.3916\n",
      "Epoch 00073: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3916 - val_loss: 1.5010\n",
      "Epoch 74/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4099\n",
      "Epoch 00074: val_loss did not improve from 1.44030\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.4099 - val_loss: 1.6205\n",
      "Epoch 75/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.3828\n",
      "Epoch 00075: val_loss improved from 1.44030 to 1.33419, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3825 - val_loss: 1.3342\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7197/7197 [==============================] - ETA: 0s - loss: 1.3946\n",
      "Epoch 00076: val_loss improved from 1.33419 to 1.29899, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3946 - val_loss: 1.2990\n",
      "Epoch 77/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.3833\n",
      "Epoch 00077: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3838 - val_loss: 1.4039\n",
      "Epoch 78/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.3767\n",
      "Epoch 00078: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3766 - val_loss: 2.1334\n",
      "Epoch 79/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3751\n",
      "Epoch 00079: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3751 - val_loss: 1.4842\n",
      "Epoch 80/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.3569\n",
      "Epoch 00080: val_loss did not improve from 1.29899\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3569 - val_loss: 1.5759\n",
      "Epoch 81/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.3491\n",
      "Epoch 00081: val_loss improved from 1.29899 to 1.26471, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.3491 - val_loss: 1.2647\n",
      "Epoch 82/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.3579\n",
      "Epoch 00082: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3580 - val_loss: 1.3480\n",
      "Epoch 83/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.3493\n",
      "Epoch 00083: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3491 - val_loss: 1.3038\n",
      "Epoch 84/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.3528\n",
      "Epoch 00084: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 33s 5ms/step - loss: 1.3525 - val_loss: 1.4164\n",
      "Epoch 85/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.3430\n",
      "Epoch 00085: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.3432 - val_loss: 1.3641\n",
      "Epoch 86/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.3316\n",
      "Epoch 00086: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3314 - val_loss: 1.3953\n",
      "Epoch 87/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.3394\n",
      "Epoch 00087: val_loss did not improve from 1.26471\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3392 - val_loss: 1.4428\n",
      "Epoch 88/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.3296\n",
      "Epoch 00088: val_loss improved from 1.26471 to 1.18257, saving model to DS02/experiment_set_6\\results_pca\\split_1\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.3295 - val_loss: 1.1826\n",
      "Epoch 89/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3130\n",
      "Epoch 00089: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3129 - val_loss: 1.2918\n",
      "Epoch 90/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3143\n",
      "Epoch 00090: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3141 - val_loss: 1.4531\n",
      "Epoch 91/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.3235\n",
      "Epoch 00091: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3233 - val_loss: 1.2402\n",
      "Epoch 92/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3208\n",
      "Epoch 00092: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3212 - val_loss: 1.7850\n",
      "Epoch 93/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.3077\n",
      "Epoch 00093: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3076 - val_loss: 1.2637\n",
      "Epoch 94/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.3097\n",
      "Epoch 00094: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3101 - val_loss: 1.4081\n",
      "Epoch 95/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.3001\n",
      "Epoch 00095: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3000 - val_loss: 1.3996\n",
      "Epoch 96/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.3070\n",
      "Epoch 00096: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3070 - val_loss: 1.5735\n",
      "Epoch 97/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 1.3105\n",
      "Epoch 00097: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3105 - val_loss: 1.4531\n",
      "Epoch 98/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.3007\n",
      "Epoch 00098: val_loss did not improve from 1.18257\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.3007 - val_loss: 1.4788\n",
      "Epoch 00098: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 35.61\n",
      "RMSE: 5.97\n",
      "CMAPSS score: 1.56\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_2\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_2\\pca.pkl\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 110.4121\n",
      "Epoch 00001: val_loss improved from inf to 13.66215, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 110.3010 - val_loss: 13.6622\n",
      "Epoch 2/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 9.4672\n",
      "Epoch 00002: val_loss improved from 13.66215 to 6.51067, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 9.4654 - val_loss: 6.5107\n",
      "Epoch 3/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 6.1902\n",
      "Epoch 00003: val_loss improved from 6.51067 to 5.96488, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 6.1891 - val_loss: 5.9649\n",
      "Epoch 4/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 5.0192\n",
      "Epoch 00004: val_loss improved from 5.96488 to 5.29547, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.0190 - val_loss: 5.2955\n",
      "Epoch 5/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 4.3570\n",
      "Epoch 00005: val_loss improved from 5.29547 to 3.94004, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.3565 - val_loss: 3.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 3.9609\n",
      "Epoch 00006: val_loss improved from 3.94004 to 3.82042, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.9603 - val_loss: 3.8204\n",
      "Epoch 7/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 3.6782\n",
      "Epoch 00007: val_loss improved from 3.82042 to 3.26827, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.6783 - val_loss: 3.2683\n",
      "Epoch 8/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.4661\n",
      "Epoch 00008: val_loss did not improve from 3.26827\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.4662 - val_loss: 3.5249\n",
      "Epoch 9/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 3.2645\n",
      "Epoch 00009: val_loss did not improve from 3.26827\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.2644 - val_loss: 3.3979\n",
      "Epoch 10/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 3.0840\n",
      "Epoch 00010: val_loss improved from 3.26827 to 2.95126, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 3.0840 - val_loss: 2.9513\n",
      "Epoch 11/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.9600- ETA\n",
      "Epoch 00011: val_loss did not improve from 2.95126\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.9611 - val_loss: 5.4648\n",
      "Epoch 12/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.8385\n",
      "Epoch 00012: val_loss improved from 2.95126 to 2.68940, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8383 - val_loss: 2.6894\n",
      "Epoch 13/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.7282\n",
      "Epoch 00013: val_loss did not improve from 2.68940\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.7281 - val_loss: 4.0758\n",
      "Epoch 14/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 2.6434\n",
      "Epoch 00014: val_loss did not improve from 2.68940\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.6434 - val_loss: 2.8234\n",
      "Epoch 15/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 2.5815\n",
      "Epoch 00015: val_loss improved from 2.68940 to 2.37209, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 2.5816 - val_loss: 2.3721\n",
      "Epoch 16/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.4688\n",
      "Epoch 00016: val_loss did not improve from 2.37209\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.4687 - val_loss: 2.5204\n",
      "Epoch 17/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.4356\n",
      "Epoch 00017: val_loss improved from 2.37209 to 2.34944, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.4354 - val_loss: 2.3494\n",
      "Epoch 18/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.3775\n",
      "Epoch 00018: val_loss improved from 2.34944 to 2.21599, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3772 - val_loss: 2.2160\n",
      "Epoch 19/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.3420\n",
      "Epoch 00019: val_loss did not improve from 2.21599\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.3426 - val_loss: 2.7504\n",
      "Epoch 20/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.2626\n",
      "Epoch 00020: val_loss did not improve from 2.21599\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2629 - val_loss: 2.4623\n",
      "Epoch 21/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.2092\n",
      "Epoch 00021: val_loss did not improve from 2.21599\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2094 - val_loss: 2.2503\n",
      "Epoch 22/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.1758\n",
      "Epoch 00022: val_loss improved from 2.21599 to 2.00007, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1758 - val_loss: 2.0001\n",
      "Epoch 23/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.1382\n",
      "Epoch 00023: val_loss did not improve from 2.00007\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1381 - val_loss: 2.1053\n",
      "Epoch 24/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.1096\n",
      "Epoch 00024: val_loss improved from 2.00007 to 1.98381, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1096 - val_loss: 1.9838\n",
      "Epoch 25/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 2.0650\n",
      "Epoch 00025: val_loss improved from 1.98381 to 1.92093, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 2.0645 - val_loss: 1.9209\n",
      "Epoch 26/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 2.0400\n",
      "Epoch 00026: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0399 - val_loss: 2.3019\n",
      "Epoch 27/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.0091\n",
      "Epoch 00027: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0096 - val_loss: 3.4709\n",
      "Epoch 28/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.9816\n",
      "Epoch 00028: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9816 - val_loss: 2.2241\n",
      "Epoch 29/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.9435\n",
      "Epoch 00029: val_loss did not improve from 1.92093\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9438 - val_loss: 2.0645\n",
      "Epoch 30/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.9063\n",
      "Epoch 00030: val_loss improved from 1.92093 to 1.85241, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 38s 5ms/step - loss: 1.9064 - val_loss: 1.8524\n",
      "Epoch 31/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.9111\n",
      "Epoch 00031: val_loss improved from 1.85241 to 1.81876, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9107 - val_loss: 1.8188\n",
      "Epoch 32/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8660\n",
      "Epoch 00032: val_loss did not improve from 1.81876\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8660 - val_loss: 1.9557\n",
      "Epoch 33/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.8537\n",
      "Epoch 00033: val_loss did not improve from 1.81876\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8535 - val_loss: 2.0449\n",
      "Epoch 34/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8322\n",
      "Epoch 00034: val_loss did not improve from 1.81876\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8322 - val_loss: 1.9982\n",
      "Epoch 35/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.8120\n",
      "Epoch 00035: val_loss improved from 1.81876 to 1.79033, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8116 - val_loss: 1.7903\n",
      "Epoch 36/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.8041\n",
      "Epoch 00036: val_loss improved from 1.79033 to 1.78422, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8036 - val_loss: 1.7842\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7820\n",
      "Epoch 00037: val_loss did not improve from 1.78422\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7821 - val_loss: 1.9467\n",
      "Epoch 38/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.7413\n",
      "Epoch 00038: val_loss did not improve from 1.78422\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7411 - val_loss: 2.0081\n",
      "Epoch 39/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.7286\n",
      "Epoch 00039: val_loss improved from 1.78422 to 1.53895, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.7286 - val_loss: 1.5390\n",
      "Epoch 40/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.7140\n",
      "Epoch 00040: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7136 - val_loss: 1.8448\n",
      "Epoch 41/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.7093- ETA: 0s - lo\n",
      "Epoch 00041: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7092 - val_loss: 2.7093\n",
      "Epoch 42/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.6699\n",
      "Epoch 00042: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6699 - val_loss: 2.0056\n",
      "Epoch 43/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.6806\n",
      "Epoch 00043: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6804 - val_loss: 1.8016\n",
      "Epoch 44/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.6591\n",
      "Epoch 00044: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6590 - val_loss: 1.8524\n",
      "Epoch 45/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6260\n",
      "Epoch 00045: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6261 - val_loss: 1.9799\n",
      "Epoch 46/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.6036\n",
      "Epoch 00046: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6037 - val_loss: 1.6126\n",
      "Epoch 47/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.5899\n",
      "Epoch 00047: val_loss did not improve from 1.53895\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5899 - val_loss: 1.8134\n",
      "Epoch 48/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.6132\n",
      "Epoch 00048: val_loss improved from 1.53895 to 1.53761, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6132 - val_loss: 1.5376\n",
      "Epoch 49/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.5852\n",
      "Epoch 00049: val_loss did not improve from 1.53761\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5852 - val_loss: 1.7157\n",
      "Epoch 50/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.5743\n",
      "Epoch 00050: val_loss did not improve from 1.53761\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5744 - val_loss: 1.8201\n",
      "Epoch 51/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.5619\n",
      "Epoch 00051: val_loss improved from 1.53761 to 1.43365, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5615 - val_loss: 1.4336\n",
      "Epoch 52/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.5676\n",
      "Epoch 00052: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5677 - val_loss: 1.9112\n",
      "Epoch 53/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5511\n",
      "Epoch 00053: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5513 - val_loss: 1.6561\n",
      "Epoch 54/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.5304\n",
      "Epoch 00054: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5304 - val_loss: 1.6039\n",
      "Epoch 55/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.5239\n",
      "Epoch 00055: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5239 - val_loss: 1.8523\n",
      "Epoch 56/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.5054\n",
      "Epoch 00056: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5055 - val_loss: 1.6769\n",
      "Epoch 57/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.5076\n",
      "Epoch 00057: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5076 - val_loss: 1.6565\n",
      "Epoch 58/200\n",
      "7181/7197 [============================>.] - ETA: 0s - loss: 1.5100\n",
      "Epoch 00058: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5099 - val_loss: 1.9622\n",
      "Epoch 59/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4937\n",
      "Epoch 00059: val_loss did not improve from 1.43365\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4933 - val_loss: 1.4451\n",
      "Epoch 60/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.4949\n",
      "Epoch 00060: val_loss improved from 1.43365 to 1.40949, saving model to DS02/experiment_set_6\\results_pca\\split_2\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4950 - val_loss: 1.4095\n",
      "Epoch 61/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4589\n",
      "Epoch 00061: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4588 - val_loss: 1.4751\n",
      "Epoch 62/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.4734\n",
      "Epoch 00062: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4736 - val_loss: 1.6506\n",
      "Epoch 63/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 1.4765\n",
      "Epoch 00063: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4768 - val_loss: 1.6790\n",
      "Epoch 64/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.4715\n",
      "Epoch 00064: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4718 - val_loss: 1.4353\n",
      "Epoch 65/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.4582\n",
      "Epoch 00065: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4582 - val_loss: 1.5604\n",
      "Epoch 66/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.4319\n",
      "Epoch 00066: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4315 - val_loss: 1.5667\n",
      "Epoch 67/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4228\n",
      "Epoch 00067: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4231 - val_loss: 1.6756\n",
      "Epoch 68/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4450\n",
      "Epoch 00068: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4451 - val_loss: 2.4692\n",
      "Epoch 69/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4393\n",
      "Epoch 00069: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4392 - val_loss: 1.5007\n",
      "Epoch 70/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.4164\n",
      "Epoch 00070: val_loss did not improve from 1.40949\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4163 - val_loss: 1.5023\n",
      "Epoch 00070: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 32.72\n",
      "RMSE: 5.72\n",
      "CMAPSS score: 1.52\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_3\\scaler.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_3\\pca.pkl\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 105.6114\n",
      "Epoch 00001: val_loss improved from inf to 14.08757, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 105.4815 - val_loss: 14.0876\n",
      "Epoch 2/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 9.5658\n",
      "Epoch 00002: val_loss improved from 14.08757 to 7.34689, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 9.5654 - val_loss: 7.3469\n",
      "Epoch 3/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 6.0949\n",
      "Epoch 00003: val_loss improved from 7.34689 to 5.66737, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 6.0949 - val_loss: 5.6674\n",
      "Epoch 4/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 4.9114\n",
      "Epoch 00004: val_loss improved from 5.66737 to 4.60128, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.9117 - val_loss: 4.6013\n",
      "Epoch 5/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 4.3313\n",
      "Epoch 00005: val_loss improved from 4.60128 to 4.29136, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 4.3312 - val_loss: 4.2914\n",
      "Epoch 6/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 3.9059\n",
      "Epoch 00006: val_loss improved from 4.29136 to 3.55571, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.9057 - val_loss: 3.5557\n",
      "Epoch 7/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 3.5989\n",
      "Epoch 00007: val_loss improved from 3.55571 to 3.55529, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.5990 - val_loss: 3.5553\n",
      "Epoch 8/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 3.3768\n",
      "Epoch 00008: val_loss improved from 3.55529 to 3.13945, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.3767 - val_loss: 3.1394\n",
      "Epoch 9/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 3.1790\n",
      "Epoch 00009: val_loss did not improve from 3.13945\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.1787 - val_loss: 3.6150\n",
      "Epoch 10/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 3.0333\n",
      "Epoch 00010: val_loss improved from 3.13945 to 2.79450, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 3.0331 - val_loss: 2.7945\n",
      "Epoch 11/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.8918\n",
      "Epoch 00011: val_loss improved from 2.79450 to 2.77848, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8917 - val_loss: 2.7785\n",
      "Epoch 12/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.7820\n",
      "Epoch 00012: val_loss improved from 2.77848 to 2.72046, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.7823 - val_loss: 2.7205\n",
      "Epoch 13/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.6660\n",
      "Epoch 00013: val_loss did not improve from 2.72046\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.6660 - val_loss: 2.8503\n",
      "Epoch 14/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.5732\n",
      "Epoch 00014: val_loss improved from 2.72046 to 2.46548, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.5728 - val_loss: 2.4655\n",
      "Epoch 15/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.4844\n",
      "Epoch 00015: val_loss improved from 2.46548 to 2.25023, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4842 - val_loss: 2.2502\n",
      "Epoch 16/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 2.4338\n",
      "Epoch 00016: val_loss did not improve from 2.25023\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.4333 - val_loss: 2.2538\n",
      "Epoch 17/200\n",
      "7190/7197 [============================>.] - ETA: 0s - loss: 2.3627\n",
      "Epoch 00017: val_loss improved from 2.25023 to 2.15850, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3626 - val_loss: 2.1585\n",
      "Epoch 18/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.2801\n",
      "Epoch 00018: val_loss did not improve from 2.15850\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2801 - val_loss: 2.5875\n",
      "Epoch 19/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.2553\n",
      "Epoch 00019: val_loss improved from 2.15850 to 2.12626, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.2554 - val_loss: 2.1263\n",
      "Epoch 20/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.1993\n",
      "Epoch 00020: val_loss did not improve from 2.12626\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1994 - val_loss: 2.5970\n",
      "Epoch 21/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.1775- ET\n",
      "Epoch 00021: val_loss improved from 2.12626 to 2.04297, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.1775 - val_loss: 2.0430\n",
      "Epoch 22/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.1216\n",
      "Epoch 00022: val_loss did not improve from 2.04297\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1214 - val_loss: 2.1888\n",
      "Epoch 23/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.0672\n",
      "Epoch 00023: val_loss improved from 2.04297 to 1.96064, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 2.0670 - val_loss: 1.9606\n",
      "Epoch 24/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.0587\n",
      "Epoch 00024: val_loss did not improve from 1.96064\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.0583 - val_loss: 1.9873\n",
      "Epoch 25/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 2.0235\n",
      "Epoch 00025: val_loss did not improve from 1.96064\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.0233 - val_loss: 1.9643\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.9689- ETA: 0s \n",
      "Epoch 00026: val_loss improved from 1.96064 to 1.82508, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.9684 - val_loss: 1.8251\n",
      "Epoch 27/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.9325\n",
      "Epoch 00027: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9325 - val_loss: 1.9621\n",
      "Epoch 28/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.9154\n",
      "Epoch 00028: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9151 - val_loss: 2.0261\n",
      "Epoch 29/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.9085\n",
      "Epoch 00029: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.9089 - val_loss: 1.8493\n",
      "Epoch 30/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.8431\n",
      "Epoch 00030: val_loss did not improve from 1.82508\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8434 - val_loss: 2.4517\n",
      "Epoch 31/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8409\n",
      "Epoch 00031: val_loss improved from 1.82508 to 1.64970, saving model to DS02/experiment_set_6\\results_pca\\split_3\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8409 - val_loss: 1.6497\n",
      "Epoch 32/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.8378\n",
      "Epoch 00032: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.8384 - val_loss: 1.9648\n",
      "Epoch 33/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.8130\n",
      "Epoch 00033: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.8130 - val_loss: 1.9908\n",
      "Epoch 34/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.7996\n",
      "Epoch 00034: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7996 - val_loss: 2.3808\n",
      "Epoch 35/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.7596\n",
      "Epoch 00035: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7597 - val_loss: 2.3413\n",
      "Epoch 36/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.7763\n",
      "Epoch 00036: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7768 - val_loss: 1.7960\n",
      "Epoch 37/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.7456\n",
      "Epoch 00037: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7456 - val_loss: 1.7737\n",
      "Epoch 38/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.7171\n",
      "Epoch 00038: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7170 - val_loss: 1.6574\n",
      "Epoch 39/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 1.6817\n",
      "Epoch 00039: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6817 - val_loss: 1.7559\n",
      "Epoch 40/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7004\n",
      "Epoch 00040: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.7004 - val_loss: 1.7617\n",
      "Epoch 41/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.6599\n",
      "Epoch 00041: val_loss did not improve from 1.64970\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 1.6603 - val_loss: 1.8178\n",
      "Epoch 00041: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_3\\history.pkl\n",
      "Test set:\n",
      "MSE: 36.53\n",
      "RMSE: 6.04\n",
      "CMAPSS score: 1.56\n",
      "\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_4\\scaler.pkl\n",
      "Saved object to file: DS02/experiment_set_6\\results_pca\\split_4\\pca.pkl\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 256)               1792      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 232,065\n",
      "Trainable params: 232,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 103.0529\n",
      "Epoch 00001: val_loss improved from inf to 14.98844, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 103.0389 - val_loss: 14.9884\n",
      "Epoch 2/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 9.2333\n",
      "Epoch 00002: val_loss improved from 14.98844 to 6.88040, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 9.2328 - val_loss: 6.8804\n",
      "Epoch 3/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 5.8592\n",
      "Epoch 00003: val_loss improved from 6.88040 to 5.15158, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 5.8599 - val_loss: 5.1516\n",
      "Epoch 4/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 4.7302\n",
      "Epoch 00004: val_loss did not improve from 5.15158\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 4.7304 - val_loss: 5.4690\n",
      "Epoch 5/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 4.1814\n",
      "Epoch 00005: val_loss improved from 5.15158 to 3.74251, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 4.1810 - val_loss: 3.7425\n",
      "Epoch 6/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 3.7810\n",
      "Epoch 00006: val_loss did not improve from 3.74251\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.7816 - val_loss: 4.4628\n",
      "Epoch 7/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 3.4765\n",
      "Epoch 00007: val_loss did not improve from 3.74251\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 3.4757 - val_loss: 3.7773\n",
      "Epoch 8/200\n",
      "7182/7197 [============================>.] - ETA: 0s - loss: 3.2653\n",
      "Epoch 00008: val_loss improved from 3.74251 to 3.32227, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.2657 - val_loss: 3.3223\n",
      "Epoch 9/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 3.0996\n",
      "Epoch 00009: val_loss improved from 3.32227 to 2.80296, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 3.0992 - val_loss: 2.8030\n",
      "Epoch 10/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 2.9280\n",
      "Epoch 00010: val_loss improved from 2.80296 to 2.56991, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.9280 - val_loss: 2.5699\n",
      "Epoch 11/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.8063\n",
      "Epoch 00011: val_loss did not improve from 2.56991\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.8062 - val_loss: 3.1983\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.6982\n",
      "Epoch 00012: val_loss did not improve from 2.56991\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.6979 - val_loss: 2.6942\n",
      "Epoch 13/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.5879\n",
      "Epoch 00013: val_loss did not improve from 2.56991\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.5882 - val_loss: 2.6061\n",
      "Epoch 14/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 2.4779\n",
      "Epoch 00014: val_loss improved from 2.56991 to 2.56137, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4778 - val_loss: 2.5614\n",
      "Epoch 15/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 2.4391\n",
      "Epoch 00015: val_loss did not improve from 2.56137\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.4392 - val_loss: 2.7317\n",
      "Epoch 16/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 2.3537\n",
      "Epoch 00016: val_loss improved from 2.56137 to 2.20523, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3535 - val_loss: 2.2052\n",
      "Epoch 17/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.3218\n",
      "Epoch 00017: val_loss improved from 2.20523 to 2.15376, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.3217 - val_loss: 2.1538\n",
      "Epoch 18/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 2.2631\n",
      "Epoch 00018: val_loss improved from 2.15376 to 2.06571, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.2632 - val_loss: 2.0657\n",
      "Epoch 19/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 2.2097\n",
      "Epoch 00019: val_loss improved from 2.06571 to 2.01537, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 36s 5ms/step - loss: 2.2098 - val_loss: 2.0154\n",
      "Epoch 20/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 2.1410\n",
      "Epoch 00020: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 2.1412 - val_loss: 2.3181\n",
      "Epoch 21/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 2.1264\n",
      "Epoch 00021: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.1265 - val_loss: 2.1127\n",
      "Epoch 22/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.0747\n",
      "Epoch 00022: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.0749 - val_loss: 3.2425\n",
      "Epoch 23/200\n",
      "7188/7197 [============================>.] - ETA: 0s - loss: 2.0300\n",
      "Epoch 00023: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.0298 - val_loss: 3.0204\n",
      "Epoch 24/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 2.0111\n",
      "Epoch 00024: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 2.0111 - val_loss: 2.3206\n",
      "Epoch 25/200\n",
      "7187/7197 [============================>.] - ETA: 0s - loss: 1.9491\n",
      "Epoch 00025: val_loss did not improve from 2.01537\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.9496 - val_loss: 2.6184\n",
      "Epoch 26/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.9615\n",
      "Epoch 00026: val_loss improved from 2.01537 to 1.81037, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.9611 - val_loss: 1.8104\n",
      "Epoch 27/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.9173\n",
      "Epoch 00027: val_loss did not improve from 1.81037\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.9173 - val_loss: 2.0126\n",
      "Epoch 28/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.8692\n",
      "Epoch 00028: val_loss did not improve from 1.81037\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8692 - val_loss: 2.2174\n",
      "Epoch 29/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.8866\n",
      "Epoch 00029: val_loss did not improve from 1.81037\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8870 - val_loss: 2.1274\n",
      "Epoch 30/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.8663\n",
      "Epoch 00030: val_loss improved from 1.81037 to 1.61255, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 37s 5ms/step - loss: 1.8657 - val_loss: 1.6126\n",
      "Epoch 31/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.8112\n",
      "Epoch 00031: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8111 - val_loss: 2.4027\n",
      "Epoch 32/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.8204\n",
      "Epoch 00032: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.8205 - val_loss: 1.8177\n",
      "Epoch 33/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7830\n",
      "Epoch 00033: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7834 - val_loss: 1.7582\n",
      "Epoch 34/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.7621\n",
      "Epoch 00034: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7624 - val_loss: 1.9941\n",
      "Epoch 35/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7593\n",
      "Epoch 00035: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7592 - val_loss: 1.8214\n",
      "Epoch 36/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.7330\n",
      "Epoch 00036: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7332 - val_loss: 1.7654\n",
      "Epoch 37/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7247\n",
      "Epoch 00037: val_loss did not improve from 1.61255\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7248 - val_loss: 1.8966\n",
      "Epoch 38/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.6949\n",
      "Epoch 00038: val_loss improved from 1.61255 to 1.58689, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6940 - val_loss: 1.5869\n",
      "Epoch 39/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.7012\n",
      "Epoch 00039: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.7011 - val_loss: 1.6053\n",
      "Epoch 40/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.6677\n",
      "Epoch 00040: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6676 - val_loss: 1.6569\n",
      "Epoch 41/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.6568\n",
      "Epoch 00041: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6570 - val_loss: 1.8143\n",
      "Epoch 42/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.6377\n",
      "Epoch 00042: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6376 - val_loss: 1.6731\n",
      "Epoch 43/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.6151\n",
      "Epoch 00043: val_loss did not improve from 1.58689\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6150 - val_loss: 1.8214\n",
      "Epoch 44/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.6035\n",
      "Epoch 00044: val_loss improved from 1.58689 to 1.56316, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.6037 - val_loss: 1.5632\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.6228\n",
      "Epoch 00045: val_loss did not improve from 1.56316\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6228 - val_loss: 1.9158\n",
      "Epoch 46/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.5886\n",
      "Epoch 00046: val_loss did not improve from 1.56316\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5886 - val_loss: 1.5728\n",
      "Epoch 47/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.6128\n",
      "Epoch 00047: val_loss did not improve from 1.56316\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.6128 - val_loss: 1.6792\n",
      "Epoch 48/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.5605\n",
      "Epoch 00048: val_loss improved from 1.56316 to 1.48890, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5599 - val_loss: 1.4889\n",
      "Epoch 49/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.5777\n",
      "Epoch 00049: val_loss did not improve from 1.48890\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5775 - val_loss: 1.6890\n",
      "Epoch 50/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5434\n",
      "Epoch 00050: val_loss improved from 1.48890 to 1.36087, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.5432 - val_loss: 1.3609\n",
      "Epoch 51/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5631\n",
      "Epoch 00051: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5635 - val_loss: 2.8896\n",
      "Epoch 52/200\n",
      "7194/7197 [============================>.] - ETA: 0s - loss: 1.5615\n",
      "Epoch 00052: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5615 - val_loss: 1.5781\n",
      "Epoch 53/200\n",
      "7181/7197 [============================>.] - ETA: 0s - loss: 1.5259\n",
      "Epoch 00053: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5268 - val_loss: 1.9175\n",
      "Epoch 54/200\n",
      "7196/7197 [============================>.] - ETA: 0s - loss: 1.5347\n",
      "Epoch 00054: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5347 - val_loss: 1.8904\n",
      "Epoch 55/200\n",
      "7193/7197 [============================>.] - ETA: 0s - loss: 1.5222\n",
      "Epoch 00055: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5222 - val_loss: 2.0372\n",
      "Epoch 56/200\n",
      "7192/7197 [============================>.] - ETA: 0s - loss: 1.5148\n",
      "Epoch 00056: val_loss did not improve from 1.36087\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5148 - val_loss: 1.5989\n",
      "Epoch 57/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4901\n",
      "Epoch 00057: val_loss improved from 1.36087 to 1.32864, saving model to DS02/experiment_set_6\\results_pca\\split_4\\mlp_model_trained.h5\n",
      "7197/7197 [==============================] - 35s 5ms/step - loss: 1.4901 - val_loss: 1.3286\n",
      "Epoch 58/200\n",
      "7183/7197 [============================>.] - ETA: 0s - loss: 1.4955\n",
      "Epoch 00058: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4950 - val_loss: 1.3697\n",
      "Epoch 59/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.5013\n",
      "Epoch 00059: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.5013 - val_loss: 1.4495\n",
      "Epoch 60/200\n",
      "7184/7197 [============================>.] - ETA: 0s - loss: 1.4705\n",
      "Epoch 00060: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4704 - val_loss: 1.5607\n",
      "Epoch 61/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4847\n",
      "Epoch 00061: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4850 - val_loss: 1.5382\n",
      "Epoch 62/200\n",
      "7197/7197 [==============================] - ETA: 0s - loss: 1.4469\n",
      "Epoch 00062: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4469 - val_loss: 1.3327\n",
      "Epoch 63/200\n",
      "7186/7197 [============================>.] - ETA: 0s - loss: 1.4706\n",
      "Epoch 00063: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4703 - val_loss: 1.4783\n",
      "Epoch 64/200\n",
      "7185/7197 [============================>.] - ETA: 0s - loss: 1.4718\n",
      "Epoch 00064: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4714 - val_loss: 1.3554\n",
      "Epoch 65/200\n",
      "7191/7197 [============================>.] - ETA: 0s - loss: 1.4388\n",
      "Epoch 00065: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4385 - val_loss: 1.5002\n",
      "Epoch 66/200\n",
      "7195/7197 [============================>.] - ETA: 0s - loss: 1.4565\n",
      "Epoch 00066: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4568 - val_loss: 2.1125\n",
      "Epoch 67/200\n",
      "7189/7197 [============================>.] - ETA: 0s - loss: 1.4467\n",
      "Epoch 00067: val_loss did not improve from 1.32864\n",
      "7197/7197 [==============================] - 34s 5ms/step - loss: 1.4467 - val_loss: 1.5411\n",
      "Epoch 00067: early stopping\n",
      "Saved training history to file: DS02/experiment_set_6\\results_pca\\split_4\\history.pkl\n",
      "Test set:\n",
      "MSE: 97.17\n",
      "RMSE: 9.86\n",
      "CMAPSS score: 2.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Test effect of PCA for feature extraction\n",
    "###########################################\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "layer_sizes = [256, 256, 512, 64]\n",
    "\n",
    "results_path = os.path.join(output_path, \"results_pca\")\n",
    "results_file = os.path.join(results_path, \"results_pca.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "mse_vals = []\n",
    "rmse_vals = []\n",
    "cmapss_vals = []\n",
    "    \n",
    "for random_seed in range(NUM_TRIALS):\n",
    "    # Train-validation split for early stopping\n",
    "    x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train, \n",
    "                                                                              y_train, \n",
    "                                                                              test_size=0.3, \n",
    "                                                                              random_state=random_seed)\n",
    "    # Create output path\n",
    "    results_path_crr_split = os.path.join(results_path, \"split_{}\".format(random_seed))\n",
    "    if not os.path.exists(results_path_crr_split):\n",
    "        os.makedirs(results_path_crr_split)\n",
    "\n",
    "    # Standardization\n",
    "    scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train_split)\n",
    "    x_val_scaled = scaler.transform(x_val_split)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    save_object(scaler, scaler_file)\n",
    "    \n",
    "    # PCA\n",
    "    pca = get_principal_components(x_train_scaled, debug=False)\n",
    "    pca_file = os.path.join(results_path_crr_split, 'pca.pkl')\n",
    "    save_object(pca, pca_file)\n",
    "    \n",
    "    x_train_final = dimensionality_reduction(x_train_scaled, pca)\n",
    "    x_val_final = dimensionality_reduction(x_val_scaled, pca)\n",
    "    x_test_final = dimensionality_reduction(x_test_scaled, pca)\n",
    "    input_dim = x_train_final.shape[1]\n",
    "\n",
    "    # Create model\n",
    "    weights_file = os.path.join(results_path, 'mlp_initial_weights.h5')\n",
    "    model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "        \n",
    "    # Save initial weights\n",
    "    if random_seed == 0:\n",
    "        model = create_mlp_model(input_dim, layer_sizes, activation='tanh',\n",
    "                                  output_weights_file=weights_file)\n",
    "    else:\n",
    "        model = create_mlp_model(input_dim, layer_sizes, activation='tanh')\n",
    "    model.summary()\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=2, \n",
    "                         save_best_only=True)\n",
    "\n",
    "    # Train model\n",
    "    history = train_model_existing_weights(model, weights_file, \n",
    "                                           x_train_final, y_train_split, \n",
    "                                           x_val_final, y_val_split, \n",
    "                                           batch_size=batch_size, \n",
    "                                           epochs=epochs, \n",
    "                                           callbacks=[es, mc])\n",
    "\n",
    "    history_file = os.path.join(results_path_crr_split, \"history.pkl\")\n",
    "    save_history(history, history_file)\n",
    "\n",
    "    # Performance evaluation\n",
    "    loaded_model = load_model(model_path)\n",
    "    predictions_test = loaded_model.predict(x_test_final).flatten()\n",
    "    mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_test, y_test)\n",
    "        \n",
    "    mse_vals.append(mse)\n",
    "    rmse_vals.append(rmse)\n",
    "    cmapss_vals.append(cmapss_score)\n",
    "    \n",
    "mse_mean = np.mean(mse_vals)\n",
    "mse_std = np.std(mse_vals)\n",
    "rmse_mean = np.mean(rmse_vals)\n",
    "rmse_std = np.std(rmse_vals)\n",
    "cmapss_mean = np.mean(cmapss_vals)\n",
    "cmapss_std = np.std(cmapss_vals)\n",
    "    \n",
    "with open(results_file, \"a\") as file:   \n",
    "    file.write(f\"{numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)}, {numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean}, {rmse_std}, {cmapss_mean}, {cmapss_std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-keras-gpu",
   "language": "python",
   "name": "tf-keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
