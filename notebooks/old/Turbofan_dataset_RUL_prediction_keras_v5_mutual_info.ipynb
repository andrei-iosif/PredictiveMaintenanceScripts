{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "seed = 0\n",
    "os.environ['PYTHONHASSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/turbofan_dataset/N-CMAPSS_DS02-006.h5'\n",
    "output_path = 'DS02/experiment_set_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, load_test_set=True):\n",
    "    \"\"\" Reads a dataset from a given .h5 file and compose (in memory) the train and test data. \n",
    "    Args:\n",
    "        filename(str): path to the .h5 file\n",
    "    Returns:\n",
    "        train_set(pd.DataFrame), test_set(pd.DataFrame)\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as hdf:\n",
    "        # Development set\n",
    "        W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "        X_v_dev = np.array(hdf.get('X_v_dev'))         # X_v\n",
    "        T_dev = np.array(hdf.get('T_dev'))             # T\n",
    "        Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
    "        A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "        # Test set\n",
    "        if load_test_set:\n",
    "            W_test = np.array(hdf.get('W_test'))           # W\n",
    "            X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
    "            X_v_test = np.array(hdf.get('X_v_test'))       # X_v\n",
    "            T_test = np.array(hdf.get('T_test'))           # T\n",
    "            Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
    "            A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
    "        \n",
    "        # Column names\n",
    "        W_var = np.array(hdf.get('W_var'))\n",
    "        X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "        X_v_var = np.array(hdf.get('X_v_var')) \n",
    "        T_var = np.array(hdf.get('T_var'))\n",
    "        A_var = np.array(hdf.get('A_var'))\n",
    "        \n",
    "        columns = []\n",
    "        columns.append(list(np.array(A_var, dtype='U20')))\n",
    "        columns.append(list(np.array(T_var, dtype='U20')))\n",
    "        columns.append(list(np.array(X_s_var, dtype='U20')))\n",
    "        columns.append(list(np.array(X_v_var, dtype='U20')))\n",
    "        columns.append(list(np.array(W_var, dtype='U20')))\n",
    "        columns.append(['RUL'])\n",
    "        \n",
    "        columns_list = []\n",
    "        for columns_per_category in columns:\n",
    "            columns_list += columns_per_category\n",
    "        \n",
    "    train_set = np.concatenate((A_dev, T_dev, X_s_dev, X_v_dev, W_dev, Y_dev), axis=1)\n",
    "    if load_test_set:\n",
    "        test_set = np.concatenate((A_test, T_test, X_s_test, X_v_test, W_test, Y_test), axis=1)\n",
    "        return pd.DataFrame(data=train_set, columns=columns_list), pd.DataFrame(data=test_set, columns=columns_list), columns\n",
    "    else:\n",
    "        return pd.DataFrame(data=train_set, columns=columns_list), None, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_cycle_info(df, compute_cycle_len=False):\n",
    "    unit_ids = np.unique(df['unit'])\n",
    "    print('Engine units in df: ', unit_ids)\n",
    "    for i in unit_ids:\n",
    "        num_cycles = len(np.unique(df.loc[df['unit'] == i, 'cycle']))\n",
    "        print('Unit: ', i, ' - Number of flight cycles: ', num_cycles)\n",
    "        \n",
    "    if compute_cycle_len:\n",
    "        cycle_ids = np.unique(df['cycle'])\n",
    "        print('Total number of cycles: ', len(cycle_ids))\n",
    "        min_len = np.inf\n",
    "        max_len = 0\n",
    "        for i in cycle_ids:\n",
    "            cycle_len = len(df.loc[df['cycle'] == i, 'cycle'])\n",
    "            if cycle_len < min_len:\n",
    "                min_len = cycle_len\n",
    "            elif cycle_len > max_len:\n",
    "                max_len = cycle_len\n",
    "        print('Min cycle length: ', min_len)\n",
    "        print('Max cycle length: ', max_len)\n",
    "    \n",
    "    return unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter constant and quasi-constant features\n",
    "def get_quasi_constant_features(dataset, variance_th=0.01, debug=True):\n",
    "    constant_filter = VarianceThreshold(threshold=variance_th)\n",
    "    constant_filter.fit(dataset)\n",
    "    constant_features = [col for col in dataset.columns \n",
    "                         if col not in dataset.columns[constant_filter.get_support()]]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Number of non-constant features: \", len(dataset.columns[constant_filter.get_support()]))\n",
    "        \n",
    "        print(\"Number of quasi-constant features: \", len(constant_features))\n",
    "        print(\"Quasi-constant features: \")\n",
    "        for col in constant_features:\n",
    "            print(col)\n",
    "    return constant_features\n",
    "\n",
    "def get_non_correlated_features(dataset, corr_th=0.9, debug=True):\n",
    "    corr_mat = dataset.corr()\n",
    "    corr_mat = np.abs(corr_mat)\n",
    "    \n",
    "    num_cols = corr_mat.shape[0]\n",
    "    columns = np.full((num_cols,), True, dtype=bool)\n",
    "    for i in range(num_cols):\n",
    "        for j in range(i+1, num_cols):\n",
    "            val = corr_mat.iloc[i, j]\n",
    "            if val >= corr_th:\n",
    "                if columns[j]:\n",
    "                    columns[j] = False\n",
    "                    if debug:\n",
    "                        print(dataset.columns[i], \"|\", dataset.columns[j], \"|\", round(val, 2))\n",
    "    if debug:        \n",
    "        correlated_features = dataset.columns[~columns]\n",
    "        print(\"Number of correlated features: \", len(correlated_features))\n",
    "        print(\"Correlated features: \", list(correlated_features))\n",
    "    \n",
    "    selected_columns = dataset.columns[columns]\n",
    "    if debug:\n",
    "        print(\"Number of selected features: \", len(selected_columns))\n",
    "        print(\"Selected features: \", list(selected_columns))\n",
    "    return selected_columns\n",
    "\n",
    "def cmapss_score_function(actual, predictions, normalize=True):\n",
    "    # diff < 0 -> over-estimation\n",
    "    # diff > 0 -> under-estimation\n",
    "    diff = actual - predictions\n",
    "    alpha = np.full_like(diff, 1/13)\n",
    "    negative_diff_mask = diff < 0\n",
    "    alpha[negative_diff_mask] = 1/10\n",
    "    score = np.sum(np.exp(alpha * np.abs(diff)))\n",
    "    \n",
    "    if normalize:\n",
    "        N = len(predictions)\n",
    "        score /= N\n",
    "    return score\n",
    "\n",
    "def compute_evaluation_metrics(actual, predictions, label='Test'):\n",
    "    mse = mean_squared_error(actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    cmapss_score = cmapss_score_function(actual, predictions)\n",
    "    print('{} set:\\nMSE: {:.2f}\\nRMSE: {:.2f}\\nCMAPSS score: {:.2f}\\n'.format(label, mse, rmse, \n",
    "                                                                     cmapss_score))\n",
    "    return mse, rmse, cmapss_score\n",
    "    \n",
    "def plot_loss_curves(history, output_path=None, y_lim=[0, 150]):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylim(y_lim)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    \n",
    "    if output_path is not None:\n",
    "        plt.savefig(os.path.join(output_path, 'loss_curves.png'), format='png', dpi=300) \n",
    "    plt.show()\n",
    "    \n",
    "def plot_rul(expected, predicted):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(expected)), expected, label='Expected')\n",
    "    plt.plot(range(len(predicted)), predicted, label='Predicted')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def create_mlp_model(input_dim, hidden_layer_sizes, activation='relu', output_weights_file=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], \n",
    "                    input_dim=input_dim, \n",
    "                    kernel_initializer='random_normal', \n",
    "                    activation=activation))\n",
    "\n",
    "    for layer_size in hidden_layer_sizes[1:]:\n",
    "        model.add(Dense(layer_size, \n",
    "                        kernel_initializer='random_normal', \n",
    "                        activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='random_normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    if output_weights_file is not None:\n",
    "        model.save_weights(output_weights_file)\n",
    "    return model\n",
    "\n",
    "def train_model_existing_weights(model, weights_file, x_train, y_train, x_val, y_val, epochs=200, batch_size=512, callbacks=[]):\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.load_weights(weights_file)\n",
    "    return model.fit(x_train, y_train,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     verbose=1,\n",
    "                     callbacks=callbacks)\n",
    "\n",
    "def save_history(history, output_file=os.path.join(output_path, \"history.pkl\")):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "    print(\"Saved training history to file: {}\".format(output_file))\n",
    "\n",
    "def load_history(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def save_object(obj, output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    print(\"Saved object to file: {}\".format(output_file))\n",
    "    \n",
    "def load_object(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "def model_evaluation(model, x_test, y_test, x_train=None, y_train=None, plot_range=[0, 10**3]):\n",
    "    if x_train is not None and y_train is not None:\n",
    "        predictions_train = model.predict(x_train).flatten()\n",
    "        compute_evaluation_metrics(predictions_train, y_train, 'Train')\n",
    "        \n",
    "        expected = y_train[plot_range[0]:plot_range[1]]\n",
    "        predicted = predictions_train[plot_range[0]:plot_range[1]]\n",
    "        plot_rul(expected, predicted)\n",
    "        \n",
    "    predictions_test = model.predict(x_test).flatten()\n",
    "    compute_evaluation_metrics(predictions_test, y_test)\n",
    "    \n",
    "    expected = y_test[plot_range[0]:plot_range[1]]\n",
    "    predicted = predictions_test[plot_range[0]:plot_range[1]]\n",
    "    plot_rul(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list(string_list, output_file):\n",
    "    output_file.write(\"[\")\n",
    "    n = len(string_list)\n",
    "    for i in range(n - 1):\n",
    "        output_file.write(\"{}, \".format(string_list[i]))\n",
    "    output_file.write(\"{}]\\n\".format(string_list[-1]))\n",
    "    \n",
    "def feature_list_to_string(feature_list):\n",
    "    return \"__\".join(feature_list)\n",
    "\n",
    "def numbers_list_to_string(num_list):\n",
    "    return \" \".join([str(x) for x in num_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mi_ranked_features(mi, n):\n",
    "    mi_sorted = mi.sort_values(by=\"MI\", ascending=False)\n",
    "    return mi[:n][\"Col\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation time (sec):  3.578125\n",
      "\n",
      "Train set shape: (5263447, 47)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()  \n",
    "train_set, test_set, columns = load_dataset(filename)\n",
    "print(\"Operation time (sec): \" , (time.process_time() - start_time))\n",
    "print()\n",
    "print(\"Train set shape: \" + str(train_set.shape))\n",
    "\n",
    "columns_aux = columns[0] \n",
    "columns_health_params = columns[1] \n",
    "columns_sensor_measurements = columns[2] \n",
    "columns_virtual_sensors = columns[3]\n",
    "columns_operating_conditions = columns[4] \n",
    "target_col = columns[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['RUL']\n",
    "x_train = train_set.drop(['RUL'], axis=1)\n",
    "\n",
    "y_test = test_set['RUL']\n",
    "x_test = test_set.drop(['RUL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-constant features:  35\n",
      "Number of quasi-constant features:  7\n",
      "Quasi-constant features: \n",
      "fan_eff_mod\n",
      "fan_flow_mod\n",
      "LPC_eff_mod\n",
      "LPC_flow_mod\n",
      "HPC_eff_mod\n",
      "HPC_flow_mod\n",
      "HPT_flow_mod\n",
      "Train shape:  (5263447, 35)\n"
     ]
    }
   ],
   "source": [
    "x_train.drop(labels=[x for x in columns_aux if x in x_train.columns], axis=1, inplace=True)\n",
    "\n",
    "constant_features = get_quasi_constant_features(x_train, variance_th=0.0)\n",
    "x_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "print(\"Train shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_mi, y_train, y_mi = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation time (sec):  3053.765625\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()  \n",
    "mi = mutual_info_regression(x_mi, y_mi, random_state=seed)\n",
    "print(\"Operation time (sec): \" , (time.process_time() - start_time))\n",
    "\n",
    "mi_series = pd.Series(mi, index=x_train.columns)\n",
    "mi_series = mi_series.sort_values(ascending=False)\n",
    "normalized_mi = (mi_series - mi_series.min()) / (mi_series.max() - mi_series.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_mi[:15].plot.bar(color='steelblue', figsize=(12, 6))\n",
    "plt.savefig(os.path.join(output_path, \"mutual_info.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mi.to_csv(os.path.join(output_path, \"mi_ranking_42.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = get_mi_ranked_features(mutual_info_series, 10)\n",
    "x_train_feature_selection = x_train[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine units in df:  [ 2.  5. 10. 16. 18. 20.]\n",
      "Unit:  2.0  - Number of flight cycles:  75\n",
      "Unit:  5.0  - Number of flight cycles:  89\n",
      "Unit:  10.0  - Number of flight cycles:  82\n",
      "Unit:  16.0  - Number of flight cycles:  63\n",
      "Unit:  18.0  - Number of flight cycles:  71\n",
      "Unit:  20.0  - Number of flight cycles:  66\n"
     ]
    }
   ],
   "source": [
    "train_unit_ids = unit_cycle_info(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HPT_eff_mod',\n",
       " 'LPT_flow_mod',\n",
       " 'LPT_eff_mod',\n",
       " 'P2',\n",
       " 'T2',\n",
       " 'alt',\n",
       " 'P50',\n",
       " 'P21',\n",
       " 'P15',\n",
       " 'Mach']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_window_processing(X, y, column_names, unit_ids, window_size):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    lag_columns = []\n",
    "    \n",
    "    for col_name in column_names:\n",
    "        for i in range(1, window_size):\n",
    "            partial_columns = []\n",
    "            for j in range(len(unit_ids)):\n",
    "                unit_df = df.loc[df['unit'] == unit_ids[j], :]\n",
    "                col = unit_df[col_name].shift(i)\n",
    "                col.name = '{}(t-{})'.format(col_name, i)\n",
    "                partial_columns.append(col)\n",
    "            column = pd.concat(partial_columns)\n",
    "            lag_columns.append(column)\n",
    "    \n",
    "    df = pd.concat([df] + lag_columns, axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(labels=['unit'], axis=1, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    feature_columns = [col for col in df.columns.values if col != 'RUL']    \n",
    "    return df[feature_columns], df['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = x_train.corrwith(y_train)\n",
    "# abs_corr = np.abs(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_corr = abs_corr.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# abs_corr[:15].plot.bar(color='steelblue', figsize=(12, 6))\n",
    "# plt.savefig(os.path.join(output_path, \"correlation.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_series = pd.read_csv(os.path.join(output_path, \"mutual_info.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_holdout, y_train, y_holdout = train_test_split(x_train, \n",
    "                                                          y_train, \n",
    "                                                          test_size=0.3, \n",
    "                                                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to file: DS02/experiment_set_10\\results_10\\split_0\\scaler.pkl\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 233,089\n",
      "Trainable params: 233,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 129.4557\n",
      "Epoch 00001: val_loss improved from inf to 17.05996, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 129.4557 - val_loss: 17.0600\n",
      "Epoch 2/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 14.3040\n",
      "Epoch 00002: val_loss improved from 17.05996 to 11.28832, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 14.3008 - val_loss: 11.2883\n",
      "Epoch 3/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 8.9565\n",
      "Epoch 00003: val_loss improved from 11.28832 to 7.21536, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 8.9549 - val_loss: 7.2154\n",
      "Epoch 4/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 6.7226\n",
      "Epoch 00004: val_loss improved from 7.21536 to 6.17360, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 6.7224 - val_loss: 6.1736\n",
      "Epoch 5/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 5.4456\n",
      "Epoch 00005: val_loss improved from 6.17360 to 4.65382, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.4456 - val_loss: 4.6538\n",
      "Epoch 6/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 4.7337\n",
      "Epoch 00006: val_loss improved from 4.65382 to 4.21661, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.7336 - val_loss: 4.2166\n",
      "Epoch 7/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 4.1921\n",
      "Epoch 00007: val_loss improved from 4.21661 to 4.10918, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.1920 - val_loss: 4.1092\n",
      "Epoch 8/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 3.8458\n",
      "Epoch 00008: val_loss did not improve from 4.10918\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.8477 - val_loss: 5.1864\n",
      "Epoch 9/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.5687- ETA: 0s - loss: \n",
      "Epoch 00009: val_loss improved from 4.10918 to 2.86282, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 29s 5ms/step - loss: 3.5686 - val_loss: 2.8628\n",
      "Epoch 10/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.2489\n",
      "Epoch 00010: val_loss did not improve from 2.86282\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.2487 - val_loss: 3.2773\n",
      "Epoch 11/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.1184- ETA: 0s - loss: 3.115\n",
      "Epoch 00011: val_loss did not improve from 2.86282\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.1201 - val_loss: 3.8327\n",
      "Epoch 12/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.9642\n",
      "Epoch 00012: val_loss improved from 2.86282 to 2.68725, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.9642 - val_loss: 2.6872\n",
      "Epoch 13/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.8286\n",
      "Epoch 00013: val_loss improved from 2.68725 to 2.44998, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.8287 - val_loss: 2.4500\n",
      "Epoch 14/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.6958\n",
      "Epoch 00014: val_loss improved from 2.44998 to 2.16577, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.6951 - val_loss: 2.1658\n",
      "Epoch 15/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.5727\n",
      "Epoch 00015: val_loss did not improve from 2.16577\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5745 - val_loss: 3.4805\n",
      "Epoch 16/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.5722\n",
      "Epoch 00016: val_loss did not improve from 2.16577\n",
      "6477/6477 [==============================] - 29s 5ms/step - loss: 2.5727 - val_loss: 3.0863\n",
      "Epoch 17/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.4057\n",
      "Epoch 00017: val_loss did not improve from 2.16577\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.4067 - val_loss: 2.9246\n",
      "Epoch 18/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.3457\n",
      "Epoch 00018: val_loss did not improve from 2.16577\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 2.3457 - val_loss: 2.1921\n",
      "Epoch 19/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.3059\n",
      "Epoch 00019: val_loss did not improve from 2.16577\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3068 - val_loss: 3.5938\n",
      "Epoch 20/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.2180\n",
      "Epoch 00020: val_loss improved from 2.16577 to 1.45400, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.2182 - val_loss: 1.4540\n",
      "Epoch 21/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.1314\n",
      "Epoch 00021: val_loss did not improve from 1.45400\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1315 - val_loss: 1.8943\n",
      "Epoch 22/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.0890\n",
      "Epoch 00022: val_loss did not improve from 1.45400\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.0884 - val_loss: 1.5524\n",
      "Epoch 23/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.0397\n",
      "Epoch 00023: val_loss did not improve from 1.45400\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.0394 - val_loss: 1.6434\n",
      "Epoch 24/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.0102\n",
      "Epoch 00024: val_loss did not improve from 1.45400\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0103 - val_loss: 1.8240\n",
      "Epoch 25/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.9430\n",
      "Epoch 00025: val_loss did not improve from 1.45400\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9426 - val_loss: 1.8594\n",
      "Epoch 26/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.926 - ETA: 0s - loss: 1.9259\n",
      "Epoch 00026: val_loss improved from 1.45400 to 1.43415, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9256 - val_loss: 1.4342\n",
      "Epoch 27/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.8709\n",
      "Epoch 00027: val_loss did not improve from 1.43415\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8709 - val_loss: 2.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.8582\n",
      "Epoch 00028: val_loss did not improve from 1.43415\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8582 - val_loss: 1.7358\n",
      "Epoch 29/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.8269\n",
      "Epoch 00029: val_loss did not improve from 1.43415\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8264 - val_loss: 1.5097\n",
      "Epoch 30/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.7593\n",
      "Epoch 00030: val_loss did not improve from 1.43415\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7593 - val_loss: 1.5826\n",
      "Epoch 31/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7577\n",
      "Epoch 00031: val_loss improved from 1.43415 to 1.42008, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7573 - val_loss: 1.4201\n",
      "Epoch 32/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.7266\n",
      "Epoch 00032: val_loss did not improve from 1.42008\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7269 - val_loss: 2.0027\n",
      "Epoch 33/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.6546\n",
      "Epoch 00033: val_loss did not improve from 1.42008\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6547 - val_loss: 2.3333\n",
      "Epoch 34/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.6881\n",
      "Epoch 00034: val_loss improved from 1.42008 to 1.18654, saving model to DS02/experiment_set_10\\results_10\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6870 - val_loss: 1.1865\n",
      "Epoch 35/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.6738\n",
      "Epoch 00035: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6734 - val_loss: 1.2650\n",
      "Epoch 36/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.6490- ETA: 0s - los\n",
      "Epoch 00036: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6489 - val_loss: 1.6859\n",
      "Epoch 37/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.6134\n",
      "Epoch 00037: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6137 - val_loss: 1.5703\n",
      "Epoch 38/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.5796- ETA: 0\n",
      "Epoch 00038: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5794 - val_loss: 1.5559\n",
      "Epoch 39/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5892\n",
      "Epoch 00039: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5893 - val_loss: 1.4123\n",
      "Epoch 40/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.5641\n",
      "Epoch 00040: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 36s 6ms/step - loss: 1.5648 - val_loss: 2.2557\n",
      "Epoch 41/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5624\n",
      "Epoch 00041: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 29s 4ms/step - loss: 1.5624 - val_loss: 1.1888\n",
      "Epoch 42/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.5387\n",
      "Epoch 00042: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5384 - val_loss: 1.4097\n",
      "Epoch 43/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5132\n",
      "Epoch 00043: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5131 - val_loss: 1.3627\n",
      "Epoch 44/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.5039\n",
      "Epoch 00044: val_loss did not improve from 1.18654\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5039 - val_loss: 1.6853\n",
      "Epoch 00044: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_10\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.19\n",
      "RMSE: 1.09\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_10\\split_1\\scaler.pkl\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 233,089\n",
      "Trainable params: 233,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 144.0416\n",
      "Epoch 00001: val_loss improved from inf to 17.71663, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 143.9923 - val_loss: 17.7166\n",
      "Epoch 2/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 14.1763\n",
      "Epoch 00002: val_loss improved from 17.71663 to 11.75324, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 14.1751 - val_loss: 11.7532\n",
      "Epoch 3/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 8.9391\n",
      "Epoch 00003: val_loss improved from 11.75324 to 7.13941, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 8.9389 - val_loss: 7.1394\n",
      "Epoch 4/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 6.6574\n",
      "Epoch 00004: val_loss improved from 7.13941 to 5.21166, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 6.6556 - val_loss: 5.2117\n",
      "Epoch 5/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 5.6158\n",
      "Epoch 00005: val_loss improved from 5.21166 to 4.38630, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.6154 - val_loss: 4.3863\n",
      "Epoch 6/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 4.8767\n",
      "Epoch 00006: val_loss did not improve from 4.38630\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.8772 - val_loss: 4.7302\n",
      "Epoch 7/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 4.4146\n",
      "Epoch 00007: val_loss improved from 4.38630 to 4.31539, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.4140 - val_loss: 4.3154\n",
      "Epoch 8/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 4.1274- \n",
      "Epoch 00008: val_loss improved from 4.31539 to 3.96814, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.1268 - val_loss: 3.9681\n",
      "Epoch 9/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.7249\n",
      "Epoch 00009: val_loss did not improve from 3.96814\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.7250 - val_loss: 5.8766\n",
      "Epoch 10/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 3.4887\n",
      "Epoch 00010: val_loss improved from 3.96814 to 2.71255, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.4887 - val_loss: 2.7126\n",
      "Epoch 11/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.3702- ETA: 1s - los - ETA: 1s - loss: 3.3 - ETA:\n",
      "Epoch 00011: val_loss did not improve from 2.71255\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3705 - val_loss: 4.8540\n",
      "Epoch 12/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 3.1252\n",
      "Epoch 00012: val_loss did not improve from 2.71255\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.1245 - val_loss: 2.8021\n",
      "Epoch 13/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.0194\n",
      "Epoch 00013: val_loss did not improve from 2.71255\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.0196 - val_loss: 2.9063\n",
      "Epoch 14/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.8635\n",
      "Epoch 00014: val_loss did not improve from 2.71255\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.8633 - val_loss: 3.0413\n",
      "Epoch 15/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.7674\n",
      "Epoch 00015: val_loss improved from 2.71255 to 2.33520, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.7673 - val_loss: 2.3352\n",
      "Epoch 16/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.6656\n",
      "Epoch 00016: val_loss did not improve from 2.33520\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6653 - val_loss: 2.5826\n",
      "Epoch 17/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.5684\n",
      "Epoch 00017: val_loss did not improve from 2.33520\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5687 - val_loss: 2.5266\n",
      "Epoch 18/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.4981\n",
      "Epoch 00018: val_loss did not improve from 2.33520\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4974 - val_loss: 2.7608\n",
      "Epoch 19/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.4321\n",
      "Epoch 00019: val_loss improved from 2.33520 to 1.98741, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.4318 - val_loss: 1.9874\n",
      "Epoch 20/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.3569\n",
      "Epoch 00020: val_loss did not improve from 1.98741\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3566 - val_loss: 2.0583\n",
      "Epoch 21/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.3176\n",
      "Epoch 00021: val_loss did not improve from 1.98741\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3171 - val_loss: 2.3585\n",
      "Epoch 22/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.2362\n",
      "Epoch 00022: val_loss did not improve from 1.98741\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2356 - val_loss: 3.0518\n",
      "Epoch 23/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.2039\n",
      "Epoch 00023: val_loss improved from 1.98741 to 1.74722, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.2038 - val_loss: 1.7472\n",
      "Epoch 24/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.1625\n",
      "Epoch 00024: val_loss did not improve from 1.74722\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1625 - val_loss: 1.8233\n",
      "Epoch 25/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.1007\n",
      "Epoch 00025: val_loss did not improve from 1.74722\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1010 - val_loss: 4.8742\n",
      "Epoch 26/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.0392\n",
      "Epoch 00026: val_loss improved from 1.74722 to 1.60181, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.0391 - val_loss: 1.6018\n",
      "Epoch 27/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.9757\n",
      "Epoch 00027: val_loss did not improve from 1.60181\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9760 - val_loss: 2.7482\n",
      "Epoch 28/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.9628\n",
      "Epoch 00028: val_loss did not improve from 1.60181\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9623 - val_loss: 1.6288\n",
      "Epoch 29/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.8983\n",
      "Epoch 00029: val_loss improved from 1.60181 to 1.50591, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8981 - val_loss: 1.5059\n",
      "Epoch 30/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.9055\n",
      "Epoch 00030: val_loss did not improve from 1.50591\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9054 - val_loss: 2.2842\n",
      "Epoch 31/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8667\n",
      "Epoch 00031: val_loss improved from 1.50591 to 1.40294, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8665 - val_loss: 1.4029\n",
      "Epoch 32/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.8275\n",
      "Epoch 00032: val_loss did not improve from 1.40294\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8275 - val_loss: 1.9915\n",
      "Epoch 33/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8078\n",
      "Epoch 00033: val_loss did not improve from 1.40294\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8077 - val_loss: 1.6519\n",
      "Epoch 34/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7492\n",
      "Epoch 00034: val_loss did not improve from 1.40294\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7519 - val_loss: 3.3065\n",
      "Epoch 35/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7439\n",
      "Epoch 00035: val_loss did not improve from 1.40294\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7443 - val_loss: 1.6562\n",
      "Epoch 36/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.7026\n",
      "Epoch 00036: val_loss did not improve from 1.40294\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7025 - val_loss: 1.4439\n",
      "Epoch 37/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.6889\n",
      "Epoch 00037: val_loss improved from 1.40294 to 1.34404, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6888 - val_loss: 1.3440\n",
      "Epoch 38/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.6478\n",
      "Epoch 00038: val_loss improved from 1.34404 to 1.32487, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.6476 - val_loss: 1.3249\n",
      "Epoch 39/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6331\n",
      "Epoch 00039: val_loss did not improve from 1.32487\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6331 - val_loss: 1.4935\n",
      "Epoch 40/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.6187- ETA: 0s - loss: 1.6\n",
      "Epoch 00040: val_loss did not improve from 1.32487\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6191 - val_loss: 2.1395\n",
      "Epoch 41/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5976\n",
      "Epoch 00041: val_loss did not improve from 1.32487\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5972 - val_loss: 1.4849\n",
      "Epoch 42/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.6279\n",
      "Epoch 00042: val_loss did not improve from 1.32487\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6275 - val_loss: 1.5090\n",
      "Epoch 43/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5913\n",
      "Epoch 00043: val_loss did not improve from 1.32487\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5912 - val_loss: 1.3566\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.5699\n",
      "Epoch 00044: val_loss improved from 1.32487 to 1.24390, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5701 - val_loss: 1.2439\n",
      "Epoch 45/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.5475\n",
      "Epoch 00045: val_loss improved from 1.24390 to 1.20989, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5474 - val_loss: 1.2099\n",
      "Epoch 46/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.5477\n",
      "Epoch 00046: val_loss did not improve from 1.20989\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5469 - val_loss: 1.2686\n",
      "Epoch 47/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5236- ETA: 1 - ETA: 0s - loss:\n",
      "Epoch 00047: val_loss did not improve from 1.20989\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5236 - val_loss: 1.3792\n",
      "Epoch 48/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.5095\n",
      "Epoch 00048: val_loss did not improve from 1.20989\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5096 - val_loss: 1.4563\n",
      "Epoch 49/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5133\n",
      "Epoch 00049: val_loss did not improve from 1.20989\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5134 - val_loss: 1.5132\n",
      "Epoch 50/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4726\n",
      "Epoch 00050: val_loss improved from 1.20989 to 1.19494, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4724 - val_loss: 1.1949\n",
      "Epoch 51/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.4691- ETA: 0s - loss: 1.468\n",
      "Epoch 00051: val_loss did not improve from 1.19494\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4696 - val_loss: 1.6824\n",
      "Epoch 52/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4609\n",
      "Epoch 00052: val_loss did not improve from 1.19494\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4606 - val_loss: 1.2805\n",
      "Epoch 53/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4748\n",
      "Epoch 00053: val_loss improved from 1.19494 to 1.02042, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4746 - val_loss: 1.0204\n",
      "Epoch 54/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.4349\n",
      "Epoch 00054: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4349 - val_loss: 1.8727\n",
      "Epoch 55/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.4397\n",
      "Epoch 00055: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4395 - val_loss: 1.2182\n",
      "Epoch 56/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3910\n",
      "Epoch 00056: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3909 - val_loss: 1.2942\n",
      "Epoch 57/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4025\n",
      "Epoch 00057: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4025 - val_loss: 1.3052\n",
      "Epoch 58/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.3994\n",
      "Epoch 00058: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3995 - val_loss: 1.6402\n",
      "Epoch 59/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3731\n",
      "Epoch 00059: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3731 - val_loss: 1.4266\n",
      "Epoch 60/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3722\n",
      "Epoch 00060: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3721 - val_loss: 1.2823\n",
      "Epoch 61/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3648- ETA: 0s -\n",
      "Epoch 00061: val_loss did not improve from 1.02042\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3650 - val_loss: 1.1336\n",
      "Epoch 62/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3477\n",
      "Epoch 00062: val_loss improved from 1.02042 to 1.00556, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3477 - val_loss: 1.0056\n",
      "Epoch 63/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.3411\n",
      "Epoch 00063: val_loss did not improve from 1.00556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3407 - val_loss: 1.0837\n",
      "Epoch 64/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3321\n",
      "Epoch 00064: val_loss did not improve from 1.00556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3320 - val_loss: 1.2236\n",
      "Epoch 65/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3387\n",
      "Epoch 00065: val_loss did not improve from 1.00556\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3384 - val_loss: 1.1950\n",
      "Epoch 66/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.3309\n",
      "Epoch 00066: val_loss did not improve from 1.00556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3306 - val_loss: 1.5660\n",
      "Epoch 67/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.2874\n",
      "Epoch 00067: val_loss improved from 1.00556 to 0.98157, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.2875 - val_loss: 0.9816\n",
      "Epoch 68/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3052\n",
      "Epoch 00068: val_loss did not improve from 0.98157\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3049 - val_loss: 1.1757\n",
      "Epoch 69/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3106\n",
      "Epoch 00069: val_loss did not improve from 0.98157\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3107 - val_loss: 1.0120\n",
      "Epoch 70/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3029\n",
      "Epoch 00070: val_loss improved from 0.98157 to 0.95778, saving model to DS02/experiment_set_10\\results_10\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3026 - val_loss: 0.9578\n",
      "Epoch 71/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.2476\n",
      "Epoch 00071: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2478 - val_loss: 1.5702\n",
      "Epoch 72/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2590\n",
      "Epoch 00072: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2592 - val_loss: 1.1520\n",
      "Epoch 73/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.2942\n",
      "Epoch 00073: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2942 - val_loss: 1.5994\n",
      "Epoch 74/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.2530\n",
      "Epoch 00074: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2534 - val_loss: 1.1305\n",
      "Epoch 75/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.2382\n",
      "Epoch 00075: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2382 - val_loss: 1.0043\n",
      "Epoch 76/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.2403\n",
      "Epoch 00076: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2405 - val_loss: 1.4253\n",
      "Epoch 77/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.2401\n",
      "Epoch 00077: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2401 - val_loss: 1.0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2333\n",
      "Epoch 00078: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2333 - val_loss: 1.1536\n",
      "Epoch 79/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.2225\n",
      "Epoch 00079: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2226 - val_loss: 1.4343\n",
      "Epoch 80/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.2215\n",
      "Epoch 00080: val_loss did not improve from 0.95778\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2217 - val_loss: 1.1446\n",
      "Epoch 00080: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_10\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.97\n",
      "RMSE: 0.99\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_10\\split_2\\scaler.pkl\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 233,089\n",
      "Trainable params: 233,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 135.0036\n",
      "Epoch 00001: val_loss improved from inf to 17.59315, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 134.7943 - val_loss: 17.5932\n",
      "Epoch 2/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 15.3564\n",
      "Epoch 00002: val_loss improved from 17.59315 to 13.33998, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 15.3531 - val_loss: 13.3400\n",
      "Epoch 3/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 10.8685\n",
      "Epoch 00003: val_loss improved from 13.33998 to 8.92531, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 10.8680 - val_loss: 8.9253\n",
      "Epoch 4/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 7.6995\n",
      "Epoch 00004: val_loss improved from 8.92531 to 8.85014, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.6995 - val_loss: 8.8501\n",
      "Epoch 5/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 6.2473\n",
      "Epoch 00005: val_loss improved from 8.85014 to 7.24824, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 6.2471 - val_loss: 7.2482\n",
      "Epoch 6/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 5.2916\n",
      "Epoch 00006: val_loss improved from 7.24824 to 4.90889, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.2919 - val_loss: 4.9089\n",
      "Epoch 7/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 4.7083\n",
      "Epoch 00007: val_loss improved from 4.90889 to 4.64816, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.7084 - val_loss: 4.6482\n",
      "Epoch 8/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 4.3305\n",
      "Epoch 00008: val_loss improved from 4.64816 to 4.64002, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.3321 - val_loss: 4.6400\n",
      "Epoch 9/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.9241\n",
      "Epoch 00009: val_loss improved from 4.64002 to 3.31519, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.9232 - val_loss: 3.3152\n",
      "Epoch 10/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.6692\n",
      "Epoch 00010: val_loss improved from 3.31519 to 3.27245, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.6688 - val_loss: 3.2724\n",
      "Epoch 11/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.4565\n",
      "Epoch 00011: val_loss improved from 3.27245 to 2.98117, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.4561 - val_loss: 2.9812\n",
      "Epoch 12/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.3024\n",
      "Epoch 00012: val_loss did not improve from 2.98117\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.3033 - val_loss: 4.8846\n",
      "Epoch 13/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 3.1925\n",
      "Epoch 00013: val_loss improved from 2.98117 to 2.70218, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.1916 - val_loss: 2.7022\n",
      "Epoch 14/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.9930\n",
      "Epoch 00014: val_loss did not improve from 2.70218\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9927 - val_loss: 3.2216\n",
      "Epoch 15/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.9482\n",
      "Epoch 00015: val_loss improved from 2.70218 to 2.34989, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9482 - val_loss: 2.3499\n",
      "Epoch 16/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.8334\n",
      "Epoch 00016: val_loss did not improve from 2.34989\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.8337 - val_loss: 2.8631\n",
      "Epoch 17/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.7342\n",
      "Epoch 00017: val_loss did not improve from 2.34989\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7342 - val_loss: 2.3988\n",
      "Epoch 18/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.6128\n",
      "Epoch 00018: val_loss did not improve from 2.34989\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6135 - val_loss: 3.6450\n",
      "Epoch 19/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.5861\n",
      "Epoch 00019: val_loss improved from 2.34989 to 2.29370, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5855 - val_loss: 2.2937\n",
      "Epoch 20/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.5017\n",
      "Epoch 00020: val_loss improved from 2.29370 to 2.09940, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.5012 - val_loss: 2.0994\n",
      "Epoch 21/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.4913\n",
      "Epoch 00021: val_loss did not improve from 2.09940\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.4913 - val_loss: 2.3406\n",
      "Epoch 22/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.3943\n",
      "Epoch 00022: val_loss did not improve from 2.09940\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3949 - val_loss: 2.8548\n",
      "Epoch 23/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.3014\n",
      "Epoch 00023: val_loss did not improve from 2.09940\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3014 - val_loss: 2.5285\n",
      "Epoch 24/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.3314\n",
      "Epoch 00024: val_loss did not improve from 2.09940\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3311 - val_loss: 2.8042\n",
      "Epoch 25/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.2423\n",
      "Epoch 00025: val_loss did not improve from 2.09940\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2421 - val_loss: 3.6623\n",
      "Epoch 26/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.1822\n",
      "Epoch 00026: val_loss improved from 2.09940 to 2.08798, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1821 - val_loss: 2.0880\n",
      "Epoch 27/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.1455\n",
      "Epoch 00027: val_loss did not improve from 2.08798\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1456 - val_loss: 2.9421\n",
      "Epoch 28/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.1310\n",
      "Epoch 00028: val_loss improved from 2.08798 to 1.85341, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1309 - val_loss: 1.8534\n",
      "Epoch 29/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.0827\n",
      "Epoch 00029: val_loss did not improve from 1.85341\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0825 - val_loss: 1.8640\n",
      "Epoch 30/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.0315\n",
      "Epoch 00030: val_loss did not improve from 1.85341\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0315 - val_loss: 2.1442\n",
      "Epoch 31/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.0695\n",
      "Epoch 00031: val_loss did not improve from 1.85341\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0698 - val_loss: 2.7897\n",
      "Epoch 32/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.9845\n",
      "Epoch 00032: val_loss improved from 1.85341 to 1.60213, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9845 - val_loss: 1.6021\n",
      "Epoch 33/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.9572\n",
      "Epoch 00033: val_loss did not improve from 1.60213\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9576 - val_loss: 1.9649\n",
      "Epoch 34/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.9393\n",
      "Epoch 00034: val_loss did not improve from 1.60213\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9390 - val_loss: 1.6092\n",
      "Epoch 35/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.8950\n",
      "Epoch 00035: val_loss improved from 1.60213 to 1.46886, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8955 - val_loss: 1.4689\n",
      "Epoch 36/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8806\n",
      "Epoch 00036: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8806 - val_loss: 2.2286\n",
      "Epoch 37/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.8628\n",
      "Epoch 00037: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8633 - val_loss: 1.7842\n",
      "Epoch 38/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.8548\n",
      "Epoch 00038: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8544 - val_loss: 1.6021\n",
      "Epoch 39/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8127\n",
      "Epoch 00039: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8127 - val_loss: 1.5486\n",
      "Epoch 40/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.7647\n",
      "Epoch 00040: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7645 - val_loss: 1.5471\n",
      "Epoch 41/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7977\n",
      "Epoch 00041: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7974 - val_loss: 1.6004\n",
      "Epoch 42/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.7406\n",
      "Epoch 00042: val_loss did not improve from 1.46886\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7403 - val_loss: 1.5543\n",
      "Epoch 43/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.7099\n",
      "Epoch 00043: val_loss improved from 1.46886 to 1.35836, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7087 - val_loss: 1.3584\n",
      "Epoch 44/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.7360- ETA: 0s - loss: 1.73\n",
      "Epoch 00044: val_loss did not improve from 1.35836\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7360 - val_loss: 1.4659\n",
      "Epoch 45/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.6631\n",
      "Epoch 00045: val_loss did not improve from 1.35836\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6637 - val_loss: 1.6904\n",
      "Epoch 46/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6889\n",
      "Epoch 00046: val_loss did not improve from 1.35836\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6890 - val_loss: 1.5707\n",
      "Epoch 47/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.6653\n",
      "Epoch 00047: val_loss did not improve from 1.35836\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6651 - val_loss: 1.6152\n",
      "Epoch 48/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.6208\n",
      "Epoch 00048: val_loss did not improve from 1.35836\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6207 - val_loss: 1.7722\n",
      "Epoch 49/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.6727\n",
      "Epoch 00049: val_loss improved from 1.35836 to 1.19196, saving model to DS02/experiment_set_10\\results_10\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6719 - val_loss: 1.1920\n",
      "Epoch 50/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.6050\n",
      "Epoch 00050: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6050 - val_loss: 1.9060\n",
      "Epoch 51/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.6027\n",
      "Epoch 00051: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6027 - val_loss: 1.3040\n",
      "Epoch 52/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5813\n",
      "Epoch 00052: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5811 - val_loss: 1.5066\n",
      "Epoch 53/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.5492\n",
      "Epoch 00053: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5492 - val_loss: 1.4400\n",
      "Epoch 54/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.5730\n",
      "Epoch 00054: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5731 - val_loss: 1.3676\n",
      "Epoch 55/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5665\n",
      "Epoch 00055: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5668 - val_loss: 3.4184\n",
      "Epoch 56/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5337\n",
      "Epoch 00056: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5330 - val_loss: 1.3139\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5671\n",
      "Epoch 00057: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5671 - val_loss: 2.6923\n",
      "Epoch 58/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.5215\n",
      "Epoch 00058: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5218 - val_loss: 1.5502\n",
      "Epoch 59/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.5174\n",
      "Epoch 00059: val_loss did not improve from 1.19196\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5176 - val_loss: 1.8423\n",
      "Epoch 00059: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_10\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.18\n",
      "RMSE: 1.09\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_15\\split_0\\scaler.pkl\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 256)               4096      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 234,369\n",
      "Trainable params: 234,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 126.7585\n",
      "Epoch 00001: val_loss improved from inf to 16.25046, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 126.7156 - val_loss: 16.2505\n",
      "Epoch 2/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 12.6309\n",
      "Epoch 00002: val_loss improved from 16.25046 to 9.91713, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 12.6287 - val_loss: 9.9171\n",
      "Epoch 3/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 7.6200\n",
      "Epoch 00003: val_loss improved from 9.91713 to 9.39286, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 7.6204 - val_loss: 9.3929\n",
      "Epoch 4/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 5.7450\n",
      "Epoch 00004: val_loss improved from 9.39286 to 4.81226, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.7439 - val_loss: 4.8123\n",
      "Epoch 5/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 4.8896\n",
      "Epoch 00005: val_loss improved from 4.81226 to 4.09244, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.8893 - val_loss: 4.0924\n",
      "Epoch 6/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 4.2546\n",
      "Epoch 00006: val_loss improved from 4.09244 to 3.54398, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.2542 - val_loss: 3.5440\n",
      "Epoch 7/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 3.8098\n",
      "Epoch 00007: val_loss improved from 3.54398 to 3.28786, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.8098 - val_loss: 3.2879\n",
      "Epoch 8/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.4687\n",
      "Epoch 00008: val_loss did not improve from 3.28786\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.4689 - val_loss: 3.4349\n",
      "Epoch 9/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 3.2384\n",
      "Epoch 00009: val_loss did not improve from 3.28786\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.2391 - val_loss: 3.5456\n",
      "Epoch 10/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 3.0161\n",
      "Epoch 00010: val_loss did not improve from 3.28786\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.0161 - val_loss: 4.6458\n",
      "Epoch 11/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.8597\n",
      "Epoch 00011: val_loss improved from 3.28786 to 2.26461, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.8588 - val_loss: 2.2646\n",
      "Epoch 12/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.7336\n",
      "Epoch 00012: val_loss improved from 2.26461 to 2.16831, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7336 - val_loss: 2.1683\n",
      "Epoch 13/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.6048\n",
      "Epoch 00013: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6044 - val_loss: 3.1080\n",
      "Epoch 14/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.4558\n",
      "Epoch 00014: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4558 - val_loss: 2.7865\n",
      "Epoch 15/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.3662\n",
      "Epoch 00015: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3663 - val_loss: 3.2704\n",
      "Epoch 16/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.2999\n",
      "Epoch 00016: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3001 - val_loss: 2.5444\n",
      "Epoch 17/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.2188\n",
      "Epoch 00017: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2187 - val_loss: 2.6509\n",
      "Epoch 18/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.1672\n",
      "Epoch 00018: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1673 - val_loss: 2.4563\n",
      "Epoch 19/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.0694\n",
      "Epoch 00019: val_loss did not improve from 2.16831\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0701 - val_loss: 2.6664\n",
      "Epoch 20/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.0346\n",
      "Epoch 00020: val_loss improved from 2.16831 to 1.90136, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0346 - val_loss: 1.9014\n",
      "Epoch 21/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.0171\n",
      "Epoch 00021: val_loss did not improve from 1.90136\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0172 - val_loss: 1.9471\n",
      "Epoch 22/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.9597\n",
      "Epoch 00022: val_loss did not improve from 1.90136\n",
      "6477/6477 [==============================] - 31s 5ms/step - loss: 1.9597 - val_loss: 1.9156\n",
      "Epoch 23/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.8937\n",
      "Epoch 00023: val_loss did not improve from 1.90136\n",
      "6477/6477 [==============================] - 32s 5ms/step - loss: 1.8937 - val_loss: 1.9115\n",
      "Epoch 24/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8355\n",
      "Epoch 00024: val_loss improved from 1.90136 to 1.52975, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8354 - val_loss: 1.5297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.7886\n",
      "Epoch 00025: val_loss improved from 1.52975 to 1.50889, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7884 - val_loss: 1.5089\n",
      "Epoch 26/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.7914- ETA: 0s -\n",
      "Epoch 00026: val_loss did not improve from 1.50889\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7915 - val_loss: 1.6762\n",
      "Epoch 27/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.7365\n",
      "Epoch 00027: val_loss did not improve from 1.50889\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7367 - val_loss: 1.8740\n",
      "Epoch 28/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.7443\n",
      "Epoch 00028: val_loss did not improve from 1.50889\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7447 - val_loss: 1.6499\n",
      "Epoch 29/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.6944\n",
      "Epoch 00029: val_loss did not improve from 1.50889\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6945 - val_loss: 2.0453\n",
      "Epoch 30/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.6778\n",
      "Epoch 00030: val_loss did not improve from 1.50889\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6778 - val_loss: 1.5351\n",
      "Epoch 31/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6430\n",
      "Epoch 00031: val_loss improved from 1.50889 to 1.48158, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6431 - val_loss: 1.4816\n",
      "Epoch 32/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.5830\n",
      "Epoch 00032: val_loss improved from 1.48158 to 1.38461, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5829 - val_loss: 1.3846\n",
      "Epoch 33/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.5797\n",
      "Epoch 00033: val_loss improved from 1.38461 to 1.29060, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5792 - val_loss: 1.2906\n",
      "Epoch 34/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.5651\n",
      "Epoch 00034: val_loss did not improve from 1.29060\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5651 - val_loss: 1.6949\n",
      "Epoch 35/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5563\n",
      "Epoch 00035: val_loss improved from 1.29060 to 1.23459, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5555 - val_loss: 1.2346\n",
      "Epoch 36/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.5450\n",
      "Epoch 00036: val_loss did not improve from 1.23459\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5450 - val_loss: 1.5971\n",
      "Epoch 37/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.5186\n",
      "Epoch 00037: val_loss did not improve from 1.23459\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5190 - val_loss: 1.4130\n",
      "Epoch 38/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5045\n",
      "Epoch 00038: val_loss did not improve from 1.23459\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5047 - val_loss: 1.4392\n",
      "Epoch 39/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.4798\n",
      "Epoch 00039: val_loss did not improve from 1.23459\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4796 - val_loss: 1.4749\n",
      "Epoch 40/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.4667\n",
      "Epoch 00040: val_loss improved from 1.23459 to 1.19990, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4667 - val_loss: 1.1999\n",
      "Epoch 41/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4500\n",
      "Epoch 00041: val_loss did not improve from 1.19990\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4501 - val_loss: 1.4266\n",
      "Epoch 42/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.4620\n",
      "Epoch 00042: val_loss did not improve from 1.19990\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4626 - val_loss: 2.4419\n",
      "Epoch 43/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.4021\n",
      "Epoch 00043: val_loss did not improve from 1.19990\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4031 - val_loss: 1.5322\n",
      "Epoch 44/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4156\n",
      "Epoch 00044: val_loss did not improve from 1.19990\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4156 - val_loss: 1.2939\n",
      "Epoch 45/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.3861\n",
      "Epoch 00045: val_loss improved from 1.19990 to 1.08721, saving model to DS02/experiment_set_10\\results_15\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.3861 - val_loss: 1.0872\n",
      "Epoch 46/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.3896\n",
      "Epoch 00046: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3895 - val_loss: 1.2469\n",
      "Epoch 47/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.3578- ETA: 0\n",
      "Epoch 00047: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3580 - val_loss: 1.2660\n",
      "Epoch 48/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3560\n",
      "Epoch 00048: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3560 - val_loss: 1.2562\n",
      "Epoch 49/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.3358\n",
      "Epoch 00049: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3361 - val_loss: 1.6252\n",
      "Epoch 50/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3316\n",
      "Epoch 00050: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3315 - val_loss: 1.1252\n",
      "Epoch 51/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3152\n",
      "Epoch 00051: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3152 - val_loss: 1.2449\n",
      "Epoch 52/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.3076- ETA: 0s - loss: 1\n",
      "Epoch 00052: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3074 - val_loss: 1.3841\n",
      "Epoch 53/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.2899\n",
      "Epoch 00053: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2902 - val_loss: 1.2269\n",
      "Epoch 54/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.3029\n",
      "Epoch 00054: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3038 - val_loss: 1.3887\n",
      "Epoch 55/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.2648\n",
      "Epoch 00055: val_loss did not improve from 1.08721\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.2648 - val_loss: 1.5937\n",
      "Epoch 00055: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_15\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.09\n",
      "RMSE: 1.04\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_15\\split_1\\scaler.pkl\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 256)               4096      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 234,369\n",
      "Trainable params: 234,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 130.9978- ETA: 0s\n",
      "Epoch 00001: val_loss improved from inf to 16.88487, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 130.9359 - val_loss: 16.8849\n",
      "Epoch 2/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 13.3009\n",
      "Epoch 00002: val_loss improved from 16.88487 to 8.67516, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 13.2996 - val_loss: 8.6752\n",
      "Epoch 3/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 7.5009\n",
      "Epoch 00003: val_loss improved from 8.67516 to 5.69988, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.5002 - val_loss: 5.6999\n",
      "Epoch 4/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 5.5760- ETA: 0s - loss: 5.\n",
      "Epoch 00004: val_loss did not improve from 5.69988\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.5761 - val_loss: 6.8726\n",
      "Epoch 5/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 4.5956\n",
      "Epoch 00005: val_loss improved from 5.69988 to 4.05176, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.5960 - val_loss: 4.0518\n",
      "Epoch 6/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 4.0438\n",
      "Epoch 00006: val_loss improved from 4.05176 to 3.20213, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.0432 - val_loss: 3.2021\n",
      "Epoch 7/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 3.6803\n",
      "Epoch 00007: val_loss did not improve from 3.20213\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.6803 - val_loss: 3.5905\n",
      "Epoch 8/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.3655\n",
      "Epoch 00008: val_loss did not improve from 3.20213\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3655 - val_loss: 3.9333\n",
      "Epoch 9/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 3.1181\n",
      "Epoch 00009: val_loss improved from 3.20213 to 2.79940, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.1181 - val_loss: 2.7994\n",
      "Epoch 10/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.9893\n",
      "Epoch 00010: val_loss improved from 2.79940 to 2.41417, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9894 - val_loss: 2.4142\n",
      "Epoch 11/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.7575\n",
      "Epoch 00011: val_loss improved from 2.41417 to 2.34263, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7572 - val_loss: 2.3426\n",
      "Epoch 12/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.6658\n",
      "Epoch 00012: val_loss did not improve from 2.34263\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6656 - val_loss: 2.6913\n",
      "Epoch 13/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.5464- ETA: \n",
      "Epoch 00013: val_loss did not improve from 2.34263\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5465 - val_loss: 2.5321\n",
      "Epoch 14/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.5220\n",
      "Epoch 00014: val_loss improved from 2.34263 to 2.05649, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.5216 - val_loss: 2.0565\n",
      "Epoch 15/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.3654\n",
      "Epoch 00015: val_loss did not improve from 2.05649\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3656 - val_loss: 2.4645\n",
      "Epoch 16/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.2563\n",
      "Epoch 00016: val_loss did not improve from 2.05649\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2558 - val_loss: 2.2641\n",
      "Epoch 17/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.2213\n",
      "Epoch 00017: val_loss did not improve from 2.05649\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2219 - val_loss: 2.2583\n",
      "Epoch 18/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.1395\n",
      "Epoch 00018: val_loss improved from 2.05649 to 2.02655, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1396 - val_loss: 2.0265\n",
      "Epoch 19/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.0798\n",
      "Epoch 00019: val_loss did not improve from 2.02655\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0797 - val_loss: 2.3033\n",
      "Epoch 20/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.0039\n",
      "Epoch 00020: val_loss improved from 2.02655 to 1.57855, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.0042 - val_loss: 1.5785\n",
      "Epoch 21/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.9873\n",
      "Epoch 00021: val_loss did not improve from 1.57855\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9873 - val_loss: 1.7887\n",
      "Epoch 22/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.9004- E\n",
      "Epoch 00022: val_loss did not improve from 1.57855\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9004 - val_loss: 2.3786\n",
      "Epoch 23/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.8675\n",
      "Epoch 00023: val_loss improved from 1.57855 to 1.44154, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8666 - val_loss: 1.4415\n",
      "Epoch 24/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8484\n",
      "Epoch 00024: val_loss improved from 1.44154 to 1.43239, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8479 - val_loss: 1.4324\n",
      "Epoch 25/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.8069\n",
      "Epoch 00025: val_loss did not improve from 1.43239\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8067 - val_loss: 1.6359\n",
      "Epoch 26/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.7692\n",
      "Epoch 00026: val_loss improved from 1.43239 to 1.34836, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7685 - val_loss: 1.3484\n",
      "Epoch 27/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.7740- ETA: 0s - lo\n",
      "Epoch 00027: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7740 - val_loss: 1.8582\n",
      "Epoch 28/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.6798\n",
      "Epoch 00028: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6800 - val_loss: 2.6762\n",
      "Epoch 29/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.6858\n",
      "Epoch 00029: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6858 - val_loss: 1.8664\n",
      "Epoch 30/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.6289\n",
      "Epoch 00030: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6292 - val_loss: 1.7517\n",
      "Epoch 31/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.6449\n",
      "Epoch 00031: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 24s 4ms/step - loss: 1.6447 - val_loss: 1.4167\n",
      "Epoch 32/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6284\n",
      "Epoch 00032: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6284 - val_loss: 1.3864\n",
      "Epoch 33/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5858- ETA: 0s - loss\n",
      "Epoch 00033: val_loss did not improve from 1.34836\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5854 - val_loss: 1.4942\n",
      "Epoch 34/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.5520\n",
      "Epoch 00034: val_loss improved from 1.34836 to 1.31391, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5517 - val_loss: 1.3139\n",
      "Epoch 35/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.5296\n",
      "Epoch 00035: val_loss did not improve from 1.31391\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5299 - val_loss: 2.4987\n",
      "Epoch 36/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5393\n",
      "Epoch 00036: val_loss did not improve from 1.31391\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5393 - val_loss: 1.3886\n",
      "Epoch 37/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5624\n",
      "Epoch 00037: val_loss improved from 1.31391 to 1.21460, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5621 - val_loss: 1.2146\n",
      "Epoch 38/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.4689\n",
      "Epoch 00038: val_loss did not improve from 1.21460\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4710 - val_loss: 2.9410\n",
      "Epoch 39/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.4525\n",
      "Epoch 00039: val_loss improved from 1.21460 to 1.06929, saving model to DS02/experiment_set_10\\results_15\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4520 - val_loss: 1.0693\n",
      "Epoch 40/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.4604\n",
      "Epoch 00040: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4604 - val_loss: 1.5084\n",
      "Epoch 41/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4477\n",
      "Epoch 00041: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4474 - val_loss: 1.3935\n",
      "Epoch 42/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.4395\n",
      "Epoch 00042: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4394 - val_loss: 1.5292\n",
      "Epoch 43/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4031- ETA: 3s - loss: 1. - ETA: 3s - ETA: 2s - loss: 1.4\n",
      "Epoch 00043: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4035 - val_loss: 1.3141\n",
      "Epoch 44/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.4102\n",
      "Epoch 00044: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4101 - val_loss: 1.0835\n",
      "Epoch 45/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.4087\n",
      "Epoch 00045: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4083 - val_loss: 1.1436\n",
      "Epoch 46/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.3892\n",
      "Epoch 00046: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.3892 - val_loss: 1.3493\n",
      "Epoch 47/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3659\n",
      "Epoch 00047: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3659 - val_loss: 1.3347\n",
      "Epoch 48/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3418\n",
      "Epoch 00048: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3415 - val_loss: 1.1354\n",
      "Epoch 49/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3501\n",
      "Epoch 00049: val_loss did not improve from 1.06929\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3502 - val_loss: 1.1598\n",
      "Epoch 00049: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_15\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.08\n",
      "RMSE: 1.04\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_15\\split_2\\scaler.pkl\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 256)               4096      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 234,369\n",
      "Trainable params: 234,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 125.7796\n",
      "Epoch 00001: val_loss improved from inf to 16.24569, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 125.6012 - val_loss: 16.2457\n",
      "Epoch 2/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 12.3101\n",
      "Epoch 00002: val_loss improved from 16.24569 to 8.73530, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 12.3096 - val_loss: 8.7353\n",
      "Epoch 3/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 7.1729\n",
      "Epoch 00003: val_loss improved from 8.73530 to 6.06590, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 7.1718 - val_loss: 6.0659\n",
      "Epoch 4/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 5.4562- E\n",
      "Epoch 00004: val_loss improved from 6.06590 to 4.20516, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.4557 - val_loss: 4.2052\n",
      "Epoch 5/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 4.6366\n",
      "Epoch 00005: val_loss improved from 4.20516 to 3.77042, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.6362 - val_loss: 3.7704\n",
      "Epoch 6/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 4.0948- ETA: 0s - loss:\n",
      "Epoch 00006: val_loss improved from 3.77042 to 3.39115, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.0938 - val_loss: 3.3911\n",
      "Epoch 7/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.7476- ETA: 0s - loss: 3.747\n",
      "Epoch 00007: val_loss did not improve from 3.39115\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.7476 - val_loss: 3.5039\n",
      "Epoch 8/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.4214\n",
      "Epoch 00008: val_loss did not improve from 3.39115\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.4235 - val_loss: 3.7811\n",
      "Epoch 9/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.2483- ETA: 1s - loss: 3. - ETA: 1s -  - ETA: 0\n",
      "Epoch 00009: val_loss did not improve from 3.39115\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 3.2483 - val_loss: 3.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.0376\n",
      "Epoch 00010: val_loss did not improve from 3.39115\n",
      "6477/6477 [==============================] - 30s 5ms/step - loss: 3.0381 - val_loss: 4.9702\n",
      "Epoch 11/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.9038\n",
      "Epoch 00011: val_loss improved from 3.39115 to 2.87954, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 2.9041 - val_loss: 2.8795\n",
      "Epoch 12/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.7573\n",
      "Epoch 00012: val_loss improved from 2.87954 to 2.47545, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.7573 - val_loss: 2.4755\n",
      "Epoch 13/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.6170\n",
      "Epoch 00013: val_loss improved from 2.47545 to 2.20045, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.6166 - val_loss: 2.2004\n",
      "Epoch 14/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.5163\n",
      "Epoch 00014: val_loss did not improve from 2.20045\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.5165 - val_loss: 3.2249\n",
      "Epoch 15/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.4101\n",
      "Epoch 00015: val_loss improved from 2.20045 to 1.98959, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4100 - val_loss: 1.9896\n",
      "Epoch 16/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 2.3147\n",
      "Epoch 00016: val_loss did not improve from 1.98959\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3145 - val_loss: 2.4699\n",
      "Epoch 17/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.2943\n",
      "Epoch 00017: val_loss did not improve from 1.98959\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.2945 - val_loss: 2.0776\n",
      "Epoch 18/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.2196\n",
      "Epoch 00018: val_loss did not improve from 1.98959\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2209 - val_loss: 2.8818\n",
      "Epoch 19/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.1221\n",
      "Epoch 00019: val_loss did not improve from 1.98959\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1221 - val_loss: 2.4808\n",
      "Epoch 20/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.0570\n",
      "Epoch 00020: val_loss did not improve from 1.98959\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0571 - val_loss: 2.3408\n",
      "Epoch 21/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.0243\n",
      "Epoch 00021: val_loss improved from 1.98959 to 1.71595, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.0242 - val_loss: 1.7159\n",
      "Epoch 22/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.9555\n",
      "Epoch 00022: val_loss did not improve from 1.71595\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9551 - val_loss: 1.8894\n",
      "Epoch 23/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.9045\n",
      "Epoch 00023: val_loss improved from 1.71595 to 1.62587, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.9050 - val_loss: 1.6259\n",
      "Epoch 24/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.8389\n",
      "Epoch 00024: val_loss improved from 1.62587 to 1.39984, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8390 - val_loss: 1.3998\n",
      "Epoch 25/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.8502\n",
      "Epoch 00025: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8502 - val_loss: 1.8255\n",
      "Epoch 26/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.8473\n",
      "Epoch 00026: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8467 - val_loss: 1.5058\n",
      "Epoch 27/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7918- ETA: 0s - los\n",
      "Epoch 00027: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7922 - val_loss: 2.4874\n",
      "Epoch 28/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7352\n",
      "Epoch 00028: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7349 - val_loss: 1.5905\n",
      "Epoch 29/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7162- ETA: 0s - loss: 1.71\n",
      "Epoch 00029: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7166 - val_loss: 1.8764\n",
      "Epoch 30/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.6850\n",
      "Epoch 00030: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6853 - val_loss: 1.8488\n",
      "Epoch 31/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.6292\n",
      "Epoch 00031: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6293 - val_loss: 2.1631\n",
      "Epoch 32/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.5958\n",
      "Epoch 00032: val_loss did not improve from 1.39984\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5952 - val_loss: 2.0094\n",
      "Epoch 33/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.5585\n",
      "Epoch 00033: val_loss improved from 1.39984 to 1.34180, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5585 - val_loss: 1.3418\n",
      "Epoch 34/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.5910\n",
      "Epoch 00034: val_loss did not improve from 1.34180\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5927 - val_loss: 2.6956\n",
      "Epoch 35/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.5058\n",
      "Epoch 00035: val_loss did not improve from 1.34180\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5055 - val_loss: 1.5482\n",
      "Epoch 36/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5605- E - ETA: 2s - ETA: 1 - ETA: 0s - los\n",
      "Epoch 00036: val_loss improved from 1.34180 to 1.31359, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5601 - val_loss: 1.3136\n",
      "Epoch 37/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.5445\n",
      "Epoch 00037: val_loss did not improve from 1.31359\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5442 - val_loss: 1.4000\n",
      "Epoch 38/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.4832- -  - ETA: 3s - loss: -  - ETA: 0s - lo\n",
      "Epoch 00038: val_loss did not improve from 1.31359\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4830 - val_loss: 1.3174\n",
      "Epoch 39/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4638\n",
      "Epoch 00039: val_loss improved from 1.31359 to 1.24172, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4638 - val_loss: 1.2417\n",
      "Epoch 40/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.4391\n",
      "Epoch 00040: val_loss improved from 1.24172 to 1.23691, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4391 - val_loss: 1.2369\n",
      "Epoch 41/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.4437\n",
      "Epoch 00041: val_loss improved from 1.23691 to 1.15735, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.4430 - val_loss: 1.1574\n",
      "Epoch 42/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.4295\n",
      "Epoch 00042: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4293 - val_loss: 1.3949\n",
      "Epoch 43/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.4455\n",
      "Epoch 00043: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4450 - val_loss: 1.2266\n",
      "Epoch 44/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.3944\n",
      "Epoch 00044: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3960 - val_loss: 1.8871\n",
      "Epoch 45/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3971\n",
      "Epoch 00045: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3969 - val_loss: 1.1646\n",
      "Epoch 46/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.3829\n",
      "Epoch 00046: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3832 - val_loss: 1.4144\n",
      "Epoch 47/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3445\n",
      "Epoch 00047: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3445 - val_loss: 1.3440\n",
      "Epoch 48/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3677\n",
      "Epoch 00048: val_loss did not improve from 1.15735\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3676 - val_loss: 1.1645\n",
      "Epoch 49/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3307- ETA: 2s - loss:  - ET\n",
      "Epoch 00049: val_loss improved from 1.15735 to 1.01280, saving model to DS02/experiment_set_10\\results_15\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3303 - val_loss: 1.0128\n",
      "Epoch 50/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.3782- ETA: 0s - loss: \n",
      "Epoch 00050: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3784 - val_loss: 1.2553\n",
      "Epoch 51/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3523\n",
      "Epoch 00051: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3521 - val_loss: 1.2122\n",
      "Epoch 52/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3095\n",
      "Epoch 00052: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3091 - val_loss: 1.1263\n",
      "Epoch 53/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.3374\n",
      "Epoch 00053: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3373 - val_loss: 1.1852\n",
      "Epoch 54/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3067\n",
      "Epoch 00054: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3065 - val_loss: 1.4669\n",
      "Epoch 55/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.2887\n",
      "Epoch 00055: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2898 - val_loss: 1.8993\n",
      "Epoch 56/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.2938- ETA: 0s - loss:\n",
      "Epoch 00056: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2932 - val_loss: 1.0710\n",
      "Epoch 57/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.2699\n",
      "Epoch 00057: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2696 - val_loss: 1.3051\n",
      "Epoch 58/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.2352\n",
      "Epoch 00058: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2352 - val_loss: 1.0954\n",
      "Epoch 59/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.2387- ETA: 0s - \n",
      "Epoch 00059: val_loss did not improve from 1.01280\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.2389 - val_loss: 2.6426\n",
      "Epoch 00059: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_15\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.01\n",
      "RMSE: 1.01\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_20\\split_0\\scaler.pkl\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 235,649\n",
      "Trainable params: 235,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 119.7162\n",
      "Epoch 00001: val_loss improved from inf to 16.62469, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 119.6758 - val_loss: 16.6247\n",
      "Epoch 2/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 12.0704\n",
      "Epoch 00002: val_loss improved from 16.62469 to 9.37304, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 12.0634 - val_loss: 9.3730\n",
      "Epoch 3/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 6.9219\n",
      "Epoch 00003: val_loss improved from 9.37304 to 8.06014, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 6.9207 - val_loss: 8.0601\n",
      "Epoch 4/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 5.4213\n",
      "Epoch 00004: val_loss improved from 8.06014 to 4.26821, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.4208 - val_loss: 4.2682\n",
      "Epoch 5/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 4.6311\n",
      "Epoch 00005: val_loss improved from 4.26821 to 3.68865, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.6300 - val_loss: 3.6887\n",
      "Epoch 6/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 4.0786\n",
      "Epoch 00006: val_loss did not improve from 3.68865\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.0784 - val_loss: 3.9041\n",
      "Epoch 7/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.7469\n",
      "Epoch 00007: val_loss improved from 3.68865 to 2.93415, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.7460 - val_loss: 2.9341\n",
      "Epoch 8/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 3.4856\n",
      "Epoch 00008: val_loss did not improve from 2.93415\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.4871 - val_loss: 3.6337\n",
      "Epoch 9/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.2731\n",
      "Epoch 00009: val_loss did not improve from 2.93415\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.2742 - val_loss: 4.3174\n",
      "Epoch 10/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.0099\n",
      "Epoch 00010: val_loss did not improve from 2.93415\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.0099 - val_loss: 3.4359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.9371\n",
      "Epoch 00011: val_loss improved from 2.93415 to 2.28668, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9364 - val_loss: 2.2867\n",
      "Epoch 12/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.7813\n",
      "Epoch 00012: val_loss did not improve from 2.28668\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7813 - val_loss: 2.3777\n",
      "Epoch 13/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.6721- ETA: 0s - loss: 2.672\n",
      "Epoch 00013: val_loss improved from 2.28668 to 2.17527, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6721 - val_loss: 2.1753\n",
      "Epoch 14/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.4815\n",
      "Epoch 00014: val_loss improved from 2.17527 to 2.06495, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4812 - val_loss: 2.0650\n",
      "Epoch 15/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.5082\n",
      "Epoch 00015: val_loss did not improve from 2.06495\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5081 - val_loss: 3.5737\n",
      "Epoch 16/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.3839\n",
      "Epoch 00016: val_loss did not improve from 2.06495\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3837 - val_loss: 2.3873\n",
      "Epoch 17/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.3094- ETA: 1s - loss:  - ETA: 1s - ETA: 0s - loss\n",
      "Epoch 00017: val_loss improved from 2.06495 to 1.84133, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3092 - val_loss: 1.8413\n",
      "Epoch 18/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.2562\n",
      "Epoch 00018: val_loss did not improve from 1.84133\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2551 - val_loss: 1.9317\n",
      "Epoch 19/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.1900\n",
      "Epoch 00019: val_loss did not improve from 1.84133\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1899 - val_loss: 2.1186\n",
      "Epoch 20/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.1178\n",
      "Epoch 00020: val_loss improved from 1.84133 to 1.69626, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1173 - val_loss: 1.6963\n",
      "Epoch 21/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.1077\n",
      "Epoch 00021: val_loss did not improve from 1.69626\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1077 - val_loss: 1.9817\n",
      "Epoch 22/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.0716\n",
      "Epoch 00022: val_loss did not improve from 1.69626\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0710 - val_loss: 1.7433\n",
      "Epoch 23/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.9925\n",
      "Epoch 00023: val_loss did not improve from 1.69626\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9921 - val_loss: 1.8143\n",
      "Epoch 24/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.9174- ETA: 1s - l\n",
      "Epoch 00024: val_loss did not improve from 1.69626\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9170 - val_loss: 1.9078\n",
      "Epoch 25/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.9246\n",
      "Epoch 00025: val_loss improved from 1.69626 to 1.49853, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9241 - val_loss: 1.4985\n",
      "Epoch 26/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.8450\n",
      "Epoch 00026: val_loss improved from 1.49853 to 1.27517, saving model to DS02/experiment_set_10\\results_20\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8440 - val_loss: 1.2752\n",
      "Epoch 27/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8393\n",
      "Epoch 00027: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8397 - val_loss: 1.6177\n",
      "Epoch 28/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.8232\n",
      "Epoch 00028: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8230 - val_loss: 2.0070\n",
      "Epoch 29/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.7723- ETA: \n",
      "Epoch 00029: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7722 - val_loss: 1.9851\n",
      "Epoch 30/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.7466\n",
      "Epoch 00030: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7466 - val_loss: 1.6360\n",
      "Epoch 31/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7749- ETA: 2s  - ETA: 0s - \n",
      "Epoch 00031: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7754 - val_loss: 2.2636\n",
      "Epoch 32/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7322\n",
      "Epoch 00032: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7319 - val_loss: 1.4773\n",
      "Epoch 33/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.6687- ETA: 0s - loss: 1.669\n",
      "Epoch 00033: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6687 - val_loss: 1.3005\n",
      "Epoch 34/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.6600\n",
      "Epoch 00034: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6600 - val_loss: 1.2979\n",
      "Epoch 35/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.6383\n",
      "Epoch 00035: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6379 - val_loss: 1.3967\n",
      "Epoch 36/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6543- ETA: 2s - loss\n",
      "Epoch 00036: val_loss did not improve from 1.27517\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6542 - val_loss: 2.2169\n",
      "Epoch 00036: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_20\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.30\n",
      "RMSE: 1.14\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_20\\split_1\\scaler.pkl\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 235,649\n",
      "Trainable params: 235,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 122.7161- ET\n",
      "Epoch 00001: val_loss improved from inf to 16.62729, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 122.6417 - val_loss: 16.6273\n",
      "Epoch 2/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 12.9891\n",
      "Epoch 00002: val_loss improved from 16.62729 to 9.73336, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 12.9890 - val_loss: 9.7334\n",
      "Epoch 3/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 7.7743- \n",
      "Epoch 00003: val_loss improved from 9.73336 to 7.53155, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.7723 - val_loss: 7.5316\n",
      "Epoch 4/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 5.8091\n",
      "Epoch 00004: val_loss improved from 7.53155 to 4.63354, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.8082 - val_loss: 4.6335\n",
      "Epoch 5/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 4.8663\n",
      "Epoch 00005: val_loss did not improve from 4.63354\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.8684 - val_loss: 6.0029\n",
      "Epoch 6/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 4.2983- ETA: 0s - loss: 4.3 - ETA: 0s\n",
      "Epoch 00006: val_loss improved from 4.63354 to 3.78130, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.2982 - val_loss: 3.7813\n",
      "Epoch 7/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.9286\n",
      "Epoch 00007: val_loss improved from 3.78130 to 2.93341, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.9281 - val_loss: 2.9334\n",
      "Epoch 8/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.5969\n",
      "Epoch 00008: val_loss did not improve from 2.93341\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.5966 - val_loss: 3.4015\n",
      "Epoch 9/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.3532\n",
      "Epoch 00009: val_loss did not improve from 2.93341\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.3536 - val_loss: 4.4685\n",
      "Epoch 10/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.0690\n",
      "Epoch 00010: val_loss improved from 2.93341 to 2.55083, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.0687 - val_loss: 2.5508\n",
      "Epoch 11/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.8990\n",
      "Epoch 00011: val_loss improved from 2.55083 to 2.38436, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.8989 - val_loss: 2.3844\n",
      "Epoch 12/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.8311\n",
      "Epoch 00012: val_loss did not improve from 2.38436\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.8306 - val_loss: 2.3978\n",
      "Epoch 13/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.6573-  \n",
      "Epoch 00013: val_loss improved from 2.38436 to 2.34529, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.6571 - val_loss: 2.3453\n",
      "Epoch 14/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 2.6133- ETA: \n",
      "Epoch 00014: val_loss did not improve from 2.34529\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6131 - val_loss: 3.2945\n",
      "Epoch 15/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.4693- ETA: 0s - loss\n",
      "Epoch 00015: val_loss improved from 2.34529 to 1.96882, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4691 - val_loss: 1.9688\n",
      "Epoch 16/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.4244\n",
      "Epoch 00016: val_loss did not improve from 1.96882\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4245 - val_loss: 2.0001\n",
      "Epoch 17/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.3396- ETA: 0s - loss: 2.3\n",
      "Epoch 00017: val_loss did not improve from 1.96882\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3396 - val_loss: 2.8836\n",
      "Epoch 18/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.3183\n",
      "Epoch 00018: val_loss did not improve from 1.96882\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3177 - val_loss: 2.1137\n",
      "Epoch 19/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.2020\n",
      "Epoch 00019: val_loss improved from 1.96882 to 1.91701, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2017 - val_loss: 1.9170\n",
      "Epoch 20/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.1315- ETA: 0s \n",
      "Epoch 00020: val_loss did not improve from 1.91701\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1316 - val_loss: 2.2217\n",
      "Epoch 21/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.1240\n",
      "Epoch 00021: val_loss improved from 1.91701 to 1.64017, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1231 - val_loss: 1.6402\n",
      "Epoch 22/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.0735\n",
      "Epoch 00022: val_loss did not improve from 1.64017\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0728 - val_loss: 1.7731\n",
      "Epoch 23/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.0105\n",
      "Epoch 00023: val_loss did not improve from 1.64017\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0103 - val_loss: 1.6516\n",
      "Epoch 24/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.9258\n",
      "Epoch 00024: val_loss did not improve from 1.64017\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9254 - val_loss: 1.6418\n",
      "Epoch 25/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.9513\n",
      "Epoch 00025: val_loss improved from 1.64017 to 1.54690, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9509 - val_loss: 1.5469\n",
      "Epoch 26/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.8748\n",
      "Epoch 00026: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.8745 - val_loss: 2.0432\n",
      "Epoch 27/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8455\n",
      "Epoch 00027: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8457 - val_loss: 1.5753\n",
      "Epoch 28/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.8511- ET\n",
      "Epoch 00028: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8513 - val_loss: 2.7064\n",
      "Epoch 29/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.7815\n",
      "Epoch 00029: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7810 - val_loss: 1.7974\n",
      "Epoch 30/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.7614\n",
      "Epoch 00030: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7615 - val_loss: 2.2124\n",
      "Epoch 31/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.7391\n",
      "Epoch 00031: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7391 - val_loss: 1.6048\n",
      "Epoch 32/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.7210\n",
      "Epoch 00032: val_loss did not improve from 1.54690\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7209 - val_loss: 2.2102\n",
      "Epoch 33/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.6970\n",
      "Epoch 00033: val_loss improved from 1.54690 to 1.38339, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6966 - val_loss: 1.3834\n",
      "Epoch 34/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.6652\n",
      "Epoch 00034: val_loss did not improve from 1.38339\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6649 - val_loss: 1.4658\n",
      "Epoch 35/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.6715\n",
      "Epoch 00035: val_loss did not improve from 1.38339\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6717 - val_loss: 1.6189\n",
      "Epoch 36/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.6257\n",
      "Epoch 00036: val_loss improved from 1.38339 to 1.32968, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6256 - val_loss: 1.3297\n",
      "Epoch 37/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.6487\n",
      "Epoch 00037: val_loss improved from 1.32968 to 1.29815, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.6478 - val_loss: 1.2982\n",
      "Epoch 38/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.6033\n",
      "Epoch 00038: val_loss did not improve from 1.29815\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6029 - val_loss: 1.5477\n",
      "Epoch 39/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.6022\n",
      "Epoch 00039: val_loss did not improve from 1.29815\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6028 - val_loss: 1.7112\n",
      "Epoch 40/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.5729- ET\n",
      "Epoch 00040: val_loss did not improve from 1.29815\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5728 - val_loss: 1.4109\n",
      "Epoch 41/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.5771\n",
      "Epoch 00041: val_loss did not improve from 1.29815\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5767 - val_loss: 1.6074\n",
      "Epoch 42/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.5505-\n",
      "Epoch 00042: val_loss did not improve from 1.29815\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5502 - val_loss: 1.4254\n",
      "Epoch 43/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.5193\n",
      "Epoch 00043: val_loss did not improve from 1.29815\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5191 - val_loss: 1.6802\n",
      "Epoch 44/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5242- - ETA: 3s  - ETA: 2s - lo - ET\n",
      "Epoch 00044: val_loss improved from 1.29815 to 1.26714, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.5243 - val_loss: 1.2671\n",
      "Epoch 45/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.4987\n",
      "Epoch 00045: val_loss improved from 1.26714 to 1.20471, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4986 - val_loss: 1.2047\n",
      "Epoch 46/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5068\n",
      "Epoch 00046: val_loss did not improve from 1.20471\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5068 - val_loss: 1.7008\n",
      "Epoch 47/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.4815- ETA: 1s - - ETA: 1s - loss: 1.479 - ET\n",
      "Epoch 00047: val_loss did not improve from 1.20471\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4820 - val_loss: 1.7334\n",
      "Epoch 48/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.4686\n",
      "Epoch 00048: val_loss did not improve from 1.20471\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4694 - val_loss: 2.4933\n",
      "Epoch 49/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.4797\n",
      "Epoch 00049: val_loss did not improve from 1.20471\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4803 - val_loss: 1.3969\n",
      "Epoch 50/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.4508- ETA: 0s - lo\n",
      "Epoch 00050: val_loss improved from 1.20471 to 1.14169, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 28s 4ms/step - loss: 1.4507 - val_loss: 1.1417\n",
      "Epoch 51/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.4134\n",
      "Epoch 00051: val_loss did not improve from 1.14169\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4143 - val_loss: 1.4930\n",
      "Epoch 52/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3947\n",
      "Epoch 00052: val_loss did not improve from 1.14169\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3942 - val_loss: 1.1778\n",
      "Epoch 53/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.4440- ET\n",
      "Epoch 00053: val_loss did not improve from 1.14169\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4432 - val_loss: 1.1486\n",
      "Epoch 54/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3962\n",
      "Epoch 00054: val_loss improved from 1.14169 to 1.11474, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3961 - val_loss: 1.1147\n",
      "Epoch 55/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3671\n",
      "Epoch 00055: val_loss did not improve from 1.11474\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3678 - val_loss: 1.3242\n",
      "Epoch 56/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3681\n",
      "Epoch 00056: val_loss did not improve from 1.11474\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3680 - val_loss: 1.4174\n",
      "Epoch 57/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3834\n",
      "Epoch 00057: val_loss did not improve from 1.11474\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3836 - val_loss: 1.9359\n",
      "Epoch 58/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3574\n",
      "Epoch 00058: val_loss did not improve from 1.11474\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3590 - val_loss: 1.9522\n",
      "Epoch 59/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.3504\n",
      "Epoch 00059: val_loss improved from 1.11474 to 0.98643, saving model to DS02/experiment_set_10\\results_20\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3504 - val_loss: 0.9864\n",
      "Epoch 60/200\n",
      "6463/6477 [============================>.] - ETA: 0s - loss: 1.3491- ETA: 6s - - ETA: 5s  - ETA\n",
      "Epoch 00060: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3490 - val_loss: 1.2041\n",
      "Epoch 61/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.3374\n",
      "Epoch 00061: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3377 - val_loss: 1.0425\n",
      "Epoch 62/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3457\n",
      "Epoch 00062: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3456 - val_loss: 1.0198\n",
      "Epoch 63/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.3417\n",
      "Epoch 00063: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3418 - val_loss: 1.1739\n",
      "Epoch 64/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.3079\n",
      "Epoch 00064: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3080 - val_loss: 1.1922\n",
      "Epoch 65/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3364\n",
      "Epoch 00065: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3364 - val_loss: 1.1601\n",
      "Epoch 66/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3125\n",
      "Epoch 00066: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3125 - val_loss: 1.4334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3104\n",
      "Epoch 00067: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3104 - val_loss: 1.0272\n",
      "Epoch 68/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.2863- ETA: 0s - loss: 1.28\n",
      "Epoch 00068: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2862 - val_loss: 1.0042\n",
      "Epoch 69/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.2875\n",
      "Epoch 00069: val_loss did not improve from 0.98643\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2872 - val_loss: 1.1745\n",
      "Epoch 00069: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_20\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.01\n",
      "RMSE: 1.01\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_20\\split_2\\scaler.pkl\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 235,649\n",
      "Trainable params: 235,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 124.0952\n",
      "Epoch 00001: val_loss improved from inf to 16.32108, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 124.0698 - val_loss: 16.3211\n",
      "Epoch 2/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 12.8553\n",
      "Epoch 00002: val_loss improved from 16.32108 to 9.65856, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 12.8484 - val_loss: 9.6586\n",
      "Epoch 3/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 7.8298\n",
      "Epoch 00003: val_loss improved from 9.65856 to 6.70699, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.8298 - val_loss: 6.7070\n",
      "Epoch 4/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 5.9637\n",
      "Epoch 00004: val_loss improved from 6.70699 to 4.99386, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.9635 - val_loss: 4.9939\n",
      "Epoch 5/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 4.9771\n",
      "Epoch 00005: val_loss did not improve from 4.99386\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.9768 - val_loss: 5.3630\n",
      "Epoch 6/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 4.4168\n",
      "Epoch 00006: val_loss improved from 4.99386 to 4.50557, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.4182 - val_loss: 4.5056\n",
      "Epoch 7/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 3.9559\n",
      "Epoch 00007: val_loss improved from 4.50557 to 2.85252, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.9556 - val_loss: 2.8525\n",
      "Epoch 8/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 3.5447\n",
      "Epoch 00008: val_loss did not improve from 2.85252\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 3.5449 - val_loss: 3.7220\n",
      "Epoch 9/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.4061- - ETA:\n",
      "Epoch 00009: val_loss improved from 2.85252 to 2.67782, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.4061 - val_loss: 2.6778\n",
      "Epoch 10/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.1422\n",
      "Epoch 00010: val_loss did not improve from 2.67782\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.1430 - val_loss: 3.6965\n",
      "Epoch 11/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.0641- ETA: 0s \n",
      "Epoch 00011: val_loss did not improve from 2.67782\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.0643 - val_loss: 3.1146\n",
      "Epoch 12/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.8629\n",
      "Epoch 00012: val_loss did not improve from 2.67782\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.8646 - val_loss: 7.5766\n",
      "Epoch 13/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.7579- ETA: 2s - los - ETA\n",
      "Epoch 00013: val_loss improved from 2.67782 to 2.49998, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7572 - val_loss: 2.5000\n",
      "Epoch 14/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.6393\n",
      "Epoch 00014: val_loss did not improve from 2.49998\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6386 - val_loss: 3.6452\n",
      "Epoch 15/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.5640\n",
      "Epoch 00015: val_loss improved from 2.49998 to 1.98962, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5640 - val_loss: 1.9896\n",
      "Epoch 16/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.4880\n",
      "Epoch 00016: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.4907 - val_loss: 4.4759\n",
      "Epoch 17/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.3484\n",
      "Epoch 00017: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3477 - val_loss: 2.0430\n",
      "Epoch 18/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.3370\n",
      "Epoch 00018: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.3376 - val_loss: 2.6434\n",
      "Epoch 19/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 2.1969\n",
      "Epoch 00019: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1977 - val_loss: 3.2137\n",
      "Epoch 20/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.2538\n",
      "Epoch 00020: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2538 - val_loss: 6.1757\n",
      "Epoch 21/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.0937- ETA: 0s - \n",
      "Epoch 00021: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0937 - val_loss: 2.2731\n",
      "Epoch 22/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.1021\n",
      "Epoch 00022: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1022 - val_loss: 2.7603\n",
      "Epoch 23/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.0530- ETA: 0s - los\n",
      "Epoch 00023: val_loss did not improve from 1.98962\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0527 - val_loss: 2.2321\n",
      "Epoch 24/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.0308\n",
      "Epoch 00024: val_loss improved from 1.98962 to 1.75655, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0310 - val_loss: 1.7566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.9569\n",
      "Epoch 00025: val_loss did not improve from 1.75655\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9566 - val_loss: 1.9317\n",
      "Epoch 26/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.9334\n",
      "Epoch 00026: val_loss did not improve from 1.75655\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9329 - val_loss: 1.9577\n",
      "Epoch 27/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.8869- ETA:  - ETA: 4s - \n",
      "Epoch 00027: val_loss improved from 1.75655 to 1.59494, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8872 - val_loss: 1.5949\n",
      "Epoch 28/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.8323\n",
      "Epoch 00028: val_loss improved from 1.59494 to 1.52681, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8318 - val_loss: 1.5268\n",
      "Epoch 29/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.7723\n",
      "Epoch 00029: val_loss did not improve from 1.52681\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7722 - val_loss: 1.5841\n",
      "Epoch 30/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7794\n",
      "Epoch 00030: val_loss improved from 1.52681 to 1.31869, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7787 - val_loss: 1.3187\n",
      "Epoch 31/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7622- ETA: 2s - loss: 1.777 - ETA: 2s\n",
      "Epoch 00031: val_loss did not improve from 1.31869\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7630 - val_loss: 1.6835\n",
      "Epoch 32/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7715- ETA: 0s - loss:\n",
      "Epoch 00032: val_loss did not improve from 1.31869\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7715 - val_loss: 1.6059\n",
      "Epoch 33/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.7175\n",
      "Epoch 00033: val_loss did not improve from 1.31869\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7170 - val_loss: 1.4296\n",
      "Epoch 34/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.6906\n",
      "Epoch 00034: val_loss did not improve from 1.31869\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6902 - val_loss: 1.6287\n",
      "Epoch 35/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.6755\n",
      "Epoch 00035: val_loss did not improve from 1.31869\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6757 - val_loss: 1.6203\n",
      "Epoch 36/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.7204\n",
      "Epoch 00036: val_loss did not improve from 1.31869\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7204 - val_loss: 1.4280\n",
      "Epoch 37/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.6432- E\n",
      "Epoch 00037: val_loss improved from 1.31869 to 1.24343, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6428 - val_loss: 1.2434\n",
      "Epoch 38/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.6010\n",
      "Epoch 00038: val_loss did not improve from 1.24343\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6008 - val_loss: 1.8232\n",
      "Epoch 39/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.6446\n",
      "Epoch 00039: val_loss did not improve from 1.24343\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6440 - val_loss: 1.4247\n",
      "Epoch 40/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.6222- ETA: 0s - loss: \n",
      "Epoch 00040: val_loss did not improve from 1.24343\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.6223 - val_loss: 1.8023\n",
      "Epoch 41/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.5583\n",
      "Epoch 00041: val_loss improved from 1.24343 to 1.22591, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5577 - val_loss: 1.2259\n",
      "Epoch 42/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.5596\n",
      "Epoch 00042: val_loss did not improve from 1.22591\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.5598 - val_loss: 1.4424\n",
      "Epoch 43/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.5176\n",
      "Epoch 00043: val_loss improved from 1.22591 to 1.20469, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5171 - val_loss: 1.2047\n",
      "Epoch 44/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.5277\n",
      "Epoch 00044: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5277 - val_loss: 1.3870\n",
      "Epoch 45/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.5354\n",
      "Epoch 00045: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.5348 - val_loss: 1.2362\n",
      "Epoch 46/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.4840\n",
      "Epoch 00046: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4843 - val_loss: 2.4603\n",
      "Epoch 47/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.5101\n",
      "Epoch 00047: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5101 - val_loss: 1.2554\n",
      "Epoch 48/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.4662- ET\n",
      "Epoch 00048: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4661 - val_loss: 1.3291\n",
      "Epoch 49/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.5156\n",
      "Epoch 00049: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.5156 - val_loss: 1.3855\n",
      "Epoch 50/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.4559\n",
      "Epoch 00050: val_loss did not improve from 1.20469\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4561 - val_loss: 1.6186\n",
      "Epoch 51/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.4771\n",
      "Epoch 00051: val_loss improved from 1.20469 to 1.13747, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.4767 - val_loss: 1.1375\n",
      "Epoch 52/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.4291\n",
      "Epoch 00052: val_loss did not improve from 1.13747\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4293 - val_loss: 2.1068\n",
      "Epoch 53/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3978\n",
      "Epoch 00053: val_loss improved from 1.13747 to 1.02161, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3978 - val_loss: 1.0216\n",
      "Epoch 54/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3799\n",
      "Epoch 00054: val_loss did not improve from 1.02161\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.3798 - val_loss: 1.1728\n",
      "Epoch 55/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.3965\n",
      "Epoch 00055: val_loss did not improve from 1.02161\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3965 - val_loss: 2.0638\n",
      "Epoch 56/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.4210\n",
      "Epoch 00056: val_loss did not improve from 1.02161\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.4203 - val_loss: 1.1443\n",
      "Epoch 57/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3980\n",
      "Epoch 00057: val_loss did not improve from 1.02161\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3980 - val_loss: 1.4580\n",
      "Epoch 58/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3905\n",
      "Epoch 00058: val_loss did not improve from 1.02161\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3908 - val_loss: 1.7512\n",
      "Epoch 59/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.3665\n",
      "Epoch 00059: val_loss improved from 1.02161 to 0.95556, saving model to DS02/experiment_set_10\\results_20\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3664 - val_loss: 0.9556\n",
      "Epoch 60/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.3400- ETA: 0s\n",
      "Epoch 00060: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3395 - val_loss: 1.3311\n",
      "Epoch 61/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3501\n",
      "Epoch 00061: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3499 - val_loss: 1.1129\n",
      "Epoch 62/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.3509\n",
      "Epoch 00062: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3508 - val_loss: 1.0668\n",
      "Epoch 63/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.3365\n",
      "Epoch 00063: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3369 - val_loss: 1.6924\n",
      "Epoch 64/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.2993\n",
      "Epoch 00064: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.2987 - val_loss: 0.9867\n",
      "Epoch 65/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.3427\n",
      "Epoch 00065: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.3428 - val_loss: 2.2768\n",
      "Epoch 66/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.3233- ETA: 0\n",
      "Epoch 00066: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3233 - val_loss: 1.7006\n",
      "Epoch 67/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 1.3282\n",
      "Epoch 00067: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.3282 - val_loss: 1.2145\n",
      "Epoch 68/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.2924\n",
      "Epoch 00068: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2924 - val_loss: 1.7840\n",
      "Epoch 69/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.2366- ETA: 0s - loss: 1. - ETA: 0s \n",
      "Epoch 00069: val_loss did not improve from 0.95556\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.2368 - val_loss: 1.7335\n",
      "Epoch 00069: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_20\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 0.95\n",
      "RMSE: 0.98\n",
      "CMAPSS score: 1.04\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_25\\split_0\\scaler.pkl\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 256)               6656      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 236,929\n",
      "Trainable params: 236,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 119.8639\n",
      "Epoch 00001: val_loss improved from inf to 16.61833, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 119.8243 - val_loss: 16.6183\n",
      "Epoch 2/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 12.8683\n",
      "Epoch 00002: val_loss improved from 16.61833 to 9.29160, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 12.8677 - val_loss: 9.2916\n",
      "Epoch 3/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 7.7758\n",
      "Epoch 00003: val_loss improved from 9.29160 to 5.91957, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.7739 - val_loss: 5.9196\n",
      "Epoch 4/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 5.9326\n",
      "Epoch 00004: val_loss improved from 5.91957 to 4.85028, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.9326 - val_loss: 4.8503\n",
      "Epoch 5/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 5.1542\n",
      "Epoch 00005: val_loss improved from 4.85028 to 4.45495, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 5.1536 - val_loss: 4.4549\n",
      "Epoch 6/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 4.5694\n",
      "Epoch 00006: val_loss improved from 4.45495 to 4.16168, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.5690 - val_loss: 4.1617\n",
      "Epoch 7/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 4.0980- ETA: 4s - los\n",
      "Epoch 00007: val_loss improved from 4.16168 to 4.07541, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.0982 - val_loss: 4.0754\n",
      "Epoch 8/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.7435\n",
      "Epoch 00008: val_loss improved from 4.07541 to 3.00242, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.7436 - val_loss: 3.0024\n",
      "Epoch 9/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 3.5672\n",
      "Epoch 00009: val_loss did not improve from 3.00242\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.5671 - val_loss: 3.6715\n",
      "Epoch 10/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 3.3485\n",
      "Epoch 00010: val_loss did not improve from 3.00242\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.3509 - val_loss: 4.8794\n",
      "Epoch 11/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.2236\n",
      "Epoch 00011: val_loss improved from 3.00242 to 2.94887, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.2230 - val_loss: 2.9489\n",
      "Epoch 12/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 3.0586\n",
      "Epoch 00012: val_loss improved from 2.94887 to 2.48708, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.0572 - val_loss: 2.4871\n",
      "Epoch 13/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.9170\n",
      "Epoch 00013: val_loss did not improve from 2.48708\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9174 - val_loss: 6.8132\n",
      "Epoch 14/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.8496\n",
      "Epoch 00014: val_loss improved from 2.48708 to 2.47443, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.8496 - val_loss: 2.4744\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.6714\n",
      "Epoch 00015: val_loss improved from 2.47443 to 2.20841, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6710 - val_loss: 2.2084\n",
      "Epoch 16/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.6553\n",
      "Epoch 00016: val_loss did not improve from 2.20841\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6552 - val_loss: 2.3626\n",
      "Epoch 17/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.5255\n",
      "Epoch 00017: val_loss did not improve from 2.20841\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5253 - val_loss: 2.2433\n",
      "Epoch 18/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.4697\n",
      "Epoch 00018: val_loss improved from 2.20841 to 2.13232, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.4693 - val_loss: 2.1323\n",
      "Epoch 19/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 2.4148\n",
      "Epoch 00019: val_loss improved from 2.13232 to 2.11496, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.4141 - val_loss: 2.1150\n",
      "Epoch 20/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.2973\n",
      "Epoch 00020: val_loss improved from 2.11496 to 1.94964, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2971 - val_loss: 1.9496\n",
      "Epoch 21/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.2557- ETA: 0\n",
      "Epoch 00021: val_loss did not improve from 1.94964\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2555 - val_loss: 2.4345\n",
      "Epoch 22/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.2741- ETA:\n",
      "Epoch 00022: val_loss improved from 1.94964 to 1.80601, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.2740 - val_loss: 1.8060\n",
      "Epoch 23/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.1903\n",
      "Epoch 00023: val_loss did not improve from 1.80601\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1899 - val_loss: 1.8907\n",
      "Epoch 24/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.1564\n",
      "Epoch 00024: val_loss did not improve from 1.80601\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.1564 - val_loss: 4.4119\n",
      "Epoch 25/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.0660\n",
      "Epoch 00025: val_loss did not improve from 1.80601\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0655 - val_loss: 2.6876\n",
      "Epoch 26/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 2.0855\n",
      "Epoch 00026: val_loss did not improve from 1.80601\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0854 - val_loss: 2.0487\n",
      "Epoch 27/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.0002- ETA: 0s - \n",
      "Epoch 00027: val_loss did not improve from 1.80601\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.0003 - val_loss: 2.1019\n",
      "Epoch 28/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.0023\n",
      "Epoch 00028: val_loss improved from 1.80601 to 1.72298, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0023 - val_loss: 1.7230\n",
      "Epoch 29/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.9806\n",
      "Epoch 00029: val_loss improved from 1.72298 to 1.71228, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9805 - val_loss: 1.7123\n",
      "Epoch 30/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.9352\n",
      "Epoch 00030: val_loss did not improve from 1.71228\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9350 - val_loss: 2.0548\n",
      "Epoch 31/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.9412\n",
      "Epoch 00031: val_loss did not improve from 1.71228\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.9421 - val_loss: 2.2188\n",
      "Epoch 32/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 1.9197\n",
      "Epoch 00032: val_loss did not improve from 1.71228\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9198 - val_loss: 2.2122\n",
      "Epoch 33/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.8699\n",
      "Epoch 00033: val_loss improved from 1.71228 to 1.48951, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8700 - val_loss: 1.4895\n",
      "Epoch 34/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.8410\n",
      "Epoch 00034: val_loss did not improve from 1.48951\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8408 - val_loss: 2.0887\n",
      "Epoch 35/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 1.8537\n",
      "Epoch 00035: val_loss improved from 1.48951 to 1.37064, saving model to DS02/experiment_set_10\\results_25\\split_0\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8533 - val_loss: 1.3706\n",
      "Epoch 36/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7717\n",
      "Epoch 00036: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7718 - val_loss: 1.8673\n",
      "Epoch 37/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.7632\n",
      "Epoch 00037: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7634 - val_loss: 1.8679\n",
      "Epoch 38/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.7760\n",
      "Epoch 00038: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7758 - val_loss: 1.4181\n",
      "Epoch 39/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7434\n",
      "Epoch 00039: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7432 - val_loss: 1.3847\n",
      "Epoch 40/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.7027\n",
      "Epoch 00040: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7026 - val_loss: 1.5834\n",
      "Epoch 41/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.7119\n",
      "Epoch 00041: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 1.7119 - val_loss: 1.8723\n",
      "Epoch 42/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.6790\n",
      "Epoch 00042: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6788 - val_loss: 1.8186\n",
      "Epoch 43/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 1.6496\n",
      "Epoch 00043: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6505 - val_loss: 2.2436\n",
      "Epoch 44/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 1.6769- ETA: 0s - l\n",
      "Epoch 00044: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6768 - val_loss: 1.5585\n",
      "Epoch 45/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.6151\n",
      "Epoch 00045: val_loss did not improve from 1.37064\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.6148 - val_loss: 1.4120\n",
      "Epoch 00045: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_25\\split_0\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.38\n",
      "RMSE: 1.18\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_25\\split_1\\scaler.pkl\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 256)               6656      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 236,929\n",
      "Trainable params: 236,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 120.6835\n",
      "Epoch 00001: val_loss improved from inf to 16.56830, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 120.6266 - val_loss: 16.5683\n",
      "Epoch 2/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 14.0081\n",
      "Epoch 00002: val_loss improved from 16.56830 to 10.94052, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 14.0057 - val_loss: 10.9405\n",
      "Epoch 3/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 8.6365- ETA: 0s - loss: 8.6\n",
      "Epoch 00003: val_loss improved from 10.94052 to 6.28853, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 8.6365 - val_loss: 6.2885\n",
      "Epoch 4/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 6.5177\n",
      "Epoch 00004: val_loss improved from 6.28853 to 5.05779, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 6.5141 - val_loss: 5.0578\n",
      "Epoch 5/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 5.3997\n",
      "Epoch 00005: val_loss improved from 5.05779 to 4.07841, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 5.3989 - val_loss: 4.0784\n",
      "Epoch 6/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 4.8848-  - ETA:\n",
      "Epoch 00006: val_loss did not improve from 4.07841\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.8842 - val_loss: 4.2927\n",
      "Epoch 7/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 4.3700\n",
      "Epoch 00007: val_loss did not improve from 4.07841\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.3700 - val_loss: 4.4538\n",
      "Epoch 8/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 4.0257\n",
      "Epoch 00008: val_loss did not improve from 4.07841\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 4.0258 - val_loss: 6.7753\n",
      "Epoch 9/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 3.8214- ETA: 0s - loss: 3.821\n",
      "Epoch 00009: val_loss improved from 4.07841 to 3.73199, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.8211 - val_loss: 3.7320\n",
      "Epoch 10/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 3.5868- ETA: 0s - loss: 3.\n",
      "Epoch 00010: val_loss improved from 3.73199 to 2.99625, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.5861 - val_loss: 2.9963\n",
      "Epoch 11/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.4011\n",
      "Epoch 00011: val_loss did not improve from 2.99625\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.4012 - val_loss: 3.1550\n",
      "Epoch 12/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.2109- ET\n",
      "Epoch 00012: val_loss improved from 2.99625 to 2.64391, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.2104 - val_loss: 2.6439\n",
      "Epoch 13/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 3.0252\n",
      "Epoch 00013: val_loss did not improve from 2.64391\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.0251 - val_loss: 2.9979\n",
      "Epoch 14/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.9228\n",
      "Epoch 00014: val_loss did not improve from 2.64391\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.9228 - val_loss: 2.6862\n",
      "Epoch 15/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 2.8289\n",
      "Epoch 00015: val_loss improved from 2.64391 to 2.03219, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.8280 - val_loss: 2.0322\n",
      "Epoch 16/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.7080\n",
      "Epoch 00016: val_loss did not improve from 2.03219\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7083 - val_loss: 2.8848\n",
      "Epoch 17/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.6553\n",
      "Epoch 00017: val_loss did not improve from 2.03219\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.6554 - val_loss: 2.4912\n",
      "Epoch 18/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.5909\n",
      "Epoch 00018: val_loss did not improve from 2.03219\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5909 - val_loss: 4.3697\n",
      "Epoch 19/200\n",
      "6477/6477 [==============================] - ETA: 0s - loss: 2.5491\n",
      "Epoch 00019: val_loss did not improve from 2.03219\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.5491 - val_loss: 2.0473\n",
      "Epoch 20/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.3880\n",
      "Epoch 00020: val_loss did not improve from 2.03219\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3877 - val_loss: 2.2642\n",
      "Epoch 21/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 2.3834\n",
      "Epoch 00021: val_loss improved from 2.03219 to 1.94266, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3826 - val_loss: 1.9427\n",
      "Epoch 22/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.3479- ETA: 0s - \n",
      "Epoch 00022: val_loss did not improve from 1.94266\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3478 - val_loss: 2.3368\n",
      "Epoch 23/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 2.2598\n",
      "Epoch 00023: val_loss improved from 1.94266 to 1.82848, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.2594 - val_loss: 1.8285\n",
      "Epoch 24/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.2357\n",
      "Epoch 00024: val_loss did not improve from 1.82848\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2356 - val_loss: 2.2384\n",
      "Epoch 25/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.1618- ETA: 0s - loss\n",
      "Epoch 00025: val_loss improved from 1.82848 to 1.74747, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1616 - val_loss: 1.7475\n",
      "Epoch 26/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.1353\n",
      "Epoch 00026: val_loss did not improve from 1.74747\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1348 - val_loss: 1.9874\n",
      "Epoch 27/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.1191\n",
      "Epoch 00027: val_loss did not improve from 1.74747\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1189 - val_loss: 2.0213\n",
      "Epoch 28/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.1158- ETA: 0s - los\n",
      "Epoch 00028: val_loss did not improve from 1.74747\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.1157 - val_loss: 2.0051\n",
      "Epoch 29/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.0489\n",
      "Epoch 00029: val_loss did not improve from 1.74747\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0485 - val_loss: 1.8640\n",
      "Epoch 30/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.9712- ET\n",
      "Epoch 00030: val_loss did not improve from 1.74747\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9718 - val_loss: 3.4670\n",
      "Epoch 31/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.9425\n",
      "Epoch 00031: val_loss improved from 1.74747 to 1.68977, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9421 - val_loss: 1.6898\n",
      "Epoch 32/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.9708\n",
      "Epoch 00032: val_loss did not improve from 1.68977\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.9706 - val_loss: 2.0055\n",
      "Epoch 33/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 1.9063\n",
      "Epoch 00033: val_loss improved from 1.68977 to 1.55931, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9063 - val_loss: 1.5593\n",
      "Epoch 34/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.8596\n",
      "Epoch 00034: val_loss improved from 1.55931 to 1.42593, saving model to DS02/experiment_set_10\\results_25\\split_1\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8592 - val_loss: 1.4259\n",
      "Epoch 35/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8597- ETA\n",
      "Epoch 00035: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8595 - val_loss: 2.5584\n",
      "Epoch 36/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.8535- \n",
      "Epoch 00036: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8532 - val_loss: 1.5189\n",
      "Epoch 37/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.8078\n",
      "Epoch 00037: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.8078 - val_loss: 1.4312\n",
      "Epoch 38/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 1.8316- \n",
      "Epoch 00038: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.8317 - val_loss: 1.7049\n",
      "Epoch 39/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 1.7891\n",
      "Epoch 00039: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7895 - val_loss: 2.2442\n",
      "Epoch 40/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 1.7722\n",
      "Epoch 00040: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7739 - val_loss: 4.1249\n",
      "Epoch 41/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.7713- ETA: 0s - lo\n",
      "Epoch 00041: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.7711 - val_loss: 1.5985\n",
      "Epoch 42/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7591\n",
      "Epoch 00042: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7587 - val_loss: 1.7576\n",
      "Epoch 43/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.7107\n",
      "Epoch 00043: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7110 - val_loss: 1.9834\n",
      "Epoch 44/200\n",
      "6467/6477 [============================>.] - ETA: 0s - loss: 1.7061\n",
      "Epoch 00044: val_loss did not improve from 1.42593\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 1.7059 - val_loss: 1.5472\n",
      "Epoch 00044: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_25\\split_1\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.44\n",
      "RMSE: 1.20\n",
      "CMAPSS score: 1.05\n",
      "\n",
      "Saved object to file: DS02/experiment_set_10\\results_25\\split_2\\scaler.pkl\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 256)               6656      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 236,929\n",
      "Trainable params: 236,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 120.2396\n",
      "Epoch 00001: val_loss improved from inf to 16.98173, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 120.1350 - val_loss: 16.9817\n",
      "Epoch 2/200\n",
      "6471/6477 [============================>.] - ETA: 0s - loss: 12.8899\n",
      "Epoch 00002: val_loss improved from 16.98173 to 9.41009, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 12.8873 - val_loss: 9.4101\n",
      "Epoch 3/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 7.3967\n",
      "Epoch 00003: val_loss improved from 9.41009 to 5.57565, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 7.3964 - val_loss: 5.5757\n",
      "Epoch 4/200\n",
      "6469/6477 [============================>.] - ETA: 0s - loss: 5.6631- ET\n",
      "Epoch 00004: val_loss did not improve from 5.57565\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 5.6621 - val_loss: 5.9428\n",
      "Epoch 5/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 4.8252\n",
      "Epoch 00005: val_loss improved from 5.57565 to 4.88919, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.8240 - val_loss: 4.8892\n",
      "Epoch 6/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 4.3637\n",
      "Epoch 00006: val_loss improved from 4.88919 to 3.78948, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 4.3635 - val_loss: 3.7895\n",
      "Epoch 7/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 3.9216\n",
      "Epoch 00007: val_loss improved from 3.78948 to 3.45791, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 3.9201 - val_loss: 3.4579\n",
      "Epoch 8/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.6714\n",
      "Epoch 00008: val_loss did not improve from 3.45791\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.6714 - val_loss: 6.7966\n",
      "Epoch 9/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 3.4534\n",
      "Epoch 00009: val_loss improved from 3.45791 to 2.74145, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.4530 - val_loss: 2.7414\n",
      "Epoch 10/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 3.2357\n",
      "Epoch 00010: val_loss did not improve from 2.74145\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.2357 - val_loss: 3.2849\n",
      "Epoch 11/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 3.0101\n",
      "Epoch 00011: val_loss did not improve from 2.74145\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 3.0103 - val_loss: 2.7724\n",
      "Epoch 12/200\n",
      "6475/6477 [============================>.] - ETA: 0s - loss: 2.9001\n",
      "Epoch 00012: val_loss did not improve from 2.74145\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.9003 - val_loss: 5.4697\n",
      "Epoch 13/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.7879\n",
      "Epoch 00013: val_loss improved from 2.74145 to 2.22741, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7878 - val_loss: 2.2274\n",
      "Epoch 14/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.7101\n",
      "Epoch 00014: val_loss improved from 2.22741 to 2.09553, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.7091 - val_loss: 2.0955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.5953\n",
      "Epoch 00015: val_loss did not improve from 2.09553\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.5947 - val_loss: 2.3533\n",
      "Epoch 16/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.5724\n",
      "Epoch 00016: val_loss did not improve from 2.09553\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.5724 - val_loss: 2.4141\n",
      "Epoch 17/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.3825\n",
      "Epoch 00017: val_loss improved from 2.09553 to 2.01829, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3820 - val_loss: 2.0183\n",
      "Epoch 18/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 2.3524\n",
      "Epoch 00018: val_loss did not improve from 2.01829\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.3523 - val_loss: 2.3975\n",
      "Epoch 19/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 2.3119\n",
      "Epoch 00019: val_loss did not improve from 2.01829\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.3120 - val_loss: 2.7440\n",
      "Epoch 20/200\n",
      "6476/6477 [============================>.] - ETA: 0s - loss: 2.3060- ETA: 0s - loss: 2.30 - ETA: 0s - los\n",
      "Epoch 00020: val_loss improved from 2.01829 to 1.61152, saving model to DS02/experiment_set_10\\results_25\\split_2\\mlp_model_trained.h5\n",
      "6477/6477 [==============================] - 27s 4ms/step - loss: 2.3060 - val_loss: 1.6115\n",
      "Epoch 21/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.2270- ETA:  - ETA: 2 - ETA: 0s - loss\n",
      "Epoch 00021: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.2262 - val_loss: 1.9485\n",
      "Epoch 22/200\n",
      "6468/6477 [============================>.] - ETA: 0s - loss: 2.1514- ETA: 0s - loss:\n",
      "Epoch 00022: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1509 - val_loss: 1.6313\n",
      "Epoch 23/200\n",
      "6472/6477 [============================>.] - ETA: 0s - loss: 2.1125\n",
      "Epoch 00023: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 25s 4ms/step - loss: 2.1126 - val_loss: 1.9714\n",
      "Epoch 24/200\n",
      "6470/6477 [============================>.] - ETA: 0s - loss: 2.0816- ETA: 0s - loss: \n",
      "Epoch 00024: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0818 - val_loss: 1.6855\n",
      "Epoch 25/200\n",
      "6473/6477 [============================>.] - ETA: 0s - loss: 2.0318\n",
      "Epoch 00025: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 2.0315 - val_loss: 3.4376\n",
      "Epoch 26/200\n",
      "6466/6477 [============================>.] - ETA: 0s - loss: 1.9795\n",
      "Epoch 00026: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9798 - val_loss: 2.0394\n",
      "Epoch 27/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.9944\n",
      "Epoch 00027: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9939 - val_loss: 1.9156\n",
      "Epoch 28/200\n",
      "6474/6477 [============================>.] - ETA: 0s - loss: 1.9695\n",
      "Epoch 00028: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9693 - val_loss: 1.7653\n",
      "Epoch 29/200\n",
      "6465/6477 [============================>.] - ETA: 0s - loss: 1.9136\n",
      "Epoch 00029: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9129 - val_loss: 1.7066\n",
      "Epoch 30/200\n",
      "6464/6477 [============================>.] - ETA: 0s - loss: 1.9061\n",
      "Epoch 00030: val_loss did not improve from 1.61152\n",
      "6477/6477 [==============================] - 26s 4ms/step - loss: 1.9079 - val_loss: 2.2015\n",
      "Epoch 00030: early stopping\n",
      "Saved training history to file: DS02/experiment_set_10\\results_25\\split_2\\history.pkl\n",
      "Test set:\n",
      "MSE: 1.64\n",
      "RMSE: 1.28\n",
      "CMAPSS score: 1.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Test effect of mutual information ranking\n",
    "###########################################\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "layer_sizes = [256, 256, 512, 64]\n",
    "\n",
    "num_selected_columns = [10, 15, 20, 25]\n",
    "\n",
    "results_file = os.path.join(output_path, \"results_mi_ranking.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"selected_features,num_features,mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "\n",
    "for n in num_selected_columns:\n",
    "    selected_columns = get_mi_ranked_features(mutual_info_series, n)\n",
    "    x_train_feature_selection = x_train[selected_columns]\n",
    "    \n",
    "    mse_vals = []\n",
    "    rmse_vals = []\n",
    "    cmapss_vals = []\n",
    "    \n",
    "    for random_seed in range(NUM_TRIALS):\n",
    "        # Train-validation split for early stopping\n",
    "        x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train_feature_selection, \n",
    "                                                                                  y_train, \n",
    "                                                                                  test_size=0.1, \n",
    "                                                                                  random_state=random_seed)\n",
    "        # Create output path\n",
    "        results_folder =\"results_{}\".format(n)\n",
    "        results_path_crr_num = os.path.join(output_path, results_folder)\n",
    "        results_path_crr_split = os.path.join(results_path_crr_num, \"split_{}\".format(random_seed))\n",
    "        if not os.path.exists(results_path_crr_split):\n",
    "            os.makedirs(results_path_crr_split)\n",
    "\n",
    "        # Standardization\n",
    "        scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(x_train_split)\n",
    "        x_val_scaled = scaler.transform(x_val_split)\n",
    "        input_dim = x_train_scaled.shape[1]\n",
    "        save_object(scaler, scaler_file)\n",
    "\n",
    "        # Create model\n",
    "        weights_file = os.path.join(results_path_crr_num, 'mlp_initial_weights.h5')\n",
    "        model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "        \n",
    "        # Save initial weights\n",
    "        if random_seed == 0:\n",
    "            model = create_mlp_model(input_dim, layer_sizes, activation='tanh',\n",
    "                                     output_weights_file=weights_file)\n",
    "        else:\n",
    "            model = create_mlp_model(input_dim, layer_sizes, activation='tanh')\n",
    "        model.summary()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=2, \n",
    "                             save_best_only=True)\n",
    "\n",
    "        # Train model\n",
    "        history = train_model_existing_weights(model, weights_file, \n",
    "                                               x_train_scaled, y_train_split, \n",
    "                                               x_val_scaled, y_val_split, \n",
    "                                               batch_size=batch_size, \n",
    "                                               epochs=epochs, \n",
    "                                               callbacks=[es, mc])\n",
    "\n",
    "        history_file = os.path.join(results_path_crr_split, \"history.pkl\")\n",
    "        save_history(history, history_file)\n",
    "\n",
    "        # Performance evaluation\n",
    "        x_holdout_feature_selection = x_holdout[selected_columns]\n",
    "        x_holdout_scaled = scaler.transform(x_holdout_feature_selection)\n",
    "\n",
    "        loaded_model = load_model(model_path)\n",
    "        predictions_holdout = loaded_model.predict(x_holdout_scaled).flatten()\n",
    "        mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_holdout, y_holdout)\n",
    "        \n",
    "        mse_vals.append(mse)\n",
    "        rmse_vals.append(rmse)\n",
    "        cmapss_vals.append(cmapss_score)\n",
    "    \n",
    "    mse_mean = np.mean(mse_vals)\n",
    "    mse_std = np.std(mse_vals)\n",
    "    rmse_mean = np.mean(rmse_vals)\n",
    "    rmse_std = np.std(rmse_vals)\n",
    "    cmapss_mean = np.mean(cmapss_vals)\n",
    "    cmapss_std = np.std(cmapss_vals)\n",
    "    \n",
    "    with open(results_file, \"a\") as file:\n",
    "        file.write(f\"{feature_list_to_string(selected_columns)}, {len(selected_columns)}, {numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)}, {numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean}, {rmse_std}, {cmapss_mean}, {cmapss_std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "MSE: 25.56\n",
      "RMSE: 5.06\n",
      "CMAPSS score: 1.46\n",
      "\n",
      "Test set:\n",
      "MSE: 39.02\n",
      "RMSE: 6.25\n",
      "CMAPSS score: 1.62\n",
      "\n",
      "Test set:\n",
      "MSE: 34.20\n",
      "RMSE: 5.85\n",
      "CMAPSS score: 1.55\n",
      "\n",
      "Test set:\n",
      "MSE: 44.83\n",
      "RMSE: 6.70\n",
      "CMAPSS score: 1.65\n",
      "\n",
      "Test set:\n",
      "MSE: 39.70\n",
      "RMSE: 6.30\n",
      "CMAPSS score: 1.59\n",
      "\n",
      "Test set:\n",
      "MSE: 40.34\n",
      "RMSE: 6.35\n",
      "CMAPSS score: 1.60\n",
      "\n",
      "Test set:\n",
      "MSE: 38.40\n",
      "RMSE: 6.20\n",
      "CMAPSS score: 1.61\n",
      "\n",
      "Test set:\n",
      "MSE: 39.08\n",
      "RMSE: 6.25\n",
      "CMAPSS score: 1.61\n",
      "\n",
      "Test set:\n",
      "MSE: 36.48\n",
      "RMSE: 6.04\n",
      "CMAPSS score: 1.57\n",
      "\n",
      "Test set:\n",
      "MSE: 33.06\n",
      "RMSE: 5.75\n",
      "CMAPSS score: 1.54\n",
      "\n",
      "Test set:\n",
      "MSE: 33.03\n",
      "RMSE: 5.75\n",
      "CMAPSS score: 1.54\n",
      "\n",
      "Test set:\n",
      "MSE: 33.37\n",
      "RMSE: 5.78\n",
      "CMAPSS score: 1.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Results on test set\n",
    "######################################################\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "layer_sizes = [256, 256, 512, 64]\n",
    "\n",
    "num_selected_columns = [10, 15, 20, 25]\n",
    "\n",
    "results_file = os.path.join(output_path, \"results_mi_ranking_test_set.csv\")\n",
    "with open(results_file, \"w\") as file:\n",
    "    file.write(\"selected_features,num_features,mse,rmse,cmapss,mse(mean),mse(std),rmse(mean),rmse(std),cmapss(mean),cmapss(std)\\n\")\n",
    "\n",
    "\n",
    "for n in num_selected_columns:\n",
    "    selected_columns = get_mi_ranked_features(mutual_info_series, n)\n",
    "    \n",
    "    mse_vals = []\n",
    "    rmse_vals = []\n",
    "    cmapss_vals = []\n",
    "    \n",
    "    for random_seed in range(NUM_TRIALS):\n",
    "        results_folder =\"results_{}\".format(n)\n",
    "        results_path_crr_th = os.path.join(output_path, results_folder)\n",
    "        results_path_crr_split = os.path.join(results_path_crr_th, \"split_{}\".format(random_seed))\n",
    "        \n",
    "        scaler_file = os.path.join(results_path_crr_split, 'scaler.pkl')\n",
    "        scaler = load_object(scaler_file)\n",
    "\n",
    "        model_path = os.path.join(results_path_crr_split, 'mlp_model_trained.h5')\n",
    "        \n",
    "        # Performance evaluation\n",
    "        x_test_feature_selection = x_test[selected_columns]\n",
    "        x_test_scaled = scaler.transform(x_test_feature_selection)\n",
    "\n",
    "        loaded_model = load_model(model_path)\n",
    "        predictions_test = loaded_model.predict(x_test_scaled).flatten()\n",
    "        mse, rmse, cmapss_score = compute_evaluation_metrics(predictions_test, y_test)\n",
    "        \n",
    "        mse_vals.append(mse)\n",
    "        rmse_vals.append(rmse)\n",
    "        cmapss_vals.append(cmapss_score)\n",
    "    \n",
    "    mse_mean = np.mean(mse_vals)\n",
    "    mse_std = np.std(mse_vals)\n",
    "    rmse_mean = np.mean(rmse_vals)\n",
    "    rmse_std = np.std(rmse_vals)\n",
    "    cmapss_mean = np.mean(cmapss_vals)\n",
    "    cmapss_std = np.std(cmapss_vals)\n",
    "    \n",
    "    with open(results_file, \"a\") as file:\n",
    "        file.write(f\"{feature_list_to_string(selected_columns)}, {len(selected_columns)}, {numbers_list_to_string(mse_vals)}, {numbers_list_to_string(rmse_vals)}, {numbers_list_to_string(cmapss_vals)}, {mse_mean}, {mse_std}, {rmse_mean}, {rmse_std}, {cmapss_mean}, {cmapss_std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-keras-gpu",
   "language": "python",
   "name": "tf-keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
